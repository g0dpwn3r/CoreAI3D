// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: cloud_speech.proto
// Protobuf C++ Version: 5.29.5

#include "cloud_speech.pb.h"

#include <algorithm>
#include <type_traits>
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/generated_message_tctable_impl.h"
#include "google/protobuf/extension_set.h"
#include "google/protobuf/generated_message_util.h"
#include "google/protobuf/wire_format_lite.h"
#include "google/protobuf/descriptor.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/reflection_ops.h"
#include "google/protobuf/wire_format.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"
PROTOBUF_PRAGMA_INIT_SEG
namespace _pb = ::google::protobuf;
namespace _pbi = ::google::protobuf::internal;
namespace _fl = ::google::protobuf::internal::field_layout;
namespace google {
namespace cloud {
namespace speech {
namespace v1 {

inline constexpr TranscriptOutputConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : output_type_{},
        _cached_size_{0},
        _oneof_case_{} {}

template <typename>
PROTOBUF_CONSTEXPR TranscriptOutputConfig::TranscriptOutputConfig(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct TranscriptOutputConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR TranscriptOutputConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~TranscriptOutputConfigDefaultTypeInternal() {}
  union {
    TranscriptOutputConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 TranscriptOutputConfigDefaultTypeInternal _TranscriptOutputConfig_default_instance_;

inline constexpr SpeechContext::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : phrases_{},
        boost_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechContext::SpeechContext(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeechContextDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechContextDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechContextDefaultTypeInternal() {}
  union {
    SpeechContext _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechContextDefaultTypeInternal _SpeechContext_default_instance_;

inline constexpr SpeechAdaptationInfo::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : timeout_message_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        adaptation_timeout_{false},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechAdaptationInfo::SpeechAdaptationInfo(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeechAdaptationInfoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechAdaptationInfoDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechAdaptationInfoDefaultTypeInternal() {}
  union {
    SpeechAdaptationInfo _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechAdaptationInfoDefaultTypeInternal _SpeechAdaptationInfo_default_instance_;

inline constexpr SpeakerDiarizationConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : enable_speaker_diarization_{false},
        min_speaker_count_{0},
        max_speaker_count_{0},
        speaker_tag_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeakerDiarizationConfig::SpeakerDiarizationConfig(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeakerDiarizationConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeakerDiarizationConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeakerDiarizationConfigDefaultTypeInternal() {}
  union {
    SpeakerDiarizationConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeakerDiarizationConfigDefaultTypeInternal _SpeakerDiarizationConfig_default_instance_;

inline constexpr RecognitionMetadata::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : recording_device_name_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        original_mime_type_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        audio_topic_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        interaction_type_{static_cast< ::google::cloud::speech::v1::RecognitionMetadata_InteractionType >(0)},
        industry_naics_code_of_audio_{0u},
        microphone_distance_{static_cast< ::google::cloud::speech::v1::RecognitionMetadata_MicrophoneDistance >(0)},
        original_media_type_{static_cast< ::google::cloud::speech::v1::RecognitionMetadata_OriginalMediaType >(0)},
        recording_device_type_{static_cast< ::google::cloud::speech::v1::RecognitionMetadata_RecordingDeviceType >(0)},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR RecognitionMetadata::RecognitionMetadata(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognitionMetadataDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognitionMetadataDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognitionMetadataDefaultTypeInternal() {}
  union {
    RecognitionMetadata _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognitionMetadataDefaultTypeInternal _RecognitionMetadata_default_instance_;

inline constexpr RecognitionAudio::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : audio_source_{},
        _cached_size_{0},
        _oneof_case_{} {}

template <typename>
PROTOBUF_CONSTEXPR RecognitionAudio::RecognitionAudio(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognitionAudioDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognitionAudioDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognitionAudioDefaultTypeInternal() {}
  union {
    RecognitionAudio _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognitionAudioDefaultTypeInternal _RecognitionAudio_default_instance_;

inline constexpr WordInfo::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        word_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        speaker_label_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        start_time_{nullptr},
        end_time_{nullptr},
        confidence_{0},
        speaker_tag_{0} {}

template <typename>
PROTOBUF_CONSTEXPR WordInfo::WordInfo(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct WordInfoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR WordInfoDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~WordInfoDefaultTypeInternal() {}
  union {
    WordInfo _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 WordInfoDefaultTypeInternal _WordInfo_default_instance_;

inline constexpr StreamingRecognitionConfig_VoiceActivityTimeout::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        speech_start_timeout_{nullptr},
        speech_end_timeout_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognitionConfig_VoiceActivityTimeout::StreamingRecognitionConfig_VoiceActivityTimeout(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognitionConfig_VoiceActivityTimeoutDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognitionConfig_VoiceActivityTimeoutDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognitionConfig_VoiceActivityTimeoutDefaultTypeInternal() {}
  union {
    StreamingRecognitionConfig_VoiceActivityTimeout _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognitionConfig_VoiceActivityTimeoutDefaultTypeInternal _StreamingRecognitionConfig_VoiceActivityTimeout_default_instance_;

inline constexpr LongRunningRecognizeMetadata::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        uri_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        start_time_{nullptr},
        last_update_time_{nullptr},
        progress_percent_{0} {}

template <typename>
PROTOBUF_CONSTEXPR LongRunningRecognizeMetadata::LongRunningRecognizeMetadata(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct LongRunningRecognizeMetadataDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LongRunningRecognizeMetadataDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~LongRunningRecognizeMetadataDefaultTypeInternal() {}
  union {
    LongRunningRecognizeMetadata _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LongRunningRecognizeMetadataDefaultTypeInternal _LongRunningRecognizeMetadata_default_instance_;

inline constexpr SpeechRecognitionAlternative::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : words_{},
        transcript_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        confidence_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechRecognitionAlternative::SpeechRecognitionAlternative(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeechRecognitionAlternativeDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechRecognitionAlternativeDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechRecognitionAlternativeDefaultTypeInternal() {}
  union {
    SpeechRecognitionAlternative _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechRecognitionAlternativeDefaultTypeInternal _SpeechRecognitionAlternative_default_instance_;

inline constexpr StreamingRecognitionResult::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        alternatives_{},
        language_code_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        result_end_time_{nullptr},
        is_final_{false},
        stability_{0},
        channel_tag_{0} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognitionResult::StreamingRecognitionResult(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognitionResultDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognitionResultDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognitionResultDefaultTypeInternal() {}
  union {
    StreamingRecognitionResult _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognitionResultDefaultTypeInternal _StreamingRecognitionResult_default_instance_;

inline constexpr SpeechRecognitionResult::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        alternatives_{},
        language_code_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        result_end_time_{nullptr},
        channel_tag_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechRecognitionResult::SpeechRecognitionResult(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeechRecognitionResultDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechRecognitionResultDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechRecognitionResultDefaultTypeInternal() {}
  union {
    SpeechRecognitionResult _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechRecognitionResultDefaultTypeInternal _SpeechRecognitionResult_default_instance_;

inline constexpr RecognitionConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        speech_contexts_{},
        alternative_language_codes_{},
        language_code_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        model_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        metadata_{nullptr},
        diarization_config_{nullptr},
        adaptation_{nullptr},
        enable_spoken_punctuation_{nullptr},
        enable_spoken_emojis_{nullptr},
        transcript_normalization_{nullptr},
        encoding_{static_cast< ::google::cloud::speech::v1::RecognitionConfig_AudioEncoding >(0)},
        sample_rate_hertz_{0},
        max_alternatives_{0},
        audio_channel_count_{0},
        enable_separate_recognition_per_channel_{false},
        profanity_filter_{false},
        enable_word_time_offsets_{false},
        enable_word_confidence_{false},
        enable_automatic_punctuation_{false},
        use_enhanced_{false} {}

template <typename>
PROTOBUF_CONSTEXPR RecognitionConfig::RecognitionConfig(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognitionConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognitionConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognitionConfigDefaultTypeInternal() {}
  union {
    RecognitionConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognitionConfigDefaultTypeInternal _RecognitionConfig_default_instance_;

inline constexpr StreamingRecognizeResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        results_{},
        error_{nullptr},
        total_billed_time_{nullptr},
        speech_event_time_{nullptr},
        speech_adaptation_info_{nullptr},
        request_id_{::int64_t{0}},
        speech_event_type_{static_cast< ::google::cloud::speech::v1::StreamingRecognizeResponse_SpeechEventType >(0)} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognizeResponse::StreamingRecognizeResponse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognizeResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognizeResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognizeResponseDefaultTypeInternal() {}
  union {
    StreamingRecognizeResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognizeResponseDefaultTypeInternal _StreamingRecognizeResponse_default_instance_;

inline constexpr StreamingRecognitionConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        config_{nullptr},
        voice_activity_timeout_{nullptr},
        single_utterance_{false},
        interim_results_{false},
        enable_voice_activity_events_{false} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognitionConfig::StreamingRecognitionConfig(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognitionConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognitionConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognitionConfigDefaultTypeInternal() {}
  union {
    StreamingRecognitionConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognitionConfigDefaultTypeInternal _StreamingRecognitionConfig_default_instance_;

inline constexpr RecognizeResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        results_{},
        total_billed_time_{nullptr},
        speech_adaptation_info_{nullptr},
        request_id_{::int64_t{0}} {}

template <typename>
PROTOBUF_CONSTEXPR RecognizeResponse::RecognizeResponse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognizeResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognizeResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognizeResponseDefaultTypeInternal() {}
  union {
    RecognizeResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognizeResponseDefaultTypeInternal _RecognizeResponse_default_instance_;

inline constexpr RecognizeRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        config_{nullptr},
        audio_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR RecognizeRequest::RecognizeRequest(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognizeRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognizeRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognizeRequestDefaultTypeInternal() {}
  union {
    RecognizeRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognizeRequestDefaultTypeInternal _RecognizeRequest_default_instance_;

inline constexpr LongRunningRecognizeResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        results_{},
        total_billed_time_{nullptr},
        output_config_{nullptr},
        output_error_{nullptr},
        speech_adaptation_info_{nullptr},
        request_id_{::int64_t{0}} {}

template <typename>
PROTOBUF_CONSTEXPR LongRunningRecognizeResponse::LongRunningRecognizeResponse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct LongRunningRecognizeResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LongRunningRecognizeResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~LongRunningRecognizeResponseDefaultTypeInternal() {}
  union {
    LongRunningRecognizeResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LongRunningRecognizeResponseDefaultTypeInternal _LongRunningRecognizeResponse_default_instance_;

inline constexpr LongRunningRecognizeRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        config_{nullptr},
        audio_{nullptr},
        output_config_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR LongRunningRecognizeRequest::LongRunningRecognizeRequest(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct LongRunningRecognizeRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LongRunningRecognizeRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~LongRunningRecognizeRequestDefaultTypeInternal() {}
  union {
    LongRunningRecognizeRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LongRunningRecognizeRequestDefaultTypeInternal _LongRunningRecognizeRequest_default_instance_;

inline constexpr StreamingRecognizeRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : streaming_request_{},
        _cached_size_{0},
        _oneof_case_{} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognizeRequest::StreamingRecognizeRequest(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognizeRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognizeRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognizeRequestDefaultTypeInternal() {}
  union {
    StreamingRecognizeRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognizeRequestDefaultTypeInternal _StreamingRecognizeRequest_default_instance_;
}  // namespace v1
}  // namespace speech
}  // namespace cloud
}  // namespace google
static const ::_pb::EnumDescriptor* file_level_enum_descriptors_cloud_5fspeech_2eproto[6];
static constexpr const ::_pb::ServiceDescriptor**
    file_level_service_descriptors_cloud_5fspeech_2eproto = nullptr;
const ::uint32_t
    TableStruct_cloud_5fspeech_2eproto::offsets[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
        protodesc_cold) = {
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeRequest, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeRequest, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeRequest, _impl_.config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeRequest, _impl_.audio_),
        0,
        1,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _impl_.config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _impl_.audio_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _impl_.output_config_),
        0,
        1,
        2,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::TranscriptOutputConfig, _internal_metadata_),
        ~0u,  // no _extensions_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::TranscriptOutputConfig, _impl_._oneof_case_[0]),
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        ::_pbi::kInvalidFieldOffsetTag,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::TranscriptOutputConfig, _impl_.output_type_),
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _internal_metadata_),
        ~0u,  // no _extensions_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _impl_._oneof_case_[0]),
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        ::_pbi::kInvalidFieldOffsetTag,
        ::_pbi::kInvalidFieldOffsetTag,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _impl_.streaming_request_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_start_timeout_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_end_timeout_),
        0,
        1,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.single_utterance_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.interim_results_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.enable_voice_activity_events_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.voice_activity_timeout_),
        0,
        ~0u,
        ~0u,
        ~0u,
        1,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.encoding_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.sample_rate_hertz_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.audio_channel_count_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_separate_recognition_per_channel_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.language_code_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.alternative_language_codes_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.max_alternatives_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.profanity_filter_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.adaptation_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.transcript_normalization_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.speech_contexts_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_word_time_offsets_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_word_confidence_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_automatic_punctuation_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_spoken_punctuation_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_spoken_emojis_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.diarization_config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.metadata_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.model_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.use_enhanced_),
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        2,
        5,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        3,
        4,
        1,
        0,
        ~0u,
        ~0u,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_.min_speaker_count_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_.max_speaker_count_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_.speaker_tag_),
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.interaction_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.industry_naics_code_of_audio_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.microphone_distance_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.original_media_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.recording_device_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.recording_device_name_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.original_mime_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.audio_topic_),
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechContext, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechContext, _impl_.phrases_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechContext, _impl_.boost_),
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _internal_metadata_),
        ~0u,  // no _extensions_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _impl_._oneof_case_[0]),
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        ::_pbi::kInvalidFieldOffsetTag,
        ::_pbi::kInvalidFieldOffsetTag,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _impl_.audio_source_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_.results_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_.total_billed_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_.speech_adaptation_info_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_.request_id_),
        ~0u,
        0,
        1,
        ~0u,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.results_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.total_billed_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.output_config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.output_error_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.speech_adaptation_info_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.request_id_),
        ~0u,
        0,
        1,
        2,
        3,
        ~0u,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_.progress_percent_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_.start_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_.last_update_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_.uri_),
        ~0u,
        0,
        1,
        ~0u,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.error_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.results_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.speech_event_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.speech_event_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.total_billed_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.speech_adaptation_info_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.request_id_),
        0,
        ~0u,
        ~0u,
        2,
        1,
        3,
        ~0u,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.alternatives_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.is_final_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.stability_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.result_end_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.channel_tag_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.language_code_),
        ~0u,
        ~0u,
        ~0u,
        0,
        ~0u,
        ~0u,
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_.alternatives_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_.channel_tag_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_.result_end_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_.language_code_),
        ~0u,
        ~0u,
        0,
        ~0u,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionAlternative, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionAlternative, _impl_.transcript_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionAlternative, _impl_.confidence_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionAlternative, _impl_.words_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.start_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.end_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.word_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.confidence_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.speaker_tag_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.speaker_label_),
        0,
        1,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechAdaptationInfo, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechAdaptationInfo, _impl_.adaptation_timeout_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechAdaptationInfo, _impl_.timeout_message_),
};

static const ::_pbi::MigrationSchema
    schemas[] ABSL_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
        {0, 10, -1, sizeof(::google::cloud::speech::v1::RecognizeRequest)},
        {12, 23, -1, sizeof(::google::cloud::speech::v1::LongRunningRecognizeRequest)},
        {26, -1, -1, sizeof(::google::cloud::speech::v1::TranscriptOutputConfig)},
        {36, -1, -1, sizeof(::google::cloud::speech::v1::StreamingRecognizeRequest)},
        {47, 57, -1, sizeof(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout)},
        {59, 72, -1, sizeof(::google::cloud::speech::v1::StreamingRecognitionConfig)},
        {77, 105, -1, sizeof(::google::cloud::speech::v1::RecognitionConfig)},
        {125, -1, -1, sizeof(::google::cloud::speech::v1::SpeakerDiarizationConfig)},
        {137, -1, -1, sizeof(::google::cloud::speech::v1::RecognitionMetadata)},
        {153, -1, -1, sizeof(::google::cloud::speech::v1::SpeechContext)},
        {163, -1, -1, sizeof(::google::cloud::speech::v1::RecognitionAudio)},
        {174, 186, -1, sizeof(::google::cloud::speech::v1::RecognizeResponse)},
        {190, 204, -1, sizeof(::google::cloud::speech::v1::LongRunningRecognizeResponse)},
        {210, 222, -1, sizeof(::google::cloud::speech::v1::LongRunningRecognizeMetadata)},
        {226, 241, -1, sizeof(::google::cloud::speech::v1::StreamingRecognizeResponse)},
        {248, 262, -1, sizeof(::google::cloud::speech::v1::StreamingRecognitionResult)},
        {268, 280, -1, sizeof(::google::cloud::speech::v1::SpeechRecognitionResult)},
        {284, -1, -1, sizeof(::google::cloud::speech::v1::SpeechRecognitionAlternative)},
        {295, 309, -1, sizeof(::google::cloud::speech::v1::WordInfo)},
        {315, -1, -1, sizeof(::google::cloud::speech::v1::SpeechAdaptationInfo)},
};
static const ::_pb::Message* const file_default_instances[] = {
    &::google::cloud::speech::v1::_RecognizeRequest_default_instance_._instance,
    &::google::cloud::speech::v1::_LongRunningRecognizeRequest_default_instance_._instance,
    &::google::cloud::speech::v1::_TranscriptOutputConfig_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognizeRequest_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognitionConfig_VoiceActivityTimeout_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognitionConfig_default_instance_._instance,
    &::google::cloud::speech::v1::_RecognitionConfig_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeakerDiarizationConfig_default_instance_._instance,
    &::google::cloud::speech::v1::_RecognitionMetadata_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeechContext_default_instance_._instance,
    &::google::cloud::speech::v1::_RecognitionAudio_default_instance_._instance,
    &::google::cloud::speech::v1::_RecognizeResponse_default_instance_._instance,
    &::google::cloud::speech::v1::_LongRunningRecognizeResponse_default_instance_._instance,
    &::google::cloud::speech::v1::_LongRunningRecognizeMetadata_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognizeResponse_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognitionResult_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeechRecognitionResult_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeechRecognitionAlternative_default_instance_._instance,
    &::google::cloud::speech::v1::_WordInfo_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeechAdaptationInfo_default_instance_._instance,
};
const char descriptor_table_protodef_cloud_5fspeech_2eproto[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
    protodesc_cold) = {
    "\n\022cloud_speech.proto\022\026google.cloud.speec"
    "h.v1\032\034google/api/annotations.proto\032\027goog"
    "le/api/client.proto\032\037google/api/field_be"
    "havior.proto\032%google/cloud/speech/v1/res"
    "ource.proto\032#google/longrunning/operatio"
    "ns.proto\032\036google/protobuf/duration.proto"
    "\032\037google/protobuf/timestamp.proto\032\036googl"
    "e/protobuf/wrappers.proto\032\027google/rpc/st"
    "atus.proto\"\220\001\n\020RecognizeRequest\022>\n\006confi"
    "g\030\001 \001(\0132).google.cloud.speech.v1.Recogni"
    "tionConfigB\003\340A\002\022<\n\005audio\030\002 \001(\0132(.google."
    "cloud.speech.v1.RecognitionAudioB\003\340A\002\"\347\001"
    "\n\033LongRunningRecognizeRequest\022>\n\006config\030"
    "\001 \001(\0132).google.cloud.speech.v1.Recogniti"
    "onConfigB\003\340A\002\022<\n\005audio\030\002 \001(\0132(.google.cl"
    "oud.speech.v1.RecognitionAudioB\003\340A\002\022J\n\ro"
    "utput_config\030\004 \001(\0132..google.cloud.speech"
    ".v1.TranscriptOutputConfigB\003\340A\001\":\n\026Trans"
    "criptOutputConfig\022\021\n\007gcs_uri\030\001 \001(\tH\000B\r\n\013"
    "output_type\"\231\001\n\031StreamingRecognizeReques"
    "t\022N\n\020streaming_config\030\001 \001(\01322.google.clo"
    "ud.speech.v1.StreamingRecognitionConfigH"
    "\000\022\027\n\raudio_content\030\002 \001(\014H\000B\023\n\021streaming_"
    "request\"\247\003\n\032StreamingRecognitionConfig\022>"
    "\n\006config\030\001 \001(\0132).google.cloud.speech.v1."
    "RecognitionConfigB\003\340A\002\022\030\n\020single_utteran"
    "ce\030\002 \001(\010\022\027\n\017interim_results\030\003 \001(\010\022$\n\034ena"
    "ble_voice_activity_events\030\005 \001(\010\022g\n\026voice"
    "_activity_timeout\030\006 \001(\0132G.google.cloud.s"
    "peech.v1.StreamingRecognitionConfig.Voic"
    "eActivityTimeout\032\206\001\n\024VoiceActivityTimeou"
    "t\0227\n\024speech_start_timeout\030\001 \001(\0132\031.google"
    ".protobuf.Duration\0225\n\022speech_end_timeout"
    "\030\002 \001(\0132\031.google.protobuf.Duration\"\312\010\n\021Re"
    "cognitionConfig\022I\n\010encoding\030\001 \001(\01627.goog"
    "le.cloud.speech.v1.RecognitionConfig.Aud"
    "ioEncoding\022\031\n\021sample_rate_hertz\030\002 \001(\005\022\033\n"
    "\023audio_channel_count\030\007 \001(\005\022/\n\'enable_sep"
    "arate_recognition_per_channel\030\014 \001(\010\022\032\n\rl"
    "anguage_code\030\003 \001(\tB\003\340A\002\022\"\n\032alternative_l"
    "anguage_codes\030\022 \003(\t\022\030\n\020max_alternatives\030"
    "\004 \001(\005\022\030\n\020profanity_filter\030\005 \001(\010\022<\n\nadapt"
    "ation\030\024 \001(\0132(.google.cloud.speech.v1.Spe"
    "echAdaptation\022V\n\030transcript_normalizatio"
    "n\030\030 \001(\0132/.google.cloud.speech.v1.Transcr"
    "iptNormalizationB\003\340A\001\022>\n\017speech_contexts"
    "\030\006 \003(\0132%.google.cloud.speech.v1.SpeechCo"
    "ntext\022 \n\030enable_word_time_offsets\030\010 \001(\010\022"
    "\036\n\026enable_word_confidence\030\017 \001(\010\022$\n\034enabl"
    "e_automatic_punctuation\030\013 \001(\010\022=\n\031enable_"
    "spoken_punctuation\030\026 \001(\0132\032.google.protob"
    "uf.BoolValue\0228\n\024enable_spoken_emojis\030\027 \001"
    "(\0132\032.google.protobuf.BoolValue\022L\n\022diariz"
    "ation_config\030\023 \001(\01320.google.cloud.speech"
    ".v1.SpeakerDiarizationConfig\022=\n\010metadata"
    "\030\t \001(\0132+.google.cloud.speech.v1.Recognit"
    "ionMetadata\022\r\n\005model\030\r \001(\t\022\024\n\014use_enhanc"
    "ed\030\016 \001(\010\"\243\001\n\rAudioEncoding\022\030\n\024ENCODING_U"
    "NSPECIFIED\020\000\022\014\n\010LINEAR16\020\001\022\010\n\004FLAC\020\002\022\t\n\005"
    "MULAW\020\003\022\007\n\003AMR\020\004\022\n\n\006AMR_WB\020\005\022\014\n\010OGG_OPUS"
    "\020\006\022\032\n\026SPEEX_WITH_HEADER_BYTE\020\007\022\007\n\003MP3\020\010\022"
    "\r\n\tWEBM_OPUS\020\t\"\220\001\n\030SpeakerDiarizationCon"
    "fig\022\"\n\032enable_speaker_diarization\030\001 \001(\010\022"
    "\031\n\021min_speaker_count\030\002 \001(\005\022\031\n\021max_speake"
    "r_count\030\003 \001(\005\022\032\n\013speaker_tag\030\005 \001(\005B\005\030\001\340A"
    "\003\"\244\010\n\023RecognitionMetadata\022U\n\020interaction"
    "_type\030\001 \001(\0162;.google.cloud.speech.v1.Rec"
    "ognitionMetadata.InteractionType\022$\n\034indu"
    "stry_naics_code_of_audio\030\003 \001(\r\022[\n\023microp"
    "hone_distance\030\004 \001(\0162>.google.cloud.speec"
    "h.v1.RecognitionMetadata.MicrophoneDista"
    "nce\022Z\n\023original_media_type\030\005 \001(\0162=.googl"
    "e.cloud.speech.v1.RecognitionMetadata.Or"
    "iginalMediaType\022^\n\025recording_device_type"
    "\030\006 \001(\0162\?.google.cloud.speech.v1.Recognit"
    "ionMetadata.RecordingDeviceType\022\035\n\025recor"
    "ding_device_name\030\007 \001(\t\022\032\n\022original_mime_"
    "type\030\010 \001(\t\022\023\n\013audio_topic\030\n \001(\t\"\305\001\n\017Inte"
    "ractionType\022 \n\034INTERACTION_TYPE_UNSPECIF"
    "IED\020\000\022\016\n\nDISCUSSION\020\001\022\020\n\014PRESENTATION\020\002\022"
    "\016\n\nPHONE_CALL\020\003\022\r\n\tVOICEMAIL\020\004\022\033\n\027PROFES"
    "SIONALLY_PRODUCED\020\005\022\020\n\014VOICE_SEARCH\020\006\022\021\n"
    "\rVOICE_COMMAND\020\007\022\r\n\tDICTATION\020\010\"d\n\022Micro"
    "phoneDistance\022#\n\037MICROPHONE_DISTANCE_UNS"
    "PECIFIED\020\000\022\r\n\tNEARFIELD\020\001\022\014\n\010MIDFIELD\020\002\022"
    "\014\n\010FARFIELD\020\003\"N\n\021OriginalMediaType\022#\n\037OR"
    "IGINAL_MEDIA_TYPE_UNSPECIFIED\020\000\022\t\n\005AUDIO"
    "\020\001\022\t\n\005VIDEO\020\002\"\244\001\n\023RecordingDeviceType\022%\n"
    "!RECORDING_DEVICE_TYPE_UNSPECIFIED\020\000\022\016\n\n"
    "SMARTPHONE\020\001\022\006\n\002PC\020\002\022\016\n\nPHONE_LINE\020\003\022\013\n\007"
    "VEHICLE\020\004\022\030\n\024OTHER_OUTDOOR_DEVICE\020\005\022\027\n\023O"
    "THER_INDOOR_DEVICE\020\006:\002\030\001\"/\n\rSpeechContex"
    "t\022\017\n\007phrases\030\001 \003(\t\022\r\n\005boost\030\004 \001(\002\"D\n\020Rec"
    "ognitionAudio\022\021\n\007content\030\001 \001(\014H\000\022\r\n\003uri\030"
    "\002 \001(\tH\000B\016\n\014audio_source\"\355\001\n\021RecognizeRes"
    "ponse\022@\n\007results\030\002 \003(\0132/.google.cloud.sp"
    "eech.v1.SpeechRecognitionResult\0224\n\021total"
    "_billed_time\030\003 \001(\0132\031.google.protobuf.Dur"
    "ation\022L\n\026speech_adaptation_info\030\007 \001(\0132,."
    "google.cloud.speech.v1.SpeechAdaptationI"
    "nfo\022\022\n\nrequest_id\030\010 \001(\003\"\351\002\n\034LongRunningR"
    "ecognizeResponse\022@\n\007results\030\002 \003(\0132/.goog"
    "le.cloud.speech.v1.SpeechRecognitionResu"
    "lt\0224\n\021total_billed_time\030\003 \001(\0132\031.google.p"
    "rotobuf.Duration\022E\n\routput_config\030\006 \001(\0132"
    "..google.cloud.speech.v1.TranscriptOutpu"
    "tConfig\022(\n\014output_error\030\007 \001(\0132\022.google.r"
    "pc.Status\022L\n\026speech_adaptation_info\030\010 \001("
    "\0132,.google.cloud.speech.v1.SpeechAdaptat"
    "ionInfo\022\022\n\nrequest_id\030\t \001(\003\"\260\001\n\034LongRunn"
    "ingRecognizeMetadata\022\030\n\020progress_percent"
    "\030\001 \001(\005\022.\n\nstart_time\030\002 \001(\0132\032.google.prot"
    "obuf.Timestamp\0224\n\020last_update_time\030\003 \001(\013"
    "2\032.google.protobuf.Timestamp\022\020\n\003uri\030\004 \001("
    "\tB\003\340A\003\"\321\004\n\032StreamingRecognizeResponse\022!\n"
    "\005error\030\001 \001(\0132\022.google.rpc.Status\022C\n\007resu"
    "lts\030\002 \003(\01322.google.cloud.speech.v1.Strea"
    "mingRecognitionResult\022]\n\021speech_event_ty"
    "pe\030\004 \001(\0162B.google.cloud.speech.v1.Stream"
    "ingRecognizeResponse.SpeechEventType\0224\n\021"
    "speech_event_time\030\010 \001(\0132\031.google.protobu"
    "f.Duration\0224\n\021total_billed_time\030\005 \001(\0132\031."
    "google.protobuf.Duration\022L\n\026speech_adapt"
    "ation_info\030\t \001(\0132,.google.cloud.speech.v"
    "1.SpeechAdaptationInfo\022\022\n\nrequest_id\030\n \001"
    "(\003\"\235\001\n\017SpeechEventType\022\034\n\030SPEECH_EVENT_U"
    "NSPECIFIED\020\000\022\033\n\027END_OF_SINGLE_UTTERANCE\020"
    "\001\022\031\n\025SPEECH_ACTIVITY_BEGIN\020\002\022\027\n\023SPEECH_A"
    "CTIVITY_END\020\003\022\033\n\027SPEECH_ACTIVITY_TIMEOUT"
    "\020\004\"\362\001\n\032StreamingRecognitionResult\022J\n\014alt"
    "ernatives\030\001 \003(\01324.google.cloud.speech.v1"
    ".SpeechRecognitionAlternative\022\020\n\010is_fina"
    "l\030\002 \001(\010\022\021\n\tstability\030\003 \001(\002\0222\n\017result_end"
    "_time\030\004 \001(\0132\031.google.protobuf.Duration\022\023"
    "\n\013channel_tag\030\005 \001(\005\022\032\n\rlanguage_code\030\006 \001"
    "(\tB\003\340A\003\"\312\001\n\027SpeechRecognitionResult\022J\n\014a"
    "lternatives\030\001 \003(\01324.google.cloud.speech."
    "v1.SpeechRecognitionAlternative\022\023\n\013chann"
    "el_tag\030\002 \001(\005\0222\n\017result_end_time\030\004 \001(\0132\031."
    "google.protobuf.Duration\022\032\n\rlanguage_cod"
    "e\030\005 \001(\tB\003\340A\003\"w\n\034SpeechRecognitionAlterna"
    "tive\022\022\n\ntranscript\030\001 \001(\t\022\022\n\nconfidence\030\002"
    " \001(\002\022/\n\005words\030\003 \003(\0132 .google.cloud.speec"
    "h.v1.WordInfo\"\300\001\n\010WordInfo\022-\n\nstart_time"
    "\030\001 \001(\0132\031.google.protobuf.Duration\022+\n\010end"
    "_time\030\002 \001(\0132\031.google.protobuf.Duration\022\014"
    "\n\004word\030\003 \001(\t\022\022\n\nconfidence\030\004 \001(\002\022\032\n\013spea"
    "ker_tag\030\005 \001(\005B\005\030\001\340A\003\022\032\n\rspeaker_label\030\006 "
    "\001(\tB\003\340A\003\"K\n\024SpeechAdaptationInfo\022\032\n\022adap"
    "tation_timeout\030\001 \001(\010\022\027\n\017timeout_message\030"
    "\004 \001(\t2\321\004\n\006Speech\022\220\001\n\tRecognize\022(.google."
    "cloud.speech.v1.RecognizeRequest\032).googl"
    "e.cloud.speech.v1.RecognizeResponse\".\332A\014"
    "config,audio\202\323\344\223\002\031\"\024/v1/speech:recognize"
    ":\001*\022\344\001\n\024LongRunningRecognize\0223.google.cl"
    "oud.speech.v1.LongRunningRecognizeReques"
    "t\032\035.google.longrunning.Operation\"x\312A<\n\034L"
    "ongRunningRecognizeResponse\022\034LongRunning"
    "RecognizeMetadata\332A\014config,audio\202\323\344\223\002$\"\037"
    "/v1/speech:longrunningrecognize:\001*\022\201\001\n\022S"
    "treamingRecognize\0221.google.cloud.speech."
    "v1.StreamingRecognizeRequest\0322.google.cl"
    "oud.speech.v1.StreamingRecognizeResponse"
    "\"\000(\0010\001\032I\312A\025speech.googleapis.com\322A.https"
    "://www.googleapis.com/auth/cloud-platfor"
    "mBh\n\032com.google.cloud.speech.v1B\013SpeechP"
    "rotoP\001Z2cloud.google.com/go/speech/apiv1"
    "/speechpb;speechpb\370\001\001\242\002\003GCSb\006proto3"
};
static const ::_pbi::DescriptorTable* const descriptor_table_cloud_5fspeech_2eproto_deps[9] =
    {
        &::descriptor_table_google_2fapi_2fannotations_2eproto,
        &::descriptor_table_google_2fapi_2fclient_2eproto,
        &::descriptor_table_google_2fapi_2ffield_5fbehavior_2eproto,
        &::descriptor_table_google_2fcloud_2fspeech_2fv1_2fresource_2eproto,
        &::descriptor_table_google_2flongrunning_2foperations_2eproto,
        &::descriptor_table_google_2fprotobuf_2fduration_2eproto,
        &::descriptor_table_google_2fprotobuf_2ftimestamp_2eproto,
        &::descriptor_table_google_2fprotobuf_2fwrappers_2eproto,
        &::descriptor_table_google_2frpc_2fstatus_2eproto,
};
static ::absl::once_flag descriptor_table_cloud_5fspeech_2eproto_once;
PROTOBUF_CONSTINIT const ::_pbi::DescriptorTable descriptor_table_cloud_5fspeech_2eproto = {
    false,
    false,
    6715,
    descriptor_table_protodef_cloud_5fspeech_2eproto,
    "cloud_speech.proto",
    &descriptor_table_cloud_5fspeech_2eproto_once,
    descriptor_table_cloud_5fspeech_2eproto_deps,
    9,
    20,
    schemas,
    file_default_instances,
    TableStruct_cloud_5fspeech_2eproto::offsets,
    file_level_enum_descriptors_cloud_5fspeech_2eproto,
    file_level_service_descriptors_cloud_5fspeech_2eproto,
};
namespace google {
namespace cloud {
namespace speech {
namespace v1 {
const ::google::protobuf::EnumDescriptor* RecognitionConfig_AudioEncoding_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_cloud_5fspeech_2eproto);
  return file_level_enum_descriptors_cloud_5fspeech_2eproto[0];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionConfig_AudioEncoding_internal_data_[] = {
    655360u, 0u, };
bool RecognitionConfig_AudioEncoding_IsValid(int value) {
  return 0 <= value && value <= 9;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr RecognitionConfig_AudioEncoding RecognitionConfig::ENCODING_UNSPECIFIED;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::LINEAR16;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::FLAC;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::MULAW;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::AMR;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::AMR_WB;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::OGG_OPUS;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::SPEEX_WITH_HEADER_BYTE;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::MP3;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::WEBM_OPUS;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::AudioEncoding_MIN;
constexpr RecognitionConfig_AudioEncoding RecognitionConfig::AudioEncoding_MAX;
constexpr int RecognitionConfig::AudioEncoding_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::google::protobuf::EnumDescriptor* RecognitionMetadata_InteractionType_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_cloud_5fspeech_2eproto);
  return file_level_enum_descriptors_cloud_5fspeech_2eproto[1];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionMetadata_InteractionType_internal_data_[] = {
    589824u, 0u, };
bool RecognitionMetadata_InteractionType_IsValid(int value) {
  return 0 <= value && value <= 8;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr RecognitionMetadata_InteractionType RecognitionMetadata::INTERACTION_TYPE_UNSPECIFIED;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::DISCUSSION;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::PRESENTATION;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::PHONE_CALL;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::VOICEMAIL;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::PROFESSIONALLY_PRODUCED;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::VOICE_SEARCH;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::VOICE_COMMAND;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::DICTATION;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::InteractionType_MIN;
constexpr RecognitionMetadata_InteractionType RecognitionMetadata::InteractionType_MAX;
constexpr int RecognitionMetadata::InteractionType_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::google::protobuf::EnumDescriptor* RecognitionMetadata_MicrophoneDistance_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_cloud_5fspeech_2eproto);
  return file_level_enum_descriptors_cloud_5fspeech_2eproto[2];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionMetadata_MicrophoneDistance_internal_data_[] = {
    262144u, 0u, };
bool RecognitionMetadata_MicrophoneDistance_IsValid(int value) {
  return 0 <= value && value <= 3;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr RecognitionMetadata_MicrophoneDistance RecognitionMetadata::MICROPHONE_DISTANCE_UNSPECIFIED;
constexpr RecognitionMetadata_MicrophoneDistance RecognitionMetadata::NEARFIELD;
constexpr RecognitionMetadata_MicrophoneDistance RecognitionMetadata::MIDFIELD;
constexpr RecognitionMetadata_MicrophoneDistance RecognitionMetadata::FARFIELD;
constexpr RecognitionMetadata_MicrophoneDistance RecognitionMetadata::MicrophoneDistance_MIN;
constexpr RecognitionMetadata_MicrophoneDistance RecognitionMetadata::MicrophoneDistance_MAX;
constexpr int RecognitionMetadata::MicrophoneDistance_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::google::protobuf::EnumDescriptor* RecognitionMetadata_OriginalMediaType_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_cloud_5fspeech_2eproto);
  return file_level_enum_descriptors_cloud_5fspeech_2eproto[3];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionMetadata_OriginalMediaType_internal_data_[] = {
    196608u, 0u, };
bool RecognitionMetadata_OriginalMediaType_IsValid(int value) {
  return 0 <= value && value <= 2;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr RecognitionMetadata_OriginalMediaType RecognitionMetadata::ORIGINAL_MEDIA_TYPE_UNSPECIFIED;
constexpr RecognitionMetadata_OriginalMediaType RecognitionMetadata::AUDIO;
constexpr RecognitionMetadata_OriginalMediaType RecognitionMetadata::VIDEO;
constexpr RecognitionMetadata_OriginalMediaType RecognitionMetadata::OriginalMediaType_MIN;
constexpr RecognitionMetadata_OriginalMediaType RecognitionMetadata::OriginalMediaType_MAX;
constexpr int RecognitionMetadata::OriginalMediaType_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::google::protobuf::EnumDescriptor* RecognitionMetadata_RecordingDeviceType_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_cloud_5fspeech_2eproto);
  return file_level_enum_descriptors_cloud_5fspeech_2eproto[4];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionMetadata_RecordingDeviceType_internal_data_[] = {
    458752u, 0u, };
bool RecognitionMetadata_RecordingDeviceType_IsValid(int value) {
  return 0 <= value && value <= 6;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::RECORDING_DEVICE_TYPE_UNSPECIFIED;
constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::SMARTPHONE;
constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::PC;
constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::PHONE_LINE;
constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::VEHICLE;
constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::OTHER_OUTDOOR_DEVICE;
constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::OTHER_INDOOR_DEVICE;
constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::RecordingDeviceType_MIN;
constexpr RecognitionMetadata_RecordingDeviceType RecognitionMetadata::RecordingDeviceType_MAX;
constexpr int RecognitionMetadata::RecordingDeviceType_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::google::protobuf::EnumDescriptor* StreamingRecognizeResponse_SpeechEventType_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_cloud_5fspeech_2eproto);
  return file_level_enum_descriptors_cloud_5fspeech_2eproto[5];
}
PROTOBUF_CONSTINIT const uint32_t StreamingRecognizeResponse_SpeechEventType_internal_data_[] = {
    327680u, 0u, };
bool StreamingRecognizeResponse_SpeechEventType_IsValid(int value) {
  return 0 <= value && value <= 4;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr StreamingRecognizeResponse_SpeechEventType StreamingRecognizeResponse::SPEECH_EVENT_UNSPECIFIED;
constexpr StreamingRecognizeResponse_SpeechEventType StreamingRecognizeResponse::END_OF_SINGLE_UTTERANCE;
constexpr StreamingRecognizeResponse_SpeechEventType StreamingRecognizeResponse::SPEECH_ACTIVITY_BEGIN;
constexpr StreamingRecognizeResponse_SpeechEventType StreamingRecognizeResponse::SPEECH_ACTIVITY_END;
constexpr StreamingRecognizeResponse_SpeechEventType StreamingRecognizeResponse::SPEECH_ACTIVITY_TIMEOUT;
constexpr StreamingRecognizeResponse_SpeechEventType StreamingRecognizeResponse::SpeechEventType_MIN;
constexpr StreamingRecognizeResponse_SpeechEventType StreamingRecognizeResponse::SpeechEventType_MAX;
constexpr int StreamingRecognizeResponse::SpeechEventType_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
// ===================================================================

class RecognizeRequest::_Internal {
 public:
  using HasBits =
      decltype(std::declval<RecognizeRequest>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_._has_bits_);
};

RecognizeRequest::RecognizeRequest(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE RecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::RecognizeRequest& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

RecognizeRequest::RecognizeRequest(
    ::google::protobuf::Arena* arena,
    const RecognizeRequest& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognizeRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.config_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionConfig>(
                              arena, *from._impl_.config_)
                        : nullptr;
  _impl_.audio_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionAudio>(
                              arena, *from._impl_.audio_)
                        : nullptr;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE RecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void RecognizeRequest::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, config_),
           0,
           offsetof(Impl_, audio_) -
               offsetof(Impl_, config_) +
               sizeof(Impl_::audio_));
}
RecognizeRequest::~RecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognizeRequest)
  SharedDtor(*this);
}
inline void RecognizeRequest::SharedDtor(MessageLite& self) {
  RecognizeRequest& this_ = static_cast<RecognizeRequest&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.config_;
  delete this_._impl_.audio_;
  this_._impl_.~Impl_();
}

inline void* RecognizeRequest::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RecognizeRequest(arena);
}
constexpr auto RecognizeRequest::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(RecognizeRequest),
                                            alignof(RecognizeRequest));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RecognizeRequest::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RecognizeRequest_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RecognizeRequest::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RecognizeRequest>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RecognizeRequest::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RecognizeRequest>(), &RecognizeRequest::ByteSizeLong,
            &RecognizeRequest::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_._cached_size_),
        false,
    },
    &RecognizeRequest::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RecognizeRequest::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 2, 0, 2> RecognizeRequest::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognizeRequest>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 1, PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.audio_)}},
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_)}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.audio_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionConfig>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionAudio>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void RecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognizeRequest)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.config_ != nullptr);
      _impl_.config_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.audio_ != nullptr);
      _impl_.audio_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RecognizeRequest::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RecognizeRequest& this_ = static_cast<const RecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RecognizeRequest::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognizeRequest)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                1, *this_._impl_.config_, this_._impl_.config_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                2, *this_._impl_.audio_, this_._impl_.audio_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognizeRequest)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RecognizeRequest::ByteSizeLong(const MessageLite& base) {
          const RecognizeRequest& this_ = static_cast<const RecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RecognizeRequest::ByteSizeLong() const {
          const RecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognizeRequest)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.config_);
            }
            // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.audio_);
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RecognizeRequest::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognizeRequest*>(&to_msg);
  auto& from = static_cast<const RecognizeRequest&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognizeRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.config_ != nullptr);
      if (_this->_impl_.config_ == nullptr) {
        _this->_impl_.config_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionConfig>(arena, *from._impl_.config_);
      } else {
        _this->_impl_.config_->MergeFrom(*from._impl_.config_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.audio_ != nullptr);
      if (_this->_impl_.audio_ == nullptr) {
        _this->_impl_.audio_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionAudio>(arena, *from._impl_.audio_);
      } else {
        _this->_impl_.audio_->MergeFrom(*from._impl_.audio_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognizeRequest::CopyFrom(const RecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognizeRequest::InternalSwap(RecognizeRequest* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.audio_)
      + sizeof(RecognizeRequest::_impl_.audio_)
      - PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_)>(
          reinterpret_cast<char*>(&_impl_.config_),
          reinterpret_cast<char*>(&other->_impl_.config_));
}

::google::protobuf::Metadata RecognizeRequest::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class LongRunningRecognizeRequest::_Internal {
 public:
  using HasBits =
      decltype(std::declval<LongRunningRecognizeRequest>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_._has_bits_);
};

LongRunningRecognizeRequest::LongRunningRecognizeRequest(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.LongRunningRecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE LongRunningRecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::LongRunningRecognizeRequest& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

LongRunningRecognizeRequest::LongRunningRecognizeRequest(
    ::google::protobuf::Arena* arena,
    const LongRunningRecognizeRequest& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  LongRunningRecognizeRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.config_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionConfig>(
                              arena, *from._impl_.config_)
                        : nullptr;
  _impl_.audio_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionAudio>(
                              arena, *from._impl_.audio_)
                        : nullptr;
  _impl_.output_config_ = (cached_has_bits & 0x00000004u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::TranscriptOutputConfig>(
                              arena, *from._impl_.output_config_)
                        : nullptr;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.LongRunningRecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE LongRunningRecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void LongRunningRecognizeRequest::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, config_),
           0,
           offsetof(Impl_, output_config_) -
               offsetof(Impl_, config_) +
               sizeof(Impl_::output_config_));
}
LongRunningRecognizeRequest::~LongRunningRecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.LongRunningRecognizeRequest)
  SharedDtor(*this);
}
inline void LongRunningRecognizeRequest::SharedDtor(MessageLite& self) {
  LongRunningRecognizeRequest& this_ = static_cast<LongRunningRecognizeRequest&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.config_;
  delete this_._impl_.audio_;
  delete this_._impl_.output_config_;
  this_._impl_.~Impl_();
}

inline void* LongRunningRecognizeRequest::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) LongRunningRecognizeRequest(arena);
}
constexpr auto LongRunningRecognizeRequest::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(LongRunningRecognizeRequest),
                                            alignof(LongRunningRecognizeRequest));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull LongRunningRecognizeRequest::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_LongRunningRecognizeRequest_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &LongRunningRecognizeRequest::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<LongRunningRecognizeRequest>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &LongRunningRecognizeRequest::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<LongRunningRecognizeRequest>(), &LongRunningRecognizeRequest::ByteSizeLong,
            &LongRunningRecognizeRequest::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_._cached_size_),
        false,
    },
    &LongRunningRecognizeRequest::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* LongRunningRecognizeRequest::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 3, 0, 2> LongRunningRecognizeRequest::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_._has_bits_),
    0, // no _extensions_
    4, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967284,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    3,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::LongRunningRecognizeRequest>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 4 [(.google.api.field_behavior) = OPTIONAL];
    {::_pbi::TcParser::FastMtS1,
     {34, 2, 2, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.output_config_)}},
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.config_)}},
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 1, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.audio_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.config_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.audio_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 4 [(.google.api.field_behavior) = OPTIONAL];
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.output_config_), _Internal::kHasBitsOffset + 2, 2,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionConfig>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionAudio>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::TranscriptOutputConfig>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void LongRunningRecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.config_ != nullptr);
      _impl_.config_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.audio_ != nullptr);
      _impl_.audio_->Clear();
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(_impl_.output_config_ != nullptr);
      _impl_.output_config_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* LongRunningRecognizeRequest::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const LongRunningRecognizeRequest& this_ = static_cast<const LongRunningRecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* LongRunningRecognizeRequest::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const LongRunningRecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                1, *this_._impl_.config_, this_._impl_.config_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                2, *this_._impl_.audio_, this_._impl_.audio_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 4 [(.google.api.field_behavior) = OPTIONAL];
          if (cached_has_bits & 0x00000004u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                4, *this_._impl_.output_config_, this_._impl_.output_config_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.LongRunningRecognizeRequest)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t LongRunningRecognizeRequest::ByteSizeLong(const MessageLite& base) {
          const LongRunningRecognizeRequest& this_ = static_cast<const LongRunningRecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t LongRunningRecognizeRequest::ByteSizeLong() const {
          const LongRunningRecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000007u) {
            // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.config_);
            }
            // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.audio_);
            }
            // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 4 [(.google.api.field_behavior) = OPTIONAL];
            if (cached_has_bits & 0x00000004u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.output_config_);
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void LongRunningRecognizeRequest::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<LongRunningRecognizeRequest*>(&to_msg);
  auto& from = static_cast<const LongRunningRecognizeRequest&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.config_ != nullptr);
      if (_this->_impl_.config_ == nullptr) {
        _this->_impl_.config_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionConfig>(arena, *from._impl_.config_);
      } else {
        _this->_impl_.config_->MergeFrom(*from._impl_.config_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.audio_ != nullptr);
      if (_this->_impl_.audio_ == nullptr) {
        _this->_impl_.audio_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionAudio>(arena, *from._impl_.audio_);
      } else {
        _this->_impl_.audio_->MergeFrom(*from._impl_.audio_);
      }
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(from._impl_.output_config_ != nullptr);
      if (_this->_impl_.output_config_ == nullptr) {
        _this->_impl_.output_config_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::TranscriptOutputConfig>(arena, *from._impl_.output_config_);
      } else {
        _this->_impl_.output_config_->MergeFrom(*from._impl_.output_config_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void LongRunningRecognizeRequest::CopyFrom(const LongRunningRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void LongRunningRecognizeRequest::InternalSwap(LongRunningRecognizeRequest* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.output_config_)
      + sizeof(LongRunningRecognizeRequest::_impl_.output_config_)
      - PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.config_)>(
          reinterpret_cast<char*>(&_impl_.config_),
          reinterpret_cast<char*>(&other->_impl_.config_));
}

::google::protobuf::Metadata LongRunningRecognizeRequest::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class TranscriptOutputConfig::_Internal {
 public:
  static constexpr ::int32_t kOneofCaseOffset =
      PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::TranscriptOutputConfig, _impl_._oneof_case_);
};

TranscriptOutputConfig::TranscriptOutputConfig(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.TranscriptOutputConfig)
}
inline PROTOBUF_NDEBUG_INLINE TranscriptOutputConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::TranscriptOutputConfig& from_msg)
      : output_type_{},
        _cached_size_{0},
        _oneof_case_{from._oneof_case_[0]} {}

TranscriptOutputConfig::TranscriptOutputConfig(
    ::google::protobuf::Arena* arena,
    const TranscriptOutputConfig& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  TranscriptOutputConfig* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  switch (output_type_case()) {
    case OUTPUT_TYPE_NOT_SET:
      break;
      case kGcsUri:
        new (&_impl_.output_type_.gcs_uri_) decltype(_impl_.output_type_.gcs_uri_){arena, from._impl_.output_type_.gcs_uri_};
        break;
  }

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.TranscriptOutputConfig)
}
inline PROTOBUF_NDEBUG_INLINE TranscriptOutputConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : output_type_{},
        _cached_size_{0},
        _oneof_case_{} {}

inline void TranscriptOutputConfig::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
TranscriptOutputConfig::~TranscriptOutputConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.TranscriptOutputConfig)
  SharedDtor(*this);
}
inline void TranscriptOutputConfig::SharedDtor(MessageLite& self) {
  TranscriptOutputConfig& this_ = static_cast<TranscriptOutputConfig&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  if (this_.has_output_type()) {
    this_.clear_output_type();
  }
  this_._impl_.~Impl_();
}

void TranscriptOutputConfig::clear_output_type() {
// @@protoc_insertion_point(one_of_clear_start:google.cloud.speech.v1.TranscriptOutputConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  switch (output_type_case()) {
    case kGcsUri: {
      _impl_.output_type_.gcs_uri_.Destroy();
      break;
    }
    case OUTPUT_TYPE_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = OUTPUT_TYPE_NOT_SET;
}


inline void* TranscriptOutputConfig::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) TranscriptOutputConfig(arena);
}
constexpr auto TranscriptOutputConfig::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(TranscriptOutputConfig),
                                            alignof(TranscriptOutputConfig));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull TranscriptOutputConfig::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_TranscriptOutputConfig_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &TranscriptOutputConfig::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<TranscriptOutputConfig>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &TranscriptOutputConfig::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<TranscriptOutputConfig>(), &TranscriptOutputConfig::ByteSizeLong,
            &TranscriptOutputConfig::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(TranscriptOutputConfig, _impl_._cached_size_),
        false,
    },
    &TranscriptOutputConfig::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* TranscriptOutputConfig::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 1, 0, 61, 2> TranscriptOutputConfig::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    1, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    1,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::TranscriptOutputConfig>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // string gcs_uri = 1;
    {PROTOBUF_FIELD_OFFSET(TranscriptOutputConfig, _impl_.output_type_.gcs_uri_), _Internal::kOneofCaseOffset + 0, 0,
    (0 | ::_fl::kFcOneof | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\55\7\0\0\0\0\0\0"
    "google.cloud.speech.v1.TranscriptOutputConfig"
    "gcs_uri"
  }},
};

PROTOBUF_NOINLINE void TranscriptOutputConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.TranscriptOutputConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_output_type();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* TranscriptOutputConfig::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const TranscriptOutputConfig& this_ = static_cast<const TranscriptOutputConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* TranscriptOutputConfig::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const TranscriptOutputConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.TranscriptOutputConfig)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // string gcs_uri = 1;
          if (this_.output_type_case() == kGcsUri) {
            const std::string& _s = this_._internal_gcs_uri();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.TranscriptOutputConfig.gcs_uri");
            target = stream->WriteStringMaybeAliased(1, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.TranscriptOutputConfig)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t TranscriptOutputConfig::ByteSizeLong(const MessageLite& base) {
          const TranscriptOutputConfig& this_ = static_cast<const TranscriptOutputConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t TranscriptOutputConfig::ByteSizeLong() const {
          const TranscriptOutputConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.TranscriptOutputConfig)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          switch (this_.output_type_case()) {
            // string gcs_uri = 1;
            case kGcsUri: {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_gcs_uri());
              break;
            }
            case OUTPUT_TYPE_NOT_SET: {
              break;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void TranscriptOutputConfig::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<TranscriptOutputConfig*>(&to_msg);
  auto& from = static_cast<const TranscriptOutputConfig&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.TranscriptOutputConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (const uint32_t oneof_from_case = from._impl_._oneof_case_[0]) {
    const uint32_t oneof_to_case = _this->_impl_._oneof_case_[0];
    const bool oneof_needs_init = oneof_to_case != oneof_from_case;
    if (oneof_needs_init) {
      if (oneof_to_case != 0) {
        _this->clear_output_type();
      }
      _this->_impl_._oneof_case_[0] = oneof_from_case;
    }

    switch (oneof_from_case) {
      case kGcsUri: {
        if (oneof_needs_init) {
          _this->_impl_.output_type_.gcs_uri_.InitDefault();
        }
        _this->_impl_.output_type_.gcs_uri_.Set(from._internal_gcs_uri(), arena);
        break;
      }
      case OUTPUT_TYPE_NOT_SET:
        break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void TranscriptOutputConfig::CopyFrom(const TranscriptOutputConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.TranscriptOutputConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void TranscriptOutputConfig::InternalSwap(TranscriptOutputConfig* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.output_type_, other->_impl_.output_type_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::google::protobuf::Metadata TranscriptOutputConfig::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognizeRequest::_Internal {
 public:
  static constexpr ::int32_t kOneofCaseOffset =
      PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _impl_._oneof_case_);
};

void StreamingRecognizeRequest::set_allocated_streaming_config(::google::cloud::speech::v1::StreamingRecognitionConfig* streaming_config) {
  ::google::protobuf::Arena* message_arena = GetArena();
  clear_streaming_request();
  if (streaming_config) {
    ::google::protobuf::Arena* submessage_arena = streaming_config->GetArena();
    if (message_arena != submessage_arena) {
      streaming_config = ::google::protobuf::internal::GetOwnedMessage(message_arena, streaming_config, submessage_arena);
    }
    set_has_streaming_config();
    _impl_.streaming_request_.streaming_config_ = streaming_config;
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1.StreamingRecognizeRequest.streaming_config)
}
StreamingRecognizeRequest::StreamingRecognizeRequest(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::StreamingRecognizeRequest& from_msg)
      : streaming_request_{},
        _cached_size_{0},
        _oneof_case_{from._oneof_case_[0]} {}

StreamingRecognizeRequest::StreamingRecognizeRequest(
    ::google::protobuf::Arena* arena,
    const StreamingRecognizeRequest& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognizeRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  switch (streaming_request_case()) {
    case STREAMING_REQUEST_NOT_SET:
      break;
      case kStreamingConfig:
        _impl_.streaming_request_.streaming_config_ = ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::StreamingRecognitionConfig>(arena, *from._impl_.streaming_request_.streaming_config_);
        break;
      case kAudioContent:
        new (&_impl_.streaming_request_.audio_content_) decltype(_impl_.streaming_request_.audio_content_){arena, from._impl_.streaming_request_.audio_content_};
        break;
  }

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognizeRequest)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognizeRequest::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : streaming_request_{},
        _cached_size_{0},
        _oneof_case_{} {}

inline void StreamingRecognizeRequest::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
StreamingRecognizeRequest::~StreamingRecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognizeRequest)
  SharedDtor(*this);
}
inline void StreamingRecognizeRequest::SharedDtor(MessageLite& self) {
  StreamingRecognizeRequest& this_ = static_cast<StreamingRecognizeRequest&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  if (this_.has_streaming_request()) {
    this_.clear_streaming_request();
  }
  this_._impl_.~Impl_();
}

void StreamingRecognizeRequest::clear_streaming_request() {
// @@protoc_insertion_point(one_of_clear_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  switch (streaming_request_case()) {
    case kStreamingConfig: {
      if (GetArena() == nullptr) {
        delete _impl_.streaming_request_.streaming_config_;
      } else if (::google::protobuf::internal::DebugHardenClearOneofMessageOnArena()) {
        ::google::protobuf::internal::MaybePoisonAfterClear(_impl_.streaming_request_.streaming_config_);
      }
      break;
    }
    case kAudioContent: {
      _impl_.streaming_request_.audio_content_.Destroy();
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = STREAMING_REQUEST_NOT_SET;
}


inline void* StreamingRecognizeRequest::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) StreamingRecognizeRequest(arena);
}
constexpr auto StreamingRecognizeRequest::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(StreamingRecognizeRequest),
                                            alignof(StreamingRecognizeRequest));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull StreamingRecognizeRequest::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_StreamingRecognizeRequest_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &StreamingRecognizeRequest::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<StreamingRecognizeRequest>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &StreamingRecognizeRequest::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<StreamingRecognizeRequest>(), &StreamingRecognizeRequest::ByteSizeLong,
            &StreamingRecognizeRequest::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_._cached_size_),
        false,
    },
    &StreamingRecognizeRequest::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* StreamingRecognizeRequest::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 2, 1, 0, 2> StreamingRecognizeRequest::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognizeRequest>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_.streaming_request_.streaming_config_), _Internal::kOneofCaseOffset + 0, 0,
    (0 | ::_fl::kFcOneof | ::_fl::kMessage | ::_fl::kTvTable)},
    // bytes audio_content = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_.streaming_request_.audio_content_), _Internal::kOneofCaseOffset + 0, 0,
    (0 | ::_fl::kFcOneof | ::_fl::kBytes | ::_fl::kRepAString)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionConfig>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void StreamingRecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_streaming_request();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* StreamingRecognizeRequest::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const StreamingRecognizeRequest& this_ = static_cast<const StreamingRecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* StreamingRecognizeRequest::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const StreamingRecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognizeRequest)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          switch (this_.streaming_request_case()) {
            case kStreamingConfig: {
              target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                  1, *this_._impl_.streaming_request_.streaming_config_, this_._impl_.streaming_request_.streaming_config_->GetCachedSize(), target,
                  stream);
              break;
            }
            case kAudioContent: {
              const std::string& _s = this_._internal_audio_content();
              target = stream->WriteBytesMaybeAliased(2, _s, target);
              break;
            }
            default:
              break;
          }
          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognizeRequest)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t StreamingRecognizeRequest::ByteSizeLong(const MessageLite& base) {
          const StreamingRecognizeRequest& this_ = static_cast<const StreamingRecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t StreamingRecognizeRequest::ByteSizeLong() const {
          const StreamingRecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognizeRequest)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          switch (this_.streaming_request_case()) {
            // .google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;
            case kStreamingConfig: {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.streaming_request_.streaming_config_);
              break;
            }
            // bytes audio_content = 2;
            case kAudioContent: {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::BytesSize(
                                              this_._internal_audio_content());
              break;
            }
            case STREAMING_REQUEST_NOT_SET: {
              break;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void StreamingRecognizeRequest::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognizeRequest*>(&to_msg);
  auto& from = static_cast<const StreamingRecognizeRequest&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (const uint32_t oneof_from_case = from._impl_._oneof_case_[0]) {
    const uint32_t oneof_to_case = _this->_impl_._oneof_case_[0];
    const bool oneof_needs_init = oneof_to_case != oneof_from_case;
    if (oneof_needs_init) {
      if (oneof_to_case != 0) {
        _this->clear_streaming_request();
      }
      _this->_impl_._oneof_case_[0] = oneof_from_case;
    }

    switch (oneof_from_case) {
      case kStreamingConfig: {
        if (oneof_needs_init) {
          _this->_impl_.streaming_request_.streaming_config_ =
              ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::StreamingRecognitionConfig>(arena, *from._impl_.streaming_request_.streaming_config_);
        } else {
          _this->_impl_.streaming_request_.streaming_config_->MergeFrom(from._internal_streaming_config());
        }
        break;
      }
      case kAudioContent: {
        if (oneof_needs_init) {
          _this->_impl_.streaming_request_.audio_content_.InitDefault();
        }
        _this->_impl_.streaming_request_.audio_content_.Set(from._internal_audio_content(), arena);
        break;
      }
      case STREAMING_REQUEST_NOT_SET:
        break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognizeRequest::CopyFrom(const StreamingRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognizeRequest::InternalSwap(StreamingRecognizeRequest* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.streaming_request_, other->_impl_.streaming_request_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::google::protobuf::Metadata StreamingRecognizeRequest::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognitionConfig_VoiceActivityTimeout::_Internal {
 public:
  using HasBits =
      decltype(std::declval<StreamingRecognitionConfig_VoiceActivityTimeout>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_._has_bits_);
};

void StreamingRecognitionConfig_VoiceActivityTimeout::clear_speech_start_timeout() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.speech_start_timeout_ != nullptr) _impl_.speech_start_timeout_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
void StreamingRecognitionConfig_VoiceActivityTimeout::clear_speech_end_timeout() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.speech_end_timeout_ != nullptr) _impl_.speech_end_timeout_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
StreamingRecognitionConfig_VoiceActivityTimeout::StreamingRecognitionConfig_VoiceActivityTimeout(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig_VoiceActivityTimeout::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

StreamingRecognitionConfig_VoiceActivityTimeout::StreamingRecognitionConfig_VoiceActivityTimeout(
    ::google::protobuf::Arena* arena,
    const StreamingRecognitionConfig_VoiceActivityTimeout& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognitionConfig_VoiceActivityTimeout* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.speech_start_timeout_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.speech_start_timeout_)
                        : nullptr;
  _impl_.speech_end_timeout_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.speech_end_timeout_)
                        : nullptr;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig_VoiceActivityTimeout::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void StreamingRecognitionConfig_VoiceActivityTimeout::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, speech_start_timeout_),
           0,
           offsetof(Impl_, speech_end_timeout_) -
               offsetof(Impl_, speech_start_timeout_) +
               sizeof(Impl_::speech_end_timeout_));
}
StreamingRecognitionConfig_VoiceActivityTimeout::~StreamingRecognitionConfig_VoiceActivityTimeout() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  SharedDtor(*this);
}
inline void StreamingRecognitionConfig_VoiceActivityTimeout::SharedDtor(MessageLite& self) {
  StreamingRecognitionConfig_VoiceActivityTimeout& this_ = static_cast<StreamingRecognitionConfig_VoiceActivityTimeout&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.speech_start_timeout_;
  delete this_._impl_.speech_end_timeout_;
  this_._impl_.~Impl_();
}

inline void* StreamingRecognitionConfig_VoiceActivityTimeout::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) StreamingRecognitionConfig_VoiceActivityTimeout(arena);
}
constexpr auto StreamingRecognitionConfig_VoiceActivityTimeout::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(StreamingRecognitionConfig_VoiceActivityTimeout),
                                            alignof(StreamingRecognitionConfig_VoiceActivityTimeout));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull StreamingRecognitionConfig_VoiceActivityTimeout::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_StreamingRecognitionConfig_VoiceActivityTimeout_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &StreamingRecognitionConfig_VoiceActivityTimeout::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<StreamingRecognitionConfig_VoiceActivityTimeout>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &StreamingRecognitionConfig_VoiceActivityTimeout::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<StreamingRecognitionConfig_VoiceActivityTimeout>(), &StreamingRecognitionConfig_VoiceActivityTimeout::ByteSizeLong,
            &StreamingRecognitionConfig_VoiceActivityTimeout::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_._cached_size_),
        false,
    },
    &StreamingRecognitionConfig_VoiceActivityTimeout::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* StreamingRecognitionConfig_VoiceActivityTimeout::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 2, 0, 2> StreamingRecognitionConfig_VoiceActivityTimeout::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.protobuf.Duration speech_end_timeout = 2;
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_end_timeout_)}},
    // .google.protobuf.Duration speech_start_timeout = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_start_timeout_)}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.protobuf.Duration speech_start_timeout = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_start_timeout_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration speech_end_timeout = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_end_timeout_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void StreamingRecognitionConfig_VoiceActivityTimeout::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.speech_start_timeout_ != nullptr);
      _impl_.speech_start_timeout_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.speech_end_timeout_ != nullptr);
      _impl_.speech_end_timeout_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* StreamingRecognitionConfig_VoiceActivityTimeout::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const StreamingRecognitionConfig_VoiceActivityTimeout& this_ = static_cast<const StreamingRecognitionConfig_VoiceActivityTimeout&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* StreamingRecognitionConfig_VoiceActivityTimeout::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const StreamingRecognitionConfig_VoiceActivityTimeout& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.protobuf.Duration speech_start_timeout = 1;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                1, *this_._impl_.speech_start_timeout_, this_._impl_.speech_start_timeout_->GetCachedSize(), target,
                stream);
          }

          // .google.protobuf.Duration speech_end_timeout = 2;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                2, *this_._impl_.speech_end_timeout_, this_._impl_.speech_end_timeout_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t StreamingRecognitionConfig_VoiceActivityTimeout::ByteSizeLong(const MessageLite& base) {
          const StreamingRecognitionConfig_VoiceActivityTimeout& this_ = static_cast<const StreamingRecognitionConfig_VoiceActivityTimeout&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t StreamingRecognitionConfig_VoiceActivityTimeout::ByteSizeLong() const {
          const StreamingRecognitionConfig_VoiceActivityTimeout& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .google.protobuf.Duration speech_start_timeout = 1;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_start_timeout_);
            }
            // .google.protobuf.Duration speech_end_timeout = 2;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_end_timeout_);
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void StreamingRecognitionConfig_VoiceActivityTimeout::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognitionConfig_VoiceActivityTimeout*>(&to_msg);
  auto& from = static_cast<const StreamingRecognitionConfig_VoiceActivityTimeout&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.speech_start_timeout_ != nullptr);
      if (_this->_impl_.speech_start_timeout_ == nullptr) {
        _this->_impl_.speech_start_timeout_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.speech_start_timeout_);
      } else {
        _this->_impl_.speech_start_timeout_->MergeFrom(*from._impl_.speech_start_timeout_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.speech_end_timeout_ != nullptr);
      if (_this->_impl_.speech_end_timeout_ == nullptr) {
        _this->_impl_.speech_end_timeout_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.speech_end_timeout_);
      } else {
        _this->_impl_.speech_end_timeout_->MergeFrom(*from._impl_.speech_end_timeout_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognitionConfig_VoiceActivityTimeout::CopyFrom(const StreamingRecognitionConfig_VoiceActivityTimeout& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognitionConfig_VoiceActivityTimeout::InternalSwap(StreamingRecognitionConfig_VoiceActivityTimeout* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_end_timeout_)
      + sizeof(StreamingRecognitionConfig_VoiceActivityTimeout::_impl_.speech_end_timeout_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_start_timeout_)>(
          reinterpret_cast<char*>(&_impl_.speech_start_timeout_),
          reinterpret_cast<char*>(&other->_impl_.speech_start_timeout_));
}

::google::protobuf::Metadata StreamingRecognitionConfig_VoiceActivityTimeout::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognitionConfig::_Internal {
 public:
  using HasBits =
      decltype(std::declval<StreamingRecognitionConfig>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_._has_bits_);
};

StreamingRecognitionConfig::StreamingRecognitionConfig(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognitionConfig)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::StreamingRecognitionConfig& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

StreamingRecognitionConfig::StreamingRecognitionConfig(
    ::google::protobuf::Arena* arena,
    const StreamingRecognitionConfig& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognitionConfig* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.config_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionConfig>(
                              arena, *from._impl_.config_)
                        : nullptr;
  _impl_.voice_activity_timeout_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout>(
                              arena, *from._impl_.voice_activity_timeout_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, single_utterance_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, single_utterance_),
           offsetof(Impl_, enable_voice_activity_events_) -
               offsetof(Impl_, single_utterance_) +
               sizeof(Impl_::enable_voice_activity_events_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognitionConfig)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void StreamingRecognitionConfig::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, config_),
           0,
           offsetof(Impl_, enable_voice_activity_events_) -
               offsetof(Impl_, config_) +
               sizeof(Impl_::enable_voice_activity_events_));
}
StreamingRecognitionConfig::~StreamingRecognitionConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognitionConfig)
  SharedDtor(*this);
}
inline void StreamingRecognitionConfig::SharedDtor(MessageLite& self) {
  StreamingRecognitionConfig& this_ = static_cast<StreamingRecognitionConfig&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.config_;
  delete this_._impl_.voice_activity_timeout_;
  this_._impl_.~Impl_();
}

inline void* StreamingRecognitionConfig::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) StreamingRecognitionConfig(arena);
}
constexpr auto StreamingRecognitionConfig::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(StreamingRecognitionConfig),
                                            alignof(StreamingRecognitionConfig));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull StreamingRecognitionConfig::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_StreamingRecognitionConfig_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &StreamingRecognitionConfig::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<StreamingRecognitionConfig>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &StreamingRecognitionConfig::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<StreamingRecognitionConfig>(), &StreamingRecognitionConfig::ByteSizeLong,
            &StreamingRecognitionConfig::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_._cached_size_),
        false,
    },
    &StreamingRecognitionConfig::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* StreamingRecognitionConfig::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 5, 2, 0, 2> StreamingRecognitionConfig::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_._has_bits_),
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967240,  // skipmap
    offsetof(decltype(_table_), field_entries),
    5,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionConfig>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_)}},
    // bool single_utterance = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionConfig, _impl_.single_utterance_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.single_utterance_)}},
    // bool interim_results = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionConfig, _impl_.interim_results_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.interim_results_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool enable_voice_activity_events = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionConfig, _impl_.enable_voice_activity_events_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.enable_voice_activity_events_)}},
    // .google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout voice_activity_timeout = 6;
    {::_pbi::TcParser::FastMtS1,
     {50, 1, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.voice_activity_timeout_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool single_utterance = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.single_utterance_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool interim_results = 3;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.interim_results_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool enable_voice_activity_events = 5;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.enable_voice_activity_events_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout voice_activity_timeout = 6;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.voice_activity_timeout_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionConfig>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void StreamingRecognitionConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognitionConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.config_ != nullptr);
      _impl_.config_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.voice_activity_timeout_ != nullptr);
      _impl_.voice_activity_timeout_->Clear();
    }
  }
  ::memset(&_impl_.single_utterance_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.enable_voice_activity_events_) -
      reinterpret_cast<char*>(&_impl_.single_utterance_)) + sizeof(_impl_.enable_voice_activity_events_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* StreamingRecognitionConfig::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const StreamingRecognitionConfig& this_ = static_cast<const StreamingRecognitionConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* StreamingRecognitionConfig::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const StreamingRecognitionConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognitionConfig)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                1, *this_._impl_.config_, this_._impl_.config_->GetCachedSize(), target,
                stream);
          }

          // bool single_utterance = 2;
          if (this_._internal_single_utterance() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                2, this_._internal_single_utterance(), target);
          }

          // bool interim_results = 3;
          if (this_._internal_interim_results() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                3, this_._internal_interim_results(), target);
          }

          // bool enable_voice_activity_events = 5;
          if (this_._internal_enable_voice_activity_events() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                5, this_._internal_enable_voice_activity_events(), target);
          }

          // .google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout voice_activity_timeout = 6;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                6, *this_._impl_.voice_activity_timeout_, this_._impl_.voice_activity_timeout_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognitionConfig)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t StreamingRecognitionConfig::ByteSizeLong(const MessageLite& base) {
          const StreamingRecognitionConfig& this_ = static_cast<const StreamingRecognitionConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t StreamingRecognitionConfig::ByteSizeLong() const {
          const StreamingRecognitionConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognitionConfig)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.config_);
            }
            // .google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout voice_activity_timeout = 6;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.voice_activity_timeout_);
            }
          }
           {
            // bool single_utterance = 2;
            if (this_._internal_single_utterance() != 0) {
              total_size += 2;
            }
            // bool interim_results = 3;
            if (this_._internal_interim_results() != 0) {
              total_size += 2;
            }
            // bool enable_voice_activity_events = 5;
            if (this_._internal_enable_voice_activity_events() != 0) {
              total_size += 2;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void StreamingRecognitionConfig::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognitionConfig*>(&to_msg);
  auto& from = static_cast<const StreamingRecognitionConfig&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognitionConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.config_ != nullptr);
      if (_this->_impl_.config_ == nullptr) {
        _this->_impl_.config_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionConfig>(arena, *from._impl_.config_);
      } else {
        _this->_impl_.config_->MergeFrom(*from._impl_.config_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.voice_activity_timeout_ != nullptr);
      if (_this->_impl_.voice_activity_timeout_ == nullptr) {
        _this->_impl_.voice_activity_timeout_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout>(arena, *from._impl_.voice_activity_timeout_);
      } else {
        _this->_impl_.voice_activity_timeout_->MergeFrom(*from._impl_.voice_activity_timeout_);
      }
    }
  }
  if (from._internal_single_utterance() != 0) {
    _this->_impl_.single_utterance_ = from._impl_.single_utterance_;
  }
  if (from._internal_interim_results() != 0) {
    _this->_impl_.interim_results_ = from._impl_.interim_results_;
  }
  if (from._internal_enable_voice_activity_events() != 0) {
    _this->_impl_.enable_voice_activity_events_ = from._impl_.enable_voice_activity_events_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognitionConfig::CopyFrom(const StreamingRecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognitionConfig::InternalSwap(StreamingRecognitionConfig* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.enable_voice_activity_events_)
      + sizeof(StreamingRecognitionConfig::_impl_.enable_voice_activity_events_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_)>(
          reinterpret_cast<char*>(&_impl_.config_),
          reinterpret_cast<char*>(&other->_impl_.config_));
}

::google::protobuf::Metadata StreamingRecognitionConfig::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RecognitionConfig::_Internal {
 public:
  using HasBits =
      decltype(std::declval<RecognitionConfig>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_._has_bits_);
};

void RecognitionConfig::clear_adaptation() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.adaptation_ != nullptr) _impl_.adaptation_->Clear();
  _impl_._has_bits_[0] &= ~0x00000004u;
}
void RecognitionConfig::clear_transcript_normalization() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.transcript_normalization_ != nullptr) _impl_.transcript_normalization_->Clear();
  _impl_._has_bits_[0] &= ~0x00000020u;
}
void RecognitionConfig::clear_enable_spoken_punctuation() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.enable_spoken_punctuation_ != nullptr) _impl_.enable_spoken_punctuation_->Clear();
  _impl_._has_bits_[0] &= ~0x00000008u;
}
void RecognitionConfig::clear_enable_spoken_emojis() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.enable_spoken_emojis_ != nullptr) _impl_.enable_spoken_emojis_->Clear();
  _impl_._has_bits_[0] &= ~0x00000010u;
}
RecognitionConfig::RecognitionConfig(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognitionConfig)
}
inline PROTOBUF_NDEBUG_INLINE RecognitionConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::RecognitionConfig& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        speech_contexts_{visibility, arena, from.speech_contexts_},
        alternative_language_codes_{visibility, arena, from.alternative_language_codes_},
        language_code_(arena, from.language_code_),
        model_(arena, from.model_) {}

RecognitionConfig::RecognitionConfig(
    ::google::protobuf::Arena* arena,
    const RecognitionConfig& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognitionConfig* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.metadata_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionMetadata>(
                              arena, *from._impl_.metadata_)
                        : nullptr;
  _impl_.diarization_config_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeakerDiarizationConfig>(
                              arena, *from._impl_.diarization_config_)
                        : nullptr;
  _impl_.adaptation_ = (cached_has_bits & 0x00000004u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeechAdaptation>(
                              arena, *from._impl_.adaptation_)
                        : nullptr;
  _impl_.enable_spoken_punctuation_ = (cached_has_bits & 0x00000008u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::BoolValue>(
                              arena, *from._impl_.enable_spoken_punctuation_)
                        : nullptr;
  _impl_.enable_spoken_emojis_ = (cached_has_bits & 0x00000010u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::BoolValue>(
                              arena, *from._impl_.enable_spoken_emojis_)
                        : nullptr;
  _impl_.transcript_normalization_ = (cached_has_bits & 0x00000020u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::TranscriptNormalization>(
                              arena, *from._impl_.transcript_normalization_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, encoding_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, encoding_),
           offsetof(Impl_, use_enhanced_) -
               offsetof(Impl_, encoding_) +
               sizeof(Impl_::use_enhanced_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognitionConfig)
}
inline PROTOBUF_NDEBUG_INLINE RecognitionConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        speech_contexts_{visibility, arena},
        alternative_language_codes_{visibility, arena},
        language_code_(arena),
        model_(arena) {}

inline void RecognitionConfig::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, metadata_),
           0,
           offsetof(Impl_, use_enhanced_) -
               offsetof(Impl_, metadata_) +
               sizeof(Impl_::use_enhanced_));
}
RecognitionConfig::~RecognitionConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognitionConfig)
  SharedDtor(*this);
}
inline void RecognitionConfig::SharedDtor(MessageLite& self) {
  RecognitionConfig& this_ = static_cast<RecognitionConfig&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.language_code_.Destroy();
  this_._impl_.model_.Destroy();
  delete this_._impl_.metadata_;
  delete this_._impl_.diarization_config_;
  delete this_._impl_.adaptation_;
  delete this_._impl_.enable_spoken_punctuation_;
  delete this_._impl_.enable_spoken_emojis_;
  delete this_._impl_.transcript_normalization_;
  this_._impl_.~Impl_();
}

inline void* RecognitionConfig::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RecognitionConfig(arena);
}
constexpr auto RecognitionConfig::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.alternative_language_codes_) +
          decltype(RecognitionConfig::_impl_.alternative_language_codes_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.speech_contexts_) +
          decltype(RecognitionConfig::_impl_.speech_contexts_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(RecognitionConfig), alignof(RecognitionConfig), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&RecognitionConfig::PlacementNew_,
                                 sizeof(RecognitionConfig),
                                 alignof(RecognitionConfig));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RecognitionConfig::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RecognitionConfig_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RecognitionConfig::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RecognitionConfig>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RecognitionConfig::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RecognitionConfig>(), &RecognitionConfig::ByteSizeLong,
            &RecognitionConfig::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_._cached_size_),
        false,
    },
    &RecognitionConfig::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RecognitionConfig::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<5, 20, 7, 109, 2> RecognitionConfig::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_._has_bits_),
    0, // no _extensions_
    24, 248,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4279337472,  // skipmap
    offsetof(decltype(_table_), field_entries),
    20,  // num_field_entries
    7,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionConfig>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.encoding_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.encoding_)}},
    // int32 sample_rate_hertz = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.sample_rate_hertz_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.sample_rate_hertz_)}},
    // string language_code = 3 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastUS1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.language_code_)}},
    // int32 max_alternatives = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.max_alternatives_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.max_alternatives_)}},
    // bool profanity_filter = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.profanity_filter_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.profanity_filter_)}},
    // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;
    {::_pbi::TcParser::FastMtR1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.speech_contexts_)}},
    // int32 audio_channel_count = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.audio_channel_count_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.audio_channel_count_)}},
    // bool enable_word_time_offsets = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_word_time_offsets_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_time_offsets_)}},
    // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;
    {::_pbi::TcParser::FastMtS1,
     {74, 0, 1, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.metadata_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool enable_automatic_punctuation = 11;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_automatic_punctuation_), 63>(),
     {88, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_automatic_punctuation_)}},
    // bool enable_separate_recognition_per_channel = 12;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_), 63>(),
     {96, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_)}},
    // string model = 13;
    {::_pbi::TcParser::FastUS1,
     {106, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.model_)}},
    // bool use_enhanced = 14;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.use_enhanced_), 63>(),
     {112, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.use_enhanced_)}},
    // bool enable_word_confidence = 15;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_word_confidence_), 63>(),
     {120, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_confidence_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // repeated string alternative_language_codes = 18;
    {::_pbi::TcParser::FastUR2,
     {402, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.alternative_language_codes_)}},
    // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;
    {::_pbi::TcParser::FastMtS2,
     {410, 1, 2, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.diarization_config_)}},
    // .google.cloud.speech.v1.SpeechAdaptation adaptation = 20;
    {::_pbi::TcParser::FastMtS2,
     {418, 2, 3, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.adaptation_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.protobuf.BoolValue enable_spoken_punctuation = 22;
    {::_pbi::TcParser::FastMtS2,
     {434, 3, 4, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_spoken_punctuation_)}},
    // .google.protobuf.BoolValue enable_spoken_emojis = 23;
    {::_pbi::TcParser::FastMtS2,
     {442, 4, 5, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_spoken_emojis_)}},
    // .google.cloud.speech.v1.TranscriptNormalization transcript_normalization = 24 [(.google.api.field_behavior) = OPTIONAL];
    {::_pbi::TcParser::FastMtS2,
     {450, 5, 6, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.transcript_normalization_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.encoding_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // int32 sample_rate_hertz = 2;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.sample_rate_hertz_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // string language_code = 3 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.language_code_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int32 max_alternatives = 4;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.max_alternatives_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool profanity_filter = 5;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.profanity_filter_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.speech_contexts_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // int32 audio_channel_count = 7;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.audio_channel_count_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool enable_word_time_offsets = 8;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_time_offsets_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.metadata_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool enable_automatic_punctuation = 11;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_automatic_punctuation_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool enable_separate_recognition_per_channel = 12;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // string model = 13;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.model_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // bool use_enhanced = 14;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.use_enhanced_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool enable_word_confidence = 15;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_confidence_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // repeated string alternative_language_codes = 18;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.alternative_language_codes_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.diarization_config_), _Internal::kHasBitsOffset + 1, 2,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.SpeechAdaptation adaptation = 20;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.adaptation_), _Internal::kHasBitsOffset + 2, 3,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.BoolValue enable_spoken_punctuation = 22;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_spoken_punctuation_), _Internal::kHasBitsOffset + 3, 4,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.BoolValue enable_spoken_emojis = 23;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_spoken_emojis_), _Internal::kHasBitsOffset + 4, 5,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.TranscriptNormalization transcript_normalization = 24 [(.google.api.field_behavior) = OPTIONAL];
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.transcript_normalization_), _Internal::kHasBitsOffset + 5, 6,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechContext>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionMetadata>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeakerDiarizationConfig>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptation>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::BoolValue>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::BoolValue>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::TranscriptNormalization>()},
  }}, {{
    "\50\0\0\15\0\0\0\0\0\0\0\0\5\0\0\32\0\0\0\0\0\0\0\0"
    "google.cloud.speech.v1.RecognitionConfig"
    "language_code"
    "model"
    "alternative_language_codes"
  }},
};

PROTOBUF_NOINLINE void RecognitionConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognitionConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.speech_contexts_.Clear();
  _impl_.alternative_language_codes_.Clear();
  _impl_.language_code_.ClearToEmpty();
  _impl_.model_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x0000003fu) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.metadata_ != nullptr);
      _impl_.metadata_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.diarization_config_ != nullptr);
      _impl_.diarization_config_->Clear();
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(_impl_.adaptation_ != nullptr);
      _impl_.adaptation_->Clear();
    }
    if (cached_has_bits & 0x00000008u) {
      ABSL_DCHECK(_impl_.enable_spoken_punctuation_ != nullptr);
      _impl_.enable_spoken_punctuation_->Clear();
    }
    if (cached_has_bits & 0x00000010u) {
      ABSL_DCHECK(_impl_.enable_spoken_emojis_ != nullptr);
      _impl_.enable_spoken_emojis_->Clear();
    }
    if (cached_has_bits & 0x00000020u) {
      ABSL_DCHECK(_impl_.transcript_normalization_ != nullptr);
      _impl_.transcript_normalization_->Clear();
    }
  }
  ::memset(&_impl_.encoding_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.use_enhanced_) -
      reinterpret_cast<char*>(&_impl_.encoding_)) + sizeof(_impl_.use_enhanced_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RecognitionConfig::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RecognitionConfig& this_ = static_cast<const RecognitionConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RecognitionConfig::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RecognitionConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognitionConfig)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;
          if (this_._internal_encoding() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                1, this_._internal_encoding(), target);
          }

          // int32 sample_rate_hertz = 2;
          if (this_._internal_sample_rate_hertz() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<2>(
                    stream, this_._internal_sample_rate_hertz(), target);
          }

          // string language_code = 3 [(.google.api.field_behavior) = REQUIRED];
          if (!this_._internal_language_code().empty()) {
            const std::string& _s = this_._internal_language_code();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionConfig.language_code");
            target = stream->WriteStringMaybeAliased(3, _s, target);
          }

          // int32 max_alternatives = 4;
          if (this_._internal_max_alternatives() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<4>(
                    stream, this_._internal_max_alternatives(), target);
          }

          // bool profanity_filter = 5;
          if (this_._internal_profanity_filter() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                5, this_._internal_profanity_filter(), target);
          }

          // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_speech_contexts_size());
               i < n; i++) {
            const auto& repfield = this_._internal_speech_contexts().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    6, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // int32 audio_channel_count = 7;
          if (this_._internal_audio_channel_count() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<7>(
                    stream, this_._internal_audio_channel_count(), target);
          }

          // bool enable_word_time_offsets = 8;
          if (this_._internal_enable_word_time_offsets() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                8, this_._internal_enable_word_time_offsets(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                9, *this_._impl_.metadata_, this_._impl_.metadata_->GetCachedSize(), target,
                stream);
          }

          // bool enable_automatic_punctuation = 11;
          if (this_._internal_enable_automatic_punctuation() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                11, this_._internal_enable_automatic_punctuation(), target);
          }

          // bool enable_separate_recognition_per_channel = 12;
          if (this_._internal_enable_separate_recognition_per_channel() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                12, this_._internal_enable_separate_recognition_per_channel(), target);
          }

          // string model = 13;
          if (!this_._internal_model().empty()) {
            const std::string& _s = this_._internal_model();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionConfig.model");
            target = stream->WriteStringMaybeAliased(13, _s, target);
          }

          // bool use_enhanced = 14;
          if (this_._internal_use_enhanced() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                14, this_._internal_use_enhanced(), target);
          }

          // bool enable_word_confidence = 15;
          if (this_._internal_enable_word_confidence() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                15, this_._internal_enable_word_confidence(), target);
          }

          // repeated string alternative_language_codes = 18;
          for (int i = 0, n = this_._internal_alternative_language_codes_size(); i < n; ++i) {
            const auto& s = this_._internal_alternative_language_codes().Get(i);
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionConfig.alternative_language_codes");
            target = stream->WriteString(18, s, target);
          }

          // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                19, *this_._impl_.diarization_config_, this_._impl_.diarization_config_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.SpeechAdaptation adaptation = 20;
          if (cached_has_bits & 0x00000004u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                20, *this_._impl_.adaptation_, this_._impl_.adaptation_->GetCachedSize(), target,
                stream);
          }

          // .google.protobuf.BoolValue enable_spoken_punctuation = 22;
          if (cached_has_bits & 0x00000008u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                22, *this_._impl_.enable_spoken_punctuation_, this_._impl_.enable_spoken_punctuation_->GetCachedSize(), target,
                stream);
          }

          // .google.protobuf.BoolValue enable_spoken_emojis = 23;
          if (cached_has_bits & 0x00000010u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                23, *this_._impl_.enable_spoken_emojis_, this_._impl_.enable_spoken_emojis_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.TranscriptNormalization transcript_normalization = 24 [(.google.api.field_behavior) = OPTIONAL];
          if (cached_has_bits & 0x00000020u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                24, *this_._impl_.transcript_normalization_, this_._impl_.transcript_normalization_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognitionConfig)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RecognitionConfig::ByteSizeLong(const MessageLite& base) {
          const RecognitionConfig& this_ = static_cast<const RecognitionConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RecognitionConfig::ByteSizeLong() const {
          const RecognitionConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognitionConfig)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;
            {
              total_size += 1UL * this_._internal_speech_contexts_size();
              for (const auto& msg : this_._internal_speech_contexts()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
            // repeated string alternative_language_codes = 18;
            {
              total_size +=
                  2 * ::google::protobuf::internal::FromIntSize(this_._internal_alternative_language_codes().size());
              for (int i = 0, n = this_._internal_alternative_language_codes().size(); i < n; ++i) {
                total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
                    this_._internal_alternative_language_codes().Get(i));
              }
            }
          }
           {
            // string language_code = 3 [(.google.api.field_behavior) = REQUIRED];
            if (!this_._internal_language_code().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_language_code());
            }
            // string model = 13;
            if (!this_._internal_model().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_model());
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x0000003fu) {
            // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.metadata_);
            }
            // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;
            if (cached_has_bits & 0x00000002u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.diarization_config_);
            }
            // .google.cloud.speech.v1.SpeechAdaptation adaptation = 20;
            if (cached_has_bits & 0x00000004u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.adaptation_);
            }
            // .google.protobuf.BoolValue enable_spoken_punctuation = 22;
            if (cached_has_bits & 0x00000008u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.enable_spoken_punctuation_);
            }
            // .google.protobuf.BoolValue enable_spoken_emojis = 23;
            if (cached_has_bits & 0x00000010u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.enable_spoken_emojis_);
            }
            // .google.cloud.speech.v1.TranscriptNormalization transcript_normalization = 24 [(.google.api.field_behavior) = OPTIONAL];
            if (cached_has_bits & 0x00000020u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.transcript_normalization_);
            }
          }
           {
            // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;
            if (this_._internal_encoding() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_encoding());
            }
            // int32 sample_rate_hertz = 2;
            if (this_._internal_sample_rate_hertz() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_sample_rate_hertz());
            }
            // int32 max_alternatives = 4;
            if (this_._internal_max_alternatives() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_max_alternatives());
            }
            // int32 audio_channel_count = 7;
            if (this_._internal_audio_channel_count() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_audio_channel_count());
            }
            // bool enable_separate_recognition_per_channel = 12;
            if (this_._internal_enable_separate_recognition_per_channel() != 0) {
              total_size += 2;
            }
            // bool profanity_filter = 5;
            if (this_._internal_profanity_filter() != 0) {
              total_size += 2;
            }
            // bool enable_word_time_offsets = 8;
            if (this_._internal_enable_word_time_offsets() != 0) {
              total_size += 2;
            }
            // bool enable_word_confidence = 15;
            if (this_._internal_enable_word_confidence() != 0) {
              total_size += 2;
            }
            // bool enable_automatic_punctuation = 11;
            if (this_._internal_enable_automatic_punctuation() != 0) {
              total_size += 2;
            }
            // bool use_enhanced = 14;
            if (this_._internal_use_enhanced() != 0) {
              total_size += 2;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RecognitionConfig::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognitionConfig*>(&to_msg);
  auto& from = static_cast<const RecognitionConfig&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognitionConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_speech_contexts()->MergeFrom(
      from._internal_speech_contexts());
  _this->_internal_mutable_alternative_language_codes()->MergeFrom(from._internal_alternative_language_codes());
  if (!from._internal_language_code().empty()) {
    _this->_internal_set_language_code(from._internal_language_code());
  }
  if (!from._internal_model().empty()) {
    _this->_internal_set_model(from._internal_model());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x0000003fu) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.metadata_ != nullptr);
      if (_this->_impl_.metadata_ == nullptr) {
        _this->_impl_.metadata_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::RecognitionMetadata>(arena, *from._impl_.metadata_);
      } else {
        _this->_impl_.metadata_->MergeFrom(*from._impl_.metadata_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.diarization_config_ != nullptr);
      if (_this->_impl_.diarization_config_ == nullptr) {
        _this->_impl_.diarization_config_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeakerDiarizationConfig>(arena, *from._impl_.diarization_config_);
      } else {
        _this->_impl_.diarization_config_->MergeFrom(*from._impl_.diarization_config_);
      }
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(from._impl_.adaptation_ != nullptr);
      if (_this->_impl_.adaptation_ == nullptr) {
        _this->_impl_.adaptation_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeechAdaptation>(arena, *from._impl_.adaptation_);
      } else {
        _this->_impl_.adaptation_->MergeFrom(*from._impl_.adaptation_);
      }
    }
    if (cached_has_bits & 0x00000008u) {
      ABSL_DCHECK(from._impl_.enable_spoken_punctuation_ != nullptr);
      if (_this->_impl_.enable_spoken_punctuation_ == nullptr) {
        _this->_impl_.enable_spoken_punctuation_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::BoolValue>(arena, *from._impl_.enable_spoken_punctuation_);
      } else {
        _this->_impl_.enable_spoken_punctuation_->MergeFrom(*from._impl_.enable_spoken_punctuation_);
      }
    }
    if (cached_has_bits & 0x00000010u) {
      ABSL_DCHECK(from._impl_.enable_spoken_emojis_ != nullptr);
      if (_this->_impl_.enable_spoken_emojis_ == nullptr) {
        _this->_impl_.enable_spoken_emojis_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::BoolValue>(arena, *from._impl_.enable_spoken_emojis_);
      } else {
        _this->_impl_.enable_spoken_emojis_->MergeFrom(*from._impl_.enable_spoken_emojis_);
      }
    }
    if (cached_has_bits & 0x00000020u) {
      ABSL_DCHECK(from._impl_.transcript_normalization_ != nullptr);
      if (_this->_impl_.transcript_normalization_ == nullptr) {
        _this->_impl_.transcript_normalization_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::TranscriptNormalization>(arena, *from._impl_.transcript_normalization_);
      } else {
        _this->_impl_.transcript_normalization_->MergeFrom(*from._impl_.transcript_normalization_);
      }
    }
  }
  if (from._internal_encoding() != 0) {
    _this->_impl_.encoding_ = from._impl_.encoding_;
  }
  if (from._internal_sample_rate_hertz() != 0) {
    _this->_impl_.sample_rate_hertz_ = from._impl_.sample_rate_hertz_;
  }
  if (from._internal_max_alternatives() != 0) {
    _this->_impl_.max_alternatives_ = from._impl_.max_alternatives_;
  }
  if (from._internal_audio_channel_count() != 0) {
    _this->_impl_.audio_channel_count_ = from._impl_.audio_channel_count_;
  }
  if (from._internal_enable_separate_recognition_per_channel() != 0) {
    _this->_impl_.enable_separate_recognition_per_channel_ = from._impl_.enable_separate_recognition_per_channel_;
  }
  if (from._internal_profanity_filter() != 0) {
    _this->_impl_.profanity_filter_ = from._impl_.profanity_filter_;
  }
  if (from._internal_enable_word_time_offsets() != 0) {
    _this->_impl_.enable_word_time_offsets_ = from._impl_.enable_word_time_offsets_;
  }
  if (from._internal_enable_word_confidence() != 0) {
    _this->_impl_.enable_word_confidence_ = from._impl_.enable_word_confidence_;
  }
  if (from._internal_enable_automatic_punctuation() != 0) {
    _this->_impl_.enable_automatic_punctuation_ = from._impl_.enable_automatic_punctuation_;
  }
  if (from._internal_use_enhanced() != 0) {
    _this->_impl_.use_enhanced_ = from._impl_.use_enhanced_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognitionConfig::CopyFrom(const RecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognitionConfig::InternalSwap(RecognitionConfig* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.speech_contexts_.InternalSwap(&other->_impl_.speech_contexts_);
  _impl_.alternative_language_codes_.InternalSwap(&other->_impl_.alternative_language_codes_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.language_code_, &other->_impl_.language_code_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.model_, &other->_impl_.model_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.use_enhanced_)
      + sizeof(RecognitionConfig::_impl_.use_enhanced_)
      - PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.metadata_)>(
          reinterpret_cast<char*>(&_impl_.metadata_),
          reinterpret_cast<char*>(&other->_impl_.metadata_));
}

::google::protobuf::Metadata RecognitionConfig::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeakerDiarizationConfig::_Internal {
 public:
};

SpeakerDiarizationConfig::SpeakerDiarizationConfig(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeakerDiarizationConfig)
}
SpeakerDiarizationConfig::SpeakerDiarizationConfig(
    ::google::protobuf::Arena* arena, const SpeakerDiarizationConfig& from)
    : SpeakerDiarizationConfig(arena) {
  MergeFrom(from);
}
inline PROTOBUF_NDEBUG_INLINE SpeakerDiarizationConfig::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void SpeakerDiarizationConfig::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, enable_speaker_diarization_),
           0,
           offsetof(Impl_, speaker_tag_) -
               offsetof(Impl_, enable_speaker_diarization_) +
               sizeof(Impl_::speaker_tag_));
}
SpeakerDiarizationConfig::~SpeakerDiarizationConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeakerDiarizationConfig)
  SharedDtor(*this);
}
inline void SpeakerDiarizationConfig::SharedDtor(MessageLite& self) {
  SpeakerDiarizationConfig& this_ = static_cast<SpeakerDiarizationConfig&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* SpeakerDiarizationConfig::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) SpeakerDiarizationConfig(arena);
}
constexpr auto SpeakerDiarizationConfig::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(SpeakerDiarizationConfig),
                                            alignof(SpeakerDiarizationConfig));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull SpeakerDiarizationConfig::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_SpeakerDiarizationConfig_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &SpeakerDiarizationConfig::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<SpeakerDiarizationConfig>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &SpeakerDiarizationConfig::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<SpeakerDiarizationConfig>(), &SpeakerDiarizationConfig::ByteSizeLong,
            &SpeakerDiarizationConfig::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_._cached_size_),
        false,
    },
    &SpeakerDiarizationConfig::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* SpeakerDiarizationConfig::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 4, 0, 0, 2> SpeakerDiarizationConfig::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    5, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967272,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeakerDiarizationConfig>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // bool enable_speaker_diarization = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_)}},
    // int32 min_speaker_count = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeakerDiarizationConfig, _impl_.min_speaker_count_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.min_speaker_count_)}},
    // int32 max_speaker_count = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeakerDiarizationConfig, _impl_.max_speaker_count_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.max_speaker_count_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeakerDiarizationConfig, _impl_.speaker_tag_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.speaker_tag_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // bool enable_speaker_diarization = 1;
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 min_speaker_count = 2;
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.min_speaker_count_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int32 max_speaker_count = 3;
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.max_speaker_count_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.speaker_tag_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
  }},
  // no aux_entries
  {{
  }},
};

PROTOBUF_NOINLINE void SpeakerDiarizationConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.enable_speaker_diarization_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.speaker_tag_) -
      reinterpret_cast<char*>(&_impl_.enable_speaker_diarization_)) + sizeof(_impl_.speaker_tag_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* SpeakerDiarizationConfig::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const SpeakerDiarizationConfig& this_ = static_cast<const SpeakerDiarizationConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* SpeakerDiarizationConfig::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const SpeakerDiarizationConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // bool enable_speaker_diarization = 1;
          if (this_._internal_enable_speaker_diarization() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                1, this_._internal_enable_speaker_diarization(), target);
          }

          // int32 min_speaker_count = 2;
          if (this_._internal_min_speaker_count() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<2>(
                    stream, this_._internal_min_speaker_count(), target);
          }

          // int32 max_speaker_count = 3;
          if (this_._internal_max_speaker_count() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<3>(
                    stream, this_._internal_max_speaker_count(), target);
          }

          // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
          if (this_._internal_speaker_tag() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<5>(
                    stream, this_._internal_speaker_tag(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeakerDiarizationConfig)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t SpeakerDiarizationConfig::ByteSizeLong(const MessageLite& base) {
          const SpeakerDiarizationConfig& this_ = static_cast<const SpeakerDiarizationConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t SpeakerDiarizationConfig::ByteSizeLong() const {
          const SpeakerDiarizationConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // bool enable_speaker_diarization = 1;
            if (this_._internal_enable_speaker_diarization() != 0) {
              total_size += 2;
            }
            // int32 min_speaker_count = 2;
            if (this_._internal_min_speaker_count() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_min_speaker_count());
            }
            // int32 max_speaker_count = 3;
            if (this_._internal_max_speaker_count() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_max_speaker_count());
            }
            // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
            if (this_._internal_speaker_tag() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_speaker_tag());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void SpeakerDiarizationConfig::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeakerDiarizationConfig*>(&to_msg);
  auto& from = static_cast<const SpeakerDiarizationConfig&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_enable_speaker_diarization() != 0) {
    _this->_impl_.enable_speaker_diarization_ = from._impl_.enable_speaker_diarization_;
  }
  if (from._internal_min_speaker_count() != 0) {
    _this->_impl_.min_speaker_count_ = from._impl_.min_speaker_count_;
  }
  if (from._internal_max_speaker_count() != 0) {
    _this->_impl_.max_speaker_count_ = from._impl_.max_speaker_count_;
  }
  if (from._internal_speaker_tag() != 0) {
    _this->_impl_.speaker_tag_ = from._impl_.speaker_tag_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeakerDiarizationConfig::CopyFrom(const SpeakerDiarizationConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeakerDiarizationConfig::InternalSwap(SpeakerDiarizationConfig* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.speaker_tag_)
      + sizeof(SpeakerDiarizationConfig::_impl_.speaker_tag_)
      - PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_)>(
          reinterpret_cast<char*>(&_impl_.enable_speaker_diarization_),
          reinterpret_cast<char*>(&other->_impl_.enable_speaker_diarization_));
}

::google::protobuf::Metadata SpeakerDiarizationConfig::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RecognitionMetadata::_Internal {
 public:
};

RecognitionMetadata::RecognitionMetadata(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognitionMetadata)
}
inline PROTOBUF_NDEBUG_INLINE RecognitionMetadata::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::RecognitionMetadata& from_msg)
      : recording_device_name_(arena, from.recording_device_name_),
        original_mime_type_(arena, from.original_mime_type_),
        audio_topic_(arena, from.audio_topic_),
        _cached_size_{0} {}

RecognitionMetadata::RecognitionMetadata(
    ::google::protobuf::Arena* arena,
    const RecognitionMetadata& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognitionMetadata* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, interaction_type_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, interaction_type_),
           offsetof(Impl_, recording_device_type_) -
               offsetof(Impl_, interaction_type_) +
               sizeof(Impl_::recording_device_type_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognitionMetadata)
}
inline PROTOBUF_NDEBUG_INLINE RecognitionMetadata::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : recording_device_name_(arena),
        original_mime_type_(arena),
        audio_topic_(arena),
        _cached_size_{0} {}

inline void RecognitionMetadata::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, interaction_type_),
           0,
           offsetof(Impl_, recording_device_type_) -
               offsetof(Impl_, interaction_type_) +
               sizeof(Impl_::recording_device_type_));
}
RecognitionMetadata::~RecognitionMetadata() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognitionMetadata)
  SharedDtor(*this);
}
inline void RecognitionMetadata::SharedDtor(MessageLite& self) {
  RecognitionMetadata& this_ = static_cast<RecognitionMetadata&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.recording_device_name_.Destroy();
  this_._impl_.original_mime_type_.Destroy();
  this_._impl_.audio_topic_.Destroy();
  this_._impl_.~Impl_();
}

inline void* RecognitionMetadata::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RecognitionMetadata(arena);
}
constexpr auto RecognitionMetadata::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(RecognitionMetadata),
                                            alignof(RecognitionMetadata));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RecognitionMetadata::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RecognitionMetadata_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RecognitionMetadata::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RecognitionMetadata>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RecognitionMetadata::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RecognitionMetadata>(), &RecognitionMetadata::ByteSizeLong,
            &RecognitionMetadata::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_._cached_size_),
        false,
    },
    &RecognitionMetadata::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RecognitionMetadata::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 8, 0, 109, 2> RecognitionMetadata::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    10, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294966530,  // skipmap
    offsetof(decltype(_table_), field_entries),
    8,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionMetadata>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string original_mime_type = 8;
    {::_pbi::TcParser::FastUS1,
     {66, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.original_mime_type_)}},
    // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.interaction_type_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.interaction_type_)}},
    // string audio_topic = 10;
    {::_pbi::TcParser::FastUS1,
     {82, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.audio_topic_)}},
    // uint32 industry_naics_code_of_audio = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.industry_naics_code_of_audio_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.industry_naics_code_of_audio_)}},
    // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.microphone_distance_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.microphone_distance_)}},
    // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.original_media_type_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.original_media_type_)}},
    // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.recording_device_type_), 63>(),
     {48, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_type_)}},
    // string recording_device_name = 7;
    {::_pbi::TcParser::FastUS1,
     {58, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_name_)}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.interaction_type_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // uint32 industry_naics_code_of_audio = 3;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.industry_naics_code_of_audio_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUInt32)},
    // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.microphone_distance_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.original_media_type_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_type_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // string recording_device_name = 7;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_name_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // string original_mime_type = 8;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.original_mime_type_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // string audio_topic = 10;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.audio_topic_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\52\0\0\0\0\0\25\22\13\0\0\0\0\0\0\0"
    "google.cloud.speech.v1.RecognitionMetadata"
    "recording_device_name"
    "original_mime_type"
    "audio_topic"
  }},
};

PROTOBUF_NOINLINE void RecognitionMetadata::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognitionMetadata)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.recording_device_name_.ClearToEmpty();
  _impl_.original_mime_type_.ClearToEmpty();
  _impl_.audio_topic_.ClearToEmpty();
  ::memset(&_impl_.interaction_type_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.recording_device_type_) -
      reinterpret_cast<char*>(&_impl_.interaction_type_)) + sizeof(_impl_.recording_device_type_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RecognitionMetadata::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RecognitionMetadata& this_ = static_cast<const RecognitionMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RecognitionMetadata::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RecognitionMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognitionMetadata)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;
          if (this_._internal_interaction_type() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                1, this_._internal_interaction_type(), target);
          }

          // uint32 industry_naics_code_of_audio = 3;
          if (this_._internal_industry_naics_code_of_audio() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteUInt32ToArray(
                3, this_._internal_industry_naics_code_of_audio(), target);
          }

          // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;
          if (this_._internal_microphone_distance() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                4, this_._internal_microphone_distance(), target);
          }

          // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;
          if (this_._internal_original_media_type() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                5, this_._internal_original_media_type(), target);
          }

          // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;
          if (this_._internal_recording_device_type() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                6, this_._internal_recording_device_type(), target);
          }

          // string recording_device_name = 7;
          if (!this_._internal_recording_device_name().empty()) {
            const std::string& _s = this_._internal_recording_device_name();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionMetadata.recording_device_name");
            target = stream->WriteStringMaybeAliased(7, _s, target);
          }

          // string original_mime_type = 8;
          if (!this_._internal_original_mime_type().empty()) {
            const std::string& _s = this_._internal_original_mime_type();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionMetadata.original_mime_type");
            target = stream->WriteStringMaybeAliased(8, _s, target);
          }

          // string audio_topic = 10;
          if (!this_._internal_audio_topic().empty()) {
            const std::string& _s = this_._internal_audio_topic();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionMetadata.audio_topic");
            target = stream->WriteStringMaybeAliased(10, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognitionMetadata)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RecognitionMetadata::ByteSizeLong(const MessageLite& base) {
          const RecognitionMetadata& this_ = static_cast<const RecognitionMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RecognitionMetadata::ByteSizeLong() const {
          const RecognitionMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognitionMetadata)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string recording_device_name = 7;
            if (!this_._internal_recording_device_name().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_recording_device_name());
            }
            // string original_mime_type = 8;
            if (!this_._internal_original_mime_type().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_original_mime_type());
            }
            // string audio_topic = 10;
            if (!this_._internal_audio_topic().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_audio_topic());
            }
            // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;
            if (this_._internal_interaction_type() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_interaction_type());
            }
            // uint32 industry_naics_code_of_audio = 3;
            if (this_._internal_industry_naics_code_of_audio() != 0) {
              total_size += ::_pbi::WireFormatLite::UInt32SizePlusOne(
                  this_._internal_industry_naics_code_of_audio());
            }
            // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;
            if (this_._internal_microphone_distance() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_microphone_distance());
            }
            // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;
            if (this_._internal_original_media_type() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_original_media_type());
            }
            // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;
            if (this_._internal_recording_device_type() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_recording_device_type());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RecognitionMetadata::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognitionMetadata*>(&to_msg);
  auto& from = static_cast<const RecognitionMetadata&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognitionMetadata)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_recording_device_name().empty()) {
    _this->_internal_set_recording_device_name(from._internal_recording_device_name());
  }
  if (!from._internal_original_mime_type().empty()) {
    _this->_internal_set_original_mime_type(from._internal_original_mime_type());
  }
  if (!from._internal_audio_topic().empty()) {
    _this->_internal_set_audio_topic(from._internal_audio_topic());
  }
  if (from._internal_interaction_type() != 0) {
    _this->_impl_.interaction_type_ = from._impl_.interaction_type_;
  }
  if (from._internal_industry_naics_code_of_audio() != 0) {
    _this->_impl_.industry_naics_code_of_audio_ = from._impl_.industry_naics_code_of_audio_;
  }
  if (from._internal_microphone_distance() != 0) {
    _this->_impl_.microphone_distance_ = from._impl_.microphone_distance_;
  }
  if (from._internal_original_media_type() != 0) {
    _this->_impl_.original_media_type_ = from._impl_.original_media_type_;
  }
  if (from._internal_recording_device_type() != 0) {
    _this->_impl_.recording_device_type_ = from._impl_.recording_device_type_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognitionMetadata::CopyFrom(const RecognitionMetadata& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognitionMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognitionMetadata::InternalSwap(RecognitionMetadata* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.recording_device_name_, &other->_impl_.recording_device_name_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.original_mime_type_, &other->_impl_.original_mime_type_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.audio_topic_, &other->_impl_.audio_topic_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_type_)
      + sizeof(RecognitionMetadata::_impl_.recording_device_type_)
      - PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.interaction_type_)>(
          reinterpret_cast<char*>(&_impl_.interaction_type_),
          reinterpret_cast<char*>(&other->_impl_.interaction_type_));
}

::google::protobuf::Metadata RecognitionMetadata::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeechContext::_Internal {
 public:
};

SpeechContext::SpeechContext(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeechContext)
}
inline PROTOBUF_NDEBUG_INLINE SpeechContext::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::SpeechContext& from_msg)
      : phrases_{visibility, arena, from.phrases_},
        _cached_size_{0} {}

SpeechContext::SpeechContext(
    ::google::protobuf::Arena* arena,
    const SpeechContext& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SpeechContext* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  _impl_.boost_ = from._impl_.boost_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.SpeechContext)
}
inline PROTOBUF_NDEBUG_INLINE SpeechContext::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : phrases_{visibility, arena},
        _cached_size_{0} {}

inline void SpeechContext::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.boost_ = {};
}
SpeechContext::~SpeechContext() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeechContext)
  SharedDtor(*this);
}
inline void SpeechContext::SharedDtor(MessageLite& self) {
  SpeechContext& this_ = static_cast<SpeechContext&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* SpeechContext::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) SpeechContext(arena);
}
constexpr auto SpeechContext::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.phrases_) +
          decltype(SpeechContext::_impl_.phrases_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(SpeechContext), alignof(SpeechContext), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&SpeechContext::PlacementNew_,
                                 sizeof(SpeechContext),
                                 alignof(SpeechContext));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull SpeechContext::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_SpeechContext_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &SpeechContext::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<SpeechContext>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &SpeechContext::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<SpeechContext>(), &SpeechContext::ByteSizeLong,
            &SpeechContext::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_._cached_size_),
        false,
    },
    &SpeechContext::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* SpeechContext::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 52, 2> SpeechContext::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    4, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967286,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechContext>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // float boost = 4;
    {::_pbi::TcParser::FastF32S1,
     {37, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.boost_)}},
    // repeated string phrases = 1;
    {::_pbi::TcParser::FastUR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.phrases_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated string phrases = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.phrases_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // float boost = 4;
    {PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.boost_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
  }},
  // no aux_entries
  {{
    "\44\7\0\0\0\0\0\0"
    "google.cloud.speech.v1.SpeechContext"
    "phrases"
  }},
};

PROTOBUF_NOINLINE void SpeechContext::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeechContext)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.phrases_.Clear();
  _impl_.boost_ = 0;
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* SpeechContext::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const SpeechContext& this_ = static_cast<const SpeechContext&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* SpeechContext::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const SpeechContext& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeechContext)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated string phrases = 1;
          for (int i = 0, n = this_._internal_phrases_size(); i < n; ++i) {
            const auto& s = this_._internal_phrases().Get(i);
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.SpeechContext.phrases");
            target = stream->WriteString(1, s, target);
          }

          // float boost = 4;
          if (::absl::bit_cast<::uint32_t>(this_._internal_boost()) != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteFloatToArray(
                4, this_._internal_boost(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeechContext)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t SpeechContext::ByteSizeLong(const MessageLite& base) {
          const SpeechContext& this_ = static_cast<const SpeechContext&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t SpeechContext::ByteSizeLong() const {
          const SpeechContext& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeechContext)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated string phrases = 1;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_phrases().size());
              for (int i = 0, n = this_._internal_phrases().size(); i < n; ++i) {
                total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
                    this_._internal_phrases().Get(i));
              }
            }
          }
           {
            // float boost = 4;
            if (::absl::bit_cast<::uint32_t>(this_._internal_boost()) != 0) {
              total_size += 5;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void SpeechContext::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeechContext*>(&to_msg);
  auto& from = static_cast<const SpeechContext&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeechContext)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_phrases()->MergeFrom(from._internal_phrases());
  if (::absl::bit_cast<::uint32_t>(from._internal_boost()) != 0) {
    _this->_impl_.boost_ = from._impl_.boost_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechContext::CopyFrom(const SpeechContext& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeechContext)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeechContext::InternalSwap(SpeechContext* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.phrases_.InternalSwap(&other->_impl_.phrases_);
        swap(_impl_.boost_, other->_impl_.boost_);
}

::google::protobuf::Metadata SpeechContext::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RecognitionAudio::_Internal {
 public:
  static constexpr ::int32_t kOneofCaseOffset =
      PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _impl_._oneof_case_);
};

RecognitionAudio::RecognitionAudio(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognitionAudio)
}
inline PROTOBUF_NDEBUG_INLINE RecognitionAudio::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::RecognitionAudio& from_msg)
      : audio_source_{},
        _cached_size_{0},
        _oneof_case_{from._oneof_case_[0]} {}

RecognitionAudio::RecognitionAudio(
    ::google::protobuf::Arena* arena,
    const RecognitionAudio& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognitionAudio* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  switch (audio_source_case()) {
    case AUDIO_SOURCE_NOT_SET:
      break;
      case kContent:
        new (&_impl_.audio_source_.content_) decltype(_impl_.audio_source_.content_){arena, from._impl_.audio_source_.content_};
        break;
      case kUri:
        new (&_impl_.audio_source_.uri_) decltype(_impl_.audio_source_.uri_){arena, from._impl_.audio_source_.uri_};
        break;
  }

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognitionAudio)
}
inline PROTOBUF_NDEBUG_INLINE RecognitionAudio::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : audio_source_{},
        _cached_size_{0},
        _oneof_case_{} {}

inline void RecognitionAudio::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
RecognitionAudio::~RecognitionAudio() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognitionAudio)
  SharedDtor(*this);
}
inline void RecognitionAudio::SharedDtor(MessageLite& self) {
  RecognitionAudio& this_ = static_cast<RecognitionAudio&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  if (this_.has_audio_source()) {
    this_.clear_audio_source();
  }
  this_._impl_.~Impl_();
}

void RecognitionAudio::clear_audio_source() {
// @@protoc_insertion_point(one_of_clear_start:google.cloud.speech.v1.RecognitionAudio)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  switch (audio_source_case()) {
    case kContent: {
      _impl_.audio_source_.content_.Destroy();
      break;
    }
    case kUri: {
      _impl_.audio_source_.uri_.Destroy();
      break;
    }
    case AUDIO_SOURCE_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = AUDIO_SOURCE_NOT_SET;
}


inline void* RecognitionAudio::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RecognitionAudio(arena);
}
constexpr auto RecognitionAudio::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(RecognitionAudio),
                                            alignof(RecognitionAudio));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RecognitionAudio::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RecognitionAudio_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RecognitionAudio::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RecognitionAudio>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RecognitionAudio::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RecognitionAudio>(), &RecognitionAudio::ByteSizeLong,
            &RecognitionAudio::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RecognitionAudio, _impl_._cached_size_),
        false,
    },
    &RecognitionAudio::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RecognitionAudio::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 2, 0, 51, 2> RecognitionAudio::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionAudio>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // bytes content = 1;
    {PROTOBUF_FIELD_OFFSET(RecognitionAudio, _impl_.audio_source_.content_), _Internal::kOneofCaseOffset + 0, 0,
    (0 | ::_fl::kFcOneof | ::_fl::kBytes | ::_fl::kRepAString)},
    // string uri = 2;
    {PROTOBUF_FIELD_OFFSET(RecognitionAudio, _impl_.audio_source_.uri_), _Internal::kOneofCaseOffset + 0, 0,
    (0 | ::_fl::kFcOneof | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\47\0\3\0\0\0\0\0"
    "google.cloud.speech.v1.RecognitionAudio"
    "uri"
  }},
};

PROTOBUF_NOINLINE void RecognitionAudio::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognitionAudio)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_audio_source();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RecognitionAudio::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RecognitionAudio& this_ = static_cast<const RecognitionAudio&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RecognitionAudio::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RecognitionAudio& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognitionAudio)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          switch (this_.audio_source_case()) {
            case kContent: {
              const std::string& _s = this_._internal_content();
              target = stream->WriteBytesMaybeAliased(1, _s, target);
              break;
            }
            case kUri: {
              const std::string& _s = this_._internal_uri();
              ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                  _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionAudio.uri");
              target = stream->WriteStringMaybeAliased(2, _s, target);
              break;
            }
            default:
              break;
          }
          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognitionAudio)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RecognitionAudio::ByteSizeLong(const MessageLite& base) {
          const RecognitionAudio& this_ = static_cast<const RecognitionAudio&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RecognitionAudio::ByteSizeLong() const {
          const RecognitionAudio& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognitionAudio)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          switch (this_.audio_source_case()) {
            // bytes content = 1;
            case kContent: {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::BytesSize(
                                              this_._internal_content());
              break;
            }
            // string uri = 2;
            case kUri: {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_uri());
              break;
            }
            case AUDIO_SOURCE_NOT_SET: {
              break;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RecognitionAudio::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognitionAudio*>(&to_msg);
  auto& from = static_cast<const RecognitionAudio&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognitionAudio)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (const uint32_t oneof_from_case = from._impl_._oneof_case_[0]) {
    const uint32_t oneof_to_case = _this->_impl_._oneof_case_[0];
    const bool oneof_needs_init = oneof_to_case != oneof_from_case;
    if (oneof_needs_init) {
      if (oneof_to_case != 0) {
        _this->clear_audio_source();
      }
      _this->_impl_._oneof_case_[0] = oneof_from_case;
    }

    switch (oneof_from_case) {
      case kContent: {
        if (oneof_needs_init) {
          _this->_impl_.audio_source_.content_.InitDefault();
        }
        _this->_impl_.audio_source_.content_.Set(from._internal_content(), arena);
        break;
      }
      case kUri: {
        if (oneof_needs_init) {
          _this->_impl_.audio_source_.uri_.InitDefault();
        }
        _this->_impl_.audio_source_.uri_.Set(from._internal_uri(), arena);
        break;
      }
      case AUDIO_SOURCE_NOT_SET:
        break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognitionAudio::CopyFrom(const RecognitionAudio& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognitionAudio)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognitionAudio::InternalSwap(RecognitionAudio* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.audio_source_, other->_impl_.audio_source_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::google::protobuf::Metadata RecognitionAudio::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RecognizeResponse::_Internal {
 public:
  using HasBits =
      decltype(std::declval<RecognizeResponse>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_._has_bits_);
};

void RecognizeResponse::clear_total_billed_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.total_billed_time_ != nullptr) _impl_.total_billed_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
RecognizeResponse::RecognizeResponse(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE RecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::RecognizeResponse& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        results_{visibility, arena, from.results_} {}

RecognizeResponse::RecognizeResponse(
    ::google::protobuf::Arena* arena,
    const RecognizeResponse& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognizeResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.total_billed_time_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.total_billed_time_)
                        : nullptr;
  _impl_.speech_adaptation_info_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeechAdaptationInfo>(
                              arena, *from._impl_.speech_adaptation_info_)
                        : nullptr;
  _impl_.request_id_ = from._impl_.request_id_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE RecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        results_{visibility, arena} {}

inline void RecognizeResponse::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, total_billed_time_),
           0,
           offsetof(Impl_, request_id_) -
               offsetof(Impl_, total_billed_time_) +
               sizeof(Impl_::request_id_));
}
RecognizeResponse::~RecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognizeResponse)
  SharedDtor(*this);
}
inline void RecognizeResponse::SharedDtor(MessageLite& self) {
  RecognizeResponse& this_ = static_cast<RecognizeResponse&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.total_billed_time_;
  delete this_._impl_.speech_adaptation_info_;
  this_._impl_.~Impl_();
}

inline void* RecognizeResponse::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RecognizeResponse(arena);
}
constexpr auto RecognizeResponse::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.results_) +
          decltype(RecognizeResponse::_impl_.results_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(RecognizeResponse), alignof(RecognizeResponse), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&RecognizeResponse::PlacementNew_,
                                 sizeof(RecognizeResponse),
                                 alignof(RecognizeResponse));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RecognizeResponse::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RecognizeResponse_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RecognizeResponse::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RecognizeResponse>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RecognizeResponse::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RecognizeResponse>(), &RecognizeResponse::ByteSizeLong,
            &RecognizeResponse::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_._cached_size_),
        false,
    },
    &RecognizeResponse::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RecognizeResponse::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 4, 3, 0, 2> RecognizeResponse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_._has_bits_),
    0, // no _extensions_
    8, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967097,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    3,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognizeResponse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // int64 request_id = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(RecognizeResponse, _impl_.request_id_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.request_id_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {::_pbi::TcParser::FastMtR1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.results_)}},
    // .google.protobuf.Duration total_billed_time = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 0, 1, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.total_billed_time_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 7;
    {::_pbi::TcParser::FastMtS1,
     {58, 1, 2, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.speech_adaptation_info_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.results_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration total_billed_time = 3;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.total_billed_time_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 7;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.speech_adaptation_info_), _Internal::kHasBitsOffset + 1, 2,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 request_id = 8;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.request_id_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionResult>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptationInfo>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void RecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognizeResponse)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.results_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.total_billed_time_ != nullptr);
      _impl_.total_billed_time_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.speech_adaptation_info_ != nullptr);
      _impl_.speech_adaptation_info_->Clear();
    }
  }
  _impl_.request_id_ = ::int64_t{0};
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RecognizeResponse::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RecognizeResponse& this_ = static_cast<const RecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RecognizeResponse::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognizeResponse)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_results_size());
               i < n; i++) {
            const auto& repfield = this_._internal_results().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    2, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.protobuf.Duration total_billed_time = 3;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                3, *this_._impl_.total_billed_time_, this_._impl_.total_billed_time_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 7;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                7, *this_._impl_.speech_adaptation_info_, this_._impl_.speech_adaptation_info_->GetCachedSize(), target,
                stream);
          }

          // int64 request_id = 8;
          if (this_._internal_request_id() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<8>(
                    stream, this_._internal_request_id(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognizeResponse)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RecognizeResponse::ByteSizeLong(const MessageLite& base) {
          const RecognizeResponse& this_ = static_cast<const RecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RecognizeResponse::ByteSizeLong() const {
          const RecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognizeResponse)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
            {
              total_size += 1UL * this_._internal_results_size();
              for (const auto& msg : this_._internal_results()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .google.protobuf.Duration total_billed_time = 3;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.total_billed_time_);
            }
            // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 7;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_adaptation_info_);
            }
          }
           {
            // int64 request_id = 8;
            if (this_._internal_request_id() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_request_id());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RecognizeResponse::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognizeResponse*>(&to_msg);
  auto& from = static_cast<const RecognizeResponse&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognizeResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_results()->MergeFrom(
      from._internal_results());
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.total_billed_time_ != nullptr);
      if (_this->_impl_.total_billed_time_ == nullptr) {
        _this->_impl_.total_billed_time_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.total_billed_time_);
      } else {
        _this->_impl_.total_billed_time_->MergeFrom(*from._impl_.total_billed_time_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.speech_adaptation_info_ != nullptr);
      if (_this->_impl_.speech_adaptation_info_ == nullptr) {
        _this->_impl_.speech_adaptation_info_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeechAdaptationInfo>(arena, *from._impl_.speech_adaptation_info_);
      } else {
        _this->_impl_.speech_adaptation_info_->MergeFrom(*from._impl_.speech_adaptation_info_);
      }
    }
  }
  if (from._internal_request_id() != 0) {
    _this->_impl_.request_id_ = from._impl_.request_id_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognizeResponse::CopyFrom(const RecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognizeResponse::InternalSwap(RecognizeResponse* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.results_.InternalSwap(&other->_impl_.results_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.request_id_)
      + sizeof(RecognizeResponse::_impl_.request_id_)
      - PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.total_billed_time_)>(
          reinterpret_cast<char*>(&_impl_.total_billed_time_),
          reinterpret_cast<char*>(&other->_impl_.total_billed_time_));
}

::google::protobuf::Metadata RecognizeResponse::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class LongRunningRecognizeResponse::_Internal {
 public:
  using HasBits =
      decltype(std::declval<LongRunningRecognizeResponse>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_._has_bits_);
};

void LongRunningRecognizeResponse::clear_total_billed_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.total_billed_time_ != nullptr) _impl_.total_billed_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
void LongRunningRecognizeResponse::clear_output_error() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.output_error_ != nullptr) _impl_.output_error_->Clear();
  _impl_._has_bits_[0] &= ~0x00000004u;
}
LongRunningRecognizeResponse::LongRunningRecognizeResponse(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.LongRunningRecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE LongRunningRecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::LongRunningRecognizeResponse& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        results_{visibility, arena, from.results_} {}

LongRunningRecognizeResponse::LongRunningRecognizeResponse(
    ::google::protobuf::Arena* arena,
    const LongRunningRecognizeResponse& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  LongRunningRecognizeResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.total_billed_time_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.total_billed_time_)
                        : nullptr;
  _impl_.output_config_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::TranscriptOutputConfig>(
                              arena, *from._impl_.output_config_)
                        : nullptr;
  _impl_.output_error_ = (cached_has_bits & 0x00000004u) ? ::google::protobuf::Message::CopyConstruct<::google::rpc::Status>(
                              arena, *from._impl_.output_error_)
                        : nullptr;
  _impl_.speech_adaptation_info_ = (cached_has_bits & 0x00000008u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeechAdaptationInfo>(
                              arena, *from._impl_.speech_adaptation_info_)
                        : nullptr;
  _impl_.request_id_ = from._impl_.request_id_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.LongRunningRecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE LongRunningRecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        results_{visibility, arena} {}

inline void LongRunningRecognizeResponse::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, total_billed_time_),
           0,
           offsetof(Impl_, request_id_) -
               offsetof(Impl_, total_billed_time_) +
               sizeof(Impl_::request_id_));
}
LongRunningRecognizeResponse::~LongRunningRecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.LongRunningRecognizeResponse)
  SharedDtor(*this);
}
inline void LongRunningRecognizeResponse::SharedDtor(MessageLite& self) {
  LongRunningRecognizeResponse& this_ = static_cast<LongRunningRecognizeResponse&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.total_billed_time_;
  delete this_._impl_.output_config_;
  delete this_._impl_.output_error_;
  delete this_._impl_.speech_adaptation_info_;
  this_._impl_.~Impl_();
}

inline void* LongRunningRecognizeResponse::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) LongRunningRecognizeResponse(arena);
}
constexpr auto LongRunningRecognizeResponse::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.results_) +
          decltype(LongRunningRecognizeResponse::_impl_.results_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(LongRunningRecognizeResponse), alignof(LongRunningRecognizeResponse), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&LongRunningRecognizeResponse::PlacementNew_,
                                 sizeof(LongRunningRecognizeResponse),
                                 alignof(LongRunningRecognizeResponse));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull LongRunningRecognizeResponse::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_LongRunningRecognizeResponse_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &LongRunningRecognizeResponse::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<LongRunningRecognizeResponse>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &LongRunningRecognizeResponse::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<LongRunningRecognizeResponse>(), &LongRunningRecognizeResponse::ByteSizeLong,
            &LongRunningRecognizeResponse::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_._cached_size_),
        false,
    },
    &LongRunningRecognizeResponse::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* LongRunningRecognizeResponse::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 5, 0, 2> LongRunningRecognizeResponse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_._has_bits_),
    0, // no _extensions_
    9, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294966809,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    5,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::LongRunningRecognizeResponse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 8;
    {::_pbi::TcParser::FastMtS1,
     {66, 3, 4, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.speech_adaptation_info_)}},
    // int64 request_id = 9;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(LongRunningRecognizeResponse, _impl_.request_id_), 63>(),
     {72, 63, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.request_id_)}},
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {::_pbi::TcParser::FastMtR1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.results_)}},
    // .google.protobuf.Duration total_billed_time = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 0, 1, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.total_billed_time_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 6;
    {::_pbi::TcParser::FastMtS1,
     {50, 1, 2, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.output_config_)}},
    // .google.rpc.Status output_error = 7;
    {::_pbi::TcParser::FastMtS1,
     {58, 2, 3, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.output_error_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.results_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration total_billed_time = 3;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.total_billed_time_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 6;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.output_config_), _Internal::kHasBitsOffset + 1, 2,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.rpc.Status output_error = 7;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.output_error_), _Internal::kHasBitsOffset + 2, 3,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 8;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.speech_adaptation_info_), _Internal::kHasBitsOffset + 3, 4,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 request_id = 9;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.request_id_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionResult>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::TranscriptOutputConfig>()},
    {::_pbi::TcParser::GetTable<::google::rpc::Status>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptationInfo>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void LongRunningRecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.results_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x0000000fu) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.total_billed_time_ != nullptr);
      _impl_.total_billed_time_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.output_config_ != nullptr);
      _impl_.output_config_->Clear();
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(_impl_.output_error_ != nullptr);
      _impl_.output_error_->Clear();
    }
    if (cached_has_bits & 0x00000008u) {
      ABSL_DCHECK(_impl_.speech_adaptation_info_ != nullptr);
      _impl_.speech_adaptation_info_->Clear();
    }
  }
  _impl_.request_id_ = ::int64_t{0};
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* LongRunningRecognizeResponse::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const LongRunningRecognizeResponse& this_ = static_cast<const LongRunningRecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* LongRunningRecognizeResponse::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const LongRunningRecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_results_size());
               i < n; i++) {
            const auto& repfield = this_._internal_results().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    2, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.protobuf.Duration total_billed_time = 3;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                3, *this_._impl_.total_billed_time_, this_._impl_.total_billed_time_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 6;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                6, *this_._impl_.output_config_, this_._impl_.output_config_->GetCachedSize(), target,
                stream);
          }

          // .google.rpc.Status output_error = 7;
          if (cached_has_bits & 0x00000004u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                7, *this_._impl_.output_error_, this_._impl_.output_error_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 8;
          if (cached_has_bits & 0x00000008u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                8, *this_._impl_.speech_adaptation_info_, this_._impl_.speech_adaptation_info_->GetCachedSize(), target,
                stream);
          }

          // int64 request_id = 9;
          if (this_._internal_request_id() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<9>(
                    stream, this_._internal_request_id(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.LongRunningRecognizeResponse)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t LongRunningRecognizeResponse::ByteSizeLong(const MessageLite& base) {
          const LongRunningRecognizeResponse& this_ = static_cast<const LongRunningRecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t LongRunningRecognizeResponse::ByteSizeLong() const {
          const LongRunningRecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
            {
              total_size += 1UL * this_._internal_results_size();
              for (const auto& msg : this_._internal_results()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x0000000fu) {
            // .google.protobuf.Duration total_billed_time = 3;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.total_billed_time_);
            }
            // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 6;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.output_config_);
            }
            // .google.rpc.Status output_error = 7;
            if (cached_has_bits & 0x00000004u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.output_error_);
            }
            // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 8;
            if (cached_has_bits & 0x00000008u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_adaptation_info_);
            }
          }
           {
            // int64 request_id = 9;
            if (this_._internal_request_id() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_request_id());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void LongRunningRecognizeResponse::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<LongRunningRecognizeResponse*>(&to_msg);
  auto& from = static_cast<const LongRunningRecognizeResponse&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_results()->MergeFrom(
      from._internal_results());
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x0000000fu) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.total_billed_time_ != nullptr);
      if (_this->_impl_.total_billed_time_ == nullptr) {
        _this->_impl_.total_billed_time_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.total_billed_time_);
      } else {
        _this->_impl_.total_billed_time_->MergeFrom(*from._impl_.total_billed_time_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.output_config_ != nullptr);
      if (_this->_impl_.output_config_ == nullptr) {
        _this->_impl_.output_config_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::TranscriptOutputConfig>(arena, *from._impl_.output_config_);
      } else {
        _this->_impl_.output_config_->MergeFrom(*from._impl_.output_config_);
      }
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(from._impl_.output_error_ != nullptr);
      if (_this->_impl_.output_error_ == nullptr) {
        _this->_impl_.output_error_ =
            ::google::protobuf::Message::CopyConstruct<::google::rpc::Status>(arena, *from._impl_.output_error_);
      } else {
        _this->_impl_.output_error_->MergeFrom(*from._impl_.output_error_);
      }
    }
    if (cached_has_bits & 0x00000008u) {
      ABSL_DCHECK(from._impl_.speech_adaptation_info_ != nullptr);
      if (_this->_impl_.speech_adaptation_info_ == nullptr) {
        _this->_impl_.speech_adaptation_info_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeechAdaptationInfo>(arena, *from._impl_.speech_adaptation_info_);
      } else {
        _this->_impl_.speech_adaptation_info_->MergeFrom(*from._impl_.speech_adaptation_info_);
      }
    }
  }
  if (from._internal_request_id() != 0) {
    _this->_impl_.request_id_ = from._impl_.request_id_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void LongRunningRecognizeResponse::CopyFrom(const LongRunningRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void LongRunningRecognizeResponse::InternalSwap(LongRunningRecognizeResponse* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.results_.InternalSwap(&other->_impl_.results_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.request_id_)
      + sizeof(LongRunningRecognizeResponse::_impl_.request_id_)
      - PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.total_billed_time_)>(
          reinterpret_cast<char*>(&_impl_.total_billed_time_),
          reinterpret_cast<char*>(&other->_impl_.total_billed_time_));
}

::google::protobuf::Metadata LongRunningRecognizeResponse::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class LongRunningRecognizeMetadata::_Internal {
 public:
  using HasBits =
      decltype(std::declval<LongRunningRecognizeMetadata>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_._has_bits_);
};

void LongRunningRecognizeMetadata::clear_start_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.start_time_ != nullptr) _impl_.start_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
void LongRunningRecognizeMetadata::clear_last_update_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.last_update_time_ != nullptr) _impl_.last_update_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
LongRunningRecognizeMetadata::LongRunningRecognizeMetadata(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.LongRunningRecognizeMetadata)
}
inline PROTOBUF_NDEBUG_INLINE LongRunningRecognizeMetadata::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::LongRunningRecognizeMetadata& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        uri_(arena, from.uri_) {}

LongRunningRecognizeMetadata::LongRunningRecognizeMetadata(
    ::google::protobuf::Arena* arena,
    const LongRunningRecognizeMetadata& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  LongRunningRecognizeMetadata* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.start_time_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Timestamp>(
                              arena, *from._impl_.start_time_)
                        : nullptr;
  _impl_.last_update_time_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Timestamp>(
                              arena, *from._impl_.last_update_time_)
                        : nullptr;
  _impl_.progress_percent_ = from._impl_.progress_percent_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.LongRunningRecognizeMetadata)
}
inline PROTOBUF_NDEBUG_INLINE LongRunningRecognizeMetadata::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        uri_(arena) {}

inline void LongRunningRecognizeMetadata::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, start_time_),
           0,
           offsetof(Impl_, progress_percent_) -
               offsetof(Impl_, start_time_) +
               sizeof(Impl_::progress_percent_));
}
LongRunningRecognizeMetadata::~LongRunningRecognizeMetadata() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  SharedDtor(*this);
}
inline void LongRunningRecognizeMetadata::SharedDtor(MessageLite& self) {
  LongRunningRecognizeMetadata& this_ = static_cast<LongRunningRecognizeMetadata&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.uri_.Destroy();
  delete this_._impl_.start_time_;
  delete this_._impl_.last_update_time_;
  this_._impl_.~Impl_();
}

inline void* LongRunningRecognizeMetadata::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) LongRunningRecognizeMetadata(arena);
}
constexpr auto LongRunningRecognizeMetadata::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(LongRunningRecognizeMetadata),
                                            alignof(LongRunningRecognizeMetadata));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull LongRunningRecognizeMetadata::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_LongRunningRecognizeMetadata_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &LongRunningRecognizeMetadata::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<LongRunningRecognizeMetadata>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &LongRunningRecognizeMetadata::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<LongRunningRecognizeMetadata>(), &LongRunningRecognizeMetadata::ByteSizeLong,
            &LongRunningRecognizeMetadata::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_._cached_size_),
        false,
    },
    &LongRunningRecognizeMetadata::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* LongRunningRecognizeMetadata::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 4, 2, 63, 2> LongRunningRecognizeMetadata::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_._has_bits_),
    0, // no _extensions_
    4, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967280,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::LongRunningRecognizeMetadata>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string uri = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::FastUS1,
     {34, 63, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.uri_)}},
    // int32 progress_percent = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(LongRunningRecognizeMetadata, _impl_.progress_percent_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.progress_percent_)}},
    // .google.protobuf.Timestamp start_time = 2;
    {::_pbi::TcParser::FastMtS1,
     {18, 0, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.start_time_)}},
    // .google.protobuf.Timestamp last_update_time = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 1, 1, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.last_update_time_)}},
  }}, {{
    65535, 65535
  }}, {{
    // int32 progress_percent = 1;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.progress_percent_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // .google.protobuf.Timestamp start_time = 2;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.start_time_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Timestamp last_update_time = 3;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.last_update_time_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // string uri = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.uri_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::protobuf::Timestamp>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Timestamp>()},
  }}, {{
    "\63\0\0\0\3\0\0\0"
    "google.cloud.speech.v1.LongRunningRecognizeMetadata"
    "uri"
  }},
};

PROTOBUF_NOINLINE void LongRunningRecognizeMetadata::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.uri_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.start_time_ != nullptr);
      _impl_.start_time_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.last_update_time_ != nullptr);
      _impl_.last_update_time_->Clear();
    }
  }
  _impl_.progress_percent_ = 0;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* LongRunningRecognizeMetadata::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const LongRunningRecognizeMetadata& this_ = static_cast<const LongRunningRecognizeMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* LongRunningRecognizeMetadata::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const LongRunningRecognizeMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // int32 progress_percent = 1;
          if (this_._internal_progress_percent() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<1>(
                    stream, this_._internal_progress_percent(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.protobuf.Timestamp start_time = 2;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                2, *this_._impl_.start_time_, this_._impl_.start_time_->GetCachedSize(), target,
                stream);
          }

          // .google.protobuf.Timestamp last_update_time = 3;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                3, *this_._impl_.last_update_time_, this_._impl_.last_update_time_->GetCachedSize(), target,
                stream);
          }

          // string uri = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
          if (!this_._internal_uri().empty()) {
            const std::string& _s = this_._internal_uri();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.LongRunningRecognizeMetadata.uri");
            target = stream->WriteStringMaybeAliased(4, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.LongRunningRecognizeMetadata)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t LongRunningRecognizeMetadata::ByteSizeLong(const MessageLite& base) {
          const LongRunningRecognizeMetadata& this_ = static_cast<const LongRunningRecognizeMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t LongRunningRecognizeMetadata::ByteSizeLong() const {
          const LongRunningRecognizeMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string uri = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
            if (!this_._internal_uri().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_uri());
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .google.protobuf.Timestamp start_time = 2;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.start_time_);
            }
            // .google.protobuf.Timestamp last_update_time = 3;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.last_update_time_);
            }
          }
           {
            // int32 progress_percent = 1;
            if (this_._internal_progress_percent() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_progress_percent());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void LongRunningRecognizeMetadata::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<LongRunningRecognizeMetadata*>(&to_msg);
  auto& from = static_cast<const LongRunningRecognizeMetadata&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_uri().empty()) {
    _this->_internal_set_uri(from._internal_uri());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.start_time_ != nullptr);
      if (_this->_impl_.start_time_ == nullptr) {
        _this->_impl_.start_time_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Timestamp>(arena, *from._impl_.start_time_);
      } else {
        _this->_impl_.start_time_->MergeFrom(*from._impl_.start_time_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.last_update_time_ != nullptr);
      if (_this->_impl_.last_update_time_ == nullptr) {
        _this->_impl_.last_update_time_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Timestamp>(arena, *from._impl_.last_update_time_);
      } else {
        _this->_impl_.last_update_time_->MergeFrom(*from._impl_.last_update_time_);
      }
    }
  }
  if (from._internal_progress_percent() != 0) {
    _this->_impl_.progress_percent_ = from._impl_.progress_percent_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void LongRunningRecognizeMetadata::CopyFrom(const LongRunningRecognizeMetadata& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void LongRunningRecognizeMetadata::InternalSwap(LongRunningRecognizeMetadata* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.uri_, &other->_impl_.uri_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.progress_percent_)
      + sizeof(LongRunningRecognizeMetadata::_impl_.progress_percent_)
      - PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.start_time_)>(
          reinterpret_cast<char*>(&_impl_.start_time_),
          reinterpret_cast<char*>(&other->_impl_.start_time_));
}

::google::protobuf::Metadata LongRunningRecognizeMetadata::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognizeResponse::_Internal {
 public:
  using HasBits =
      decltype(std::declval<StreamingRecognizeResponse>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_._has_bits_);
};

void StreamingRecognizeResponse::clear_error() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.error_ != nullptr) _impl_.error_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
void StreamingRecognizeResponse::clear_speech_event_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.speech_event_time_ != nullptr) _impl_.speech_event_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000004u;
}
void StreamingRecognizeResponse::clear_total_billed_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.total_billed_time_ != nullptr) _impl_.total_billed_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
StreamingRecognizeResponse::StreamingRecognizeResponse(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::StreamingRecognizeResponse& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        results_{visibility, arena, from.results_} {}

StreamingRecognizeResponse::StreamingRecognizeResponse(
    ::google::protobuf::Arena* arena,
    const StreamingRecognizeResponse& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognizeResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.error_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::rpc::Status>(
                              arena, *from._impl_.error_)
                        : nullptr;
  _impl_.total_billed_time_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.total_billed_time_)
                        : nullptr;
  _impl_.speech_event_time_ = (cached_has_bits & 0x00000004u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.speech_event_time_)
                        : nullptr;
  _impl_.speech_adaptation_info_ = (cached_has_bits & 0x00000008u) ? ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeechAdaptationInfo>(
                              arena, *from._impl_.speech_adaptation_info_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, request_id_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, request_id_),
           offsetof(Impl_, speech_event_type_) -
               offsetof(Impl_, request_id_) +
               sizeof(Impl_::speech_event_type_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognizeResponse)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognizeResponse::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        results_{visibility, arena} {}

inline void StreamingRecognizeResponse::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, error_),
           0,
           offsetof(Impl_, speech_event_type_) -
               offsetof(Impl_, error_) +
               sizeof(Impl_::speech_event_type_));
}
StreamingRecognizeResponse::~StreamingRecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognizeResponse)
  SharedDtor(*this);
}
inline void StreamingRecognizeResponse::SharedDtor(MessageLite& self) {
  StreamingRecognizeResponse& this_ = static_cast<StreamingRecognizeResponse&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.error_;
  delete this_._impl_.total_billed_time_;
  delete this_._impl_.speech_event_time_;
  delete this_._impl_.speech_adaptation_info_;
  this_._impl_.~Impl_();
}

inline void* StreamingRecognizeResponse::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) StreamingRecognizeResponse(arena);
}
constexpr auto StreamingRecognizeResponse::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.results_) +
          decltype(StreamingRecognizeResponse::_impl_.results_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(StreamingRecognizeResponse), alignof(StreamingRecognizeResponse), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&StreamingRecognizeResponse::PlacementNew_,
                                 sizeof(StreamingRecognizeResponse),
                                 alignof(StreamingRecognizeResponse));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull StreamingRecognizeResponse::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_StreamingRecognizeResponse_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &StreamingRecognizeResponse::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<StreamingRecognizeResponse>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &StreamingRecognizeResponse::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<StreamingRecognizeResponse>(), &StreamingRecognizeResponse::ByteSizeLong,
            &StreamingRecognizeResponse::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_._cached_size_),
        false,
    },
    &StreamingRecognizeResponse::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* StreamingRecognizeResponse::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 7, 5, 0, 2> StreamingRecognizeResponse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_._has_bits_),
    0, // no _extensions_
    10, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294966372,  // skipmap
    offsetof(decltype(_table_), field_entries),
    7,  // num_field_entries
    5,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognizeResponse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.protobuf.Duration speech_event_time = 8;
    {::_pbi::TcParser::FastMtS1,
     {66, 2, 3, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_time_)}},
    // .google.rpc.Status error = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.error_)}},
    // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;
    {::_pbi::TcParser::FastMtR1,
     {18, 63, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.results_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(StreamingRecognizeResponse, _impl_.speech_event_type_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_type_)}},
    // .google.protobuf.Duration total_billed_time = 5;
    {::_pbi::TcParser::FastMtS1,
     {42, 1, 2, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.total_billed_time_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.rpc.Status error = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.error_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.results_), -1, 1,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_type_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // .google.protobuf.Duration total_billed_time = 5;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.total_billed_time_), _Internal::kHasBitsOffset + 1, 2,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration speech_event_time = 8;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_time_), _Internal::kHasBitsOffset + 2, 3,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 9;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_adaptation_info_), _Internal::kHasBitsOffset + 3, 4,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 request_id = 10;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.request_id_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::rpc::Status>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionResult>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptationInfo>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void StreamingRecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognizeResponse)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.results_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x0000000fu) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.error_ != nullptr);
      _impl_.error_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.total_billed_time_ != nullptr);
      _impl_.total_billed_time_->Clear();
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(_impl_.speech_event_time_ != nullptr);
      _impl_.speech_event_time_->Clear();
    }
    if (cached_has_bits & 0x00000008u) {
      ABSL_DCHECK(_impl_.speech_adaptation_info_ != nullptr);
      _impl_.speech_adaptation_info_->Clear();
    }
  }
  ::memset(&_impl_.request_id_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.speech_event_type_) -
      reinterpret_cast<char*>(&_impl_.request_id_)) + sizeof(_impl_.speech_event_type_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* StreamingRecognizeResponse::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const StreamingRecognizeResponse& this_ = static_cast<const StreamingRecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* StreamingRecognizeResponse::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const StreamingRecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognizeResponse)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.rpc.Status error = 1;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                1, *this_._impl_.error_, this_._impl_.error_->GetCachedSize(), target,
                stream);
          }

          // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_results_size());
               i < n; i++) {
            const auto& repfield = this_._internal_results().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    2, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;
          if (this_._internal_speech_event_type() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                4, this_._internal_speech_event_type(), target);
          }

          // .google.protobuf.Duration total_billed_time = 5;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                5, *this_._impl_.total_billed_time_, this_._impl_.total_billed_time_->GetCachedSize(), target,
                stream);
          }

          // .google.protobuf.Duration speech_event_time = 8;
          if (cached_has_bits & 0x00000004u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                8, *this_._impl_.speech_event_time_, this_._impl_.speech_event_time_->GetCachedSize(), target,
                stream);
          }

          // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 9;
          if (cached_has_bits & 0x00000008u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                9, *this_._impl_.speech_adaptation_info_, this_._impl_.speech_adaptation_info_->GetCachedSize(), target,
                stream);
          }

          // int64 request_id = 10;
          if (this_._internal_request_id() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<10>(
                    stream, this_._internal_request_id(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognizeResponse)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t StreamingRecognizeResponse::ByteSizeLong(const MessageLite& base) {
          const StreamingRecognizeResponse& this_ = static_cast<const StreamingRecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t StreamingRecognizeResponse::ByteSizeLong() const {
          const StreamingRecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognizeResponse)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;
            {
              total_size += 1UL * this_._internal_results_size();
              for (const auto& msg : this_._internal_results()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x0000000fu) {
            // .google.rpc.Status error = 1;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.error_);
            }
            // .google.protobuf.Duration total_billed_time = 5;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.total_billed_time_);
            }
            // .google.protobuf.Duration speech_event_time = 8;
            if (cached_has_bits & 0x00000004u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_event_time_);
            }
            // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 9;
            if (cached_has_bits & 0x00000008u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_adaptation_info_);
            }
          }
           {
            // int64 request_id = 10;
            if (this_._internal_request_id() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_request_id());
            }
            // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;
            if (this_._internal_speech_event_type() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_speech_event_type());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void StreamingRecognizeResponse::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognizeResponse*>(&to_msg);
  auto& from = static_cast<const StreamingRecognizeResponse&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognizeResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_results()->MergeFrom(
      from._internal_results());
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x0000000fu) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.error_ != nullptr);
      if (_this->_impl_.error_ == nullptr) {
        _this->_impl_.error_ =
            ::google::protobuf::Message::CopyConstruct<::google::rpc::Status>(arena, *from._impl_.error_);
      } else {
        _this->_impl_.error_->MergeFrom(*from._impl_.error_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.total_billed_time_ != nullptr);
      if (_this->_impl_.total_billed_time_ == nullptr) {
        _this->_impl_.total_billed_time_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.total_billed_time_);
      } else {
        _this->_impl_.total_billed_time_->MergeFrom(*from._impl_.total_billed_time_);
      }
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(from._impl_.speech_event_time_ != nullptr);
      if (_this->_impl_.speech_event_time_ == nullptr) {
        _this->_impl_.speech_event_time_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.speech_event_time_);
      } else {
        _this->_impl_.speech_event_time_->MergeFrom(*from._impl_.speech_event_time_);
      }
    }
    if (cached_has_bits & 0x00000008u) {
      ABSL_DCHECK(from._impl_.speech_adaptation_info_ != nullptr);
      if (_this->_impl_.speech_adaptation_info_ == nullptr) {
        _this->_impl_.speech_adaptation_info_ =
            ::google::protobuf::Message::CopyConstruct<::google::cloud::speech::v1::SpeechAdaptationInfo>(arena, *from._impl_.speech_adaptation_info_);
      } else {
        _this->_impl_.speech_adaptation_info_->MergeFrom(*from._impl_.speech_adaptation_info_);
      }
    }
  }
  if (from._internal_request_id() != 0) {
    _this->_impl_.request_id_ = from._impl_.request_id_;
  }
  if (from._internal_speech_event_type() != 0) {
    _this->_impl_.speech_event_type_ = from._impl_.speech_event_type_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognizeResponse::CopyFrom(const StreamingRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognizeResponse::InternalSwap(StreamingRecognizeResponse* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.results_.InternalSwap(&other->_impl_.results_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_type_)
      + sizeof(StreamingRecognizeResponse::_impl_.speech_event_type_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.error_)>(
          reinterpret_cast<char*>(&_impl_.error_),
          reinterpret_cast<char*>(&other->_impl_.error_));
}

::google::protobuf::Metadata StreamingRecognizeResponse::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognitionResult::_Internal {
 public:
  using HasBits =
      decltype(std::declval<StreamingRecognitionResult>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_._has_bits_);
};

void StreamingRecognitionResult::clear_result_end_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.result_end_time_ != nullptr) _impl_.result_end_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
StreamingRecognitionResult::StreamingRecognitionResult(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognitionResult)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionResult::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::StreamingRecognitionResult& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        alternatives_{visibility, arena, from.alternatives_},
        language_code_(arena, from.language_code_) {}

StreamingRecognitionResult::StreamingRecognitionResult(
    ::google::protobuf::Arena* arena,
    const StreamingRecognitionResult& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognitionResult* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.result_end_time_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.result_end_time_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, is_final_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, is_final_),
           offsetof(Impl_, channel_tag_) -
               offsetof(Impl_, is_final_) +
               sizeof(Impl_::channel_tag_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognitionResult)
}
inline PROTOBUF_NDEBUG_INLINE StreamingRecognitionResult::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        alternatives_{visibility, arena},
        language_code_(arena) {}

inline void StreamingRecognitionResult::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, result_end_time_),
           0,
           offsetof(Impl_, channel_tag_) -
               offsetof(Impl_, result_end_time_) +
               sizeof(Impl_::channel_tag_));
}
StreamingRecognitionResult::~StreamingRecognitionResult() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognitionResult)
  SharedDtor(*this);
}
inline void StreamingRecognitionResult::SharedDtor(MessageLite& self) {
  StreamingRecognitionResult& this_ = static_cast<StreamingRecognitionResult&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.language_code_.Destroy();
  delete this_._impl_.result_end_time_;
  this_._impl_.~Impl_();
}

inline void* StreamingRecognitionResult::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) StreamingRecognitionResult(arena);
}
constexpr auto StreamingRecognitionResult::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.alternatives_) +
          decltype(StreamingRecognitionResult::_impl_.alternatives_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(StreamingRecognitionResult), alignof(StreamingRecognitionResult), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&StreamingRecognitionResult::PlacementNew_,
                                 sizeof(StreamingRecognitionResult),
                                 alignof(StreamingRecognitionResult));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull StreamingRecognitionResult::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_StreamingRecognitionResult_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &StreamingRecognitionResult::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<StreamingRecognitionResult>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &StreamingRecognitionResult::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<StreamingRecognitionResult>(), &StreamingRecognitionResult::ByteSizeLong,
            &StreamingRecognitionResult::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_._cached_size_),
        false,
    },
    &StreamingRecognitionResult::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* StreamingRecognitionResult::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 2, 71, 2> StreamingRecognitionResult::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_._has_bits_),
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967232,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionResult>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.alternatives_)}},
    // bool is_final = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionResult, _impl_.is_final_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.is_final_)}},
    // float stability = 3;
    {::_pbi::TcParser::FastF32S1,
     {29, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.stability_)}},
    // .google.protobuf.Duration result_end_time = 4;
    {::_pbi::TcParser::FastMtS1,
     {34, 0, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.result_end_time_)}},
    // int32 channel_tag = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(StreamingRecognitionResult, _impl_.channel_tag_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.channel_tag_)}},
    // string language_code = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::FastUS1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.language_code_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.alternatives_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool is_final = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.is_final_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // float stability = 3;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.stability_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
    // .google.protobuf.Duration result_end_time = 4;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.result_end_time_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int32 channel_tag = 5;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.channel_tag_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // string language_code = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.language_code_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionAlternative>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
  }}, {{
    "\61\0\0\0\0\0\15\0"
    "google.cloud.speech.v1.StreamingRecognitionResult"
    "language_code"
  }},
};

PROTOBUF_NOINLINE void StreamingRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognitionResult)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.alternatives_.Clear();
  _impl_.language_code_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.result_end_time_ != nullptr);
    _impl_.result_end_time_->Clear();
  }
  ::memset(&_impl_.is_final_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.channel_tag_) -
      reinterpret_cast<char*>(&_impl_.is_final_)) + sizeof(_impl_.channel_tag_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* StreamingRecognitionResult::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const StreamingRecognitionResult& this_ = static_cast<const StreamingRecognitionResult&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* StreamingRecognitionResult::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const StreamingRecognitionResult& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognitionResult)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_alternatives_size());
               i < n; i++) {
            const auto& repfield = this_._internal_alternatives().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    1, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // bool is_final = 2;
          if (this_._internal_is_final() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                2, this_._internal_is_final(), target);
          }

          // float stability = 3;
          if (::absl::bit_cast<::uint32_t>(this_._internal_stability()) != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteFloatToArray(
                3, this_._internal_stability(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.protobuf.Duration result_end_time = 4;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                4, *this_._impl_.result_end_time_, this_._impl_.result_end_time_->GetCachedSize(), target,
                stream);
          }

          // int32 channel_tag = 5;
          if (this_._internal_channel_tag() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<5>(
                    stream, this_._internal_channel_tag(), target);
          }

          // string language_code = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
          if (!this_._internal_language_code().empty()) {
            const std::string& _s = this_._internal_language_code();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.StreamingRecognitionResult.language_code");
            target = stream->WriteStringMaybeAliased(6, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognitionResult)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t StreamingRecognitionResult::ByteSizeLong(const MessageLite& base) {
          const StreamingRecognitionResult& this_ = static_cast<const StreamingRecognitionResult&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t StreamingRecognitionResult::ByteSizeLong() const {
          const StreamingRecognitionResult& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognitionResult)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
            {
              total_size += 1UL * this_._internal_alternatives_size();
              for (const auto& msg : this_._internal_alternatives()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
           {
            // string language_code = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
            if (!this_._internal_language_code().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_language_code());
            }
          }
           {
            // .google.protobuf.Duration result_end_time = 4;
            cached_has_bits = this_._impl_._has_bits_[0];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.result_end_time_);
            }
          }
           {
            // bool is_final = 2;
            if (this_._internal_is_final() != 0) {
              total_size += 2;
            }
            // float stability = 3;
            if (::absl::bit_cast<::uint32_t>(this_._internal_stability()) != 0) {
              total_size += 5;
            }
            // int32 channel_tag = 5;
            if (this_._internal_channel_tag() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_channel_tag());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void StreamingRecognitionResult::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognitionResult*>(&to_msg);
  auto& from = static_cast<const StreamingRecognitionResult&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognitionResult)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_alternatives()->MergeFrom(
      from._internal_alternatives());
  if (!from._internal_language_code().empty()) {
    _this->_internal_set_language_code(from._internal_language_code());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(from._impl_.result_end_time_ != nullptr);
    if (_this->_impl_.result_end_time_ == nullptr) {
      _this->_impl_.result_end_time_ =
          ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.result_end_time_);
    } else {
      _this->_impl_.result_end_time_->MergeFrom(*from._impl_.result_end_time_);
    }
  }
  if (from._internal_is_final() != 0) {
    _this->_impl_.is_final_ = from._impl_.is_final_;
  }
  if (::absl::bit_cast<::uint32_t>(from._internal_stability()) != 0) {
    _this->_impl_.stability_ = from._impl_.stability_;
  }
  if (from._internal_channel_tag() != 0) {
    _this->_impl_.channel_tag_ = from._impl_.channel_tag_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognitionResult::CopyFrom(const StreamingRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognitionResult::InternalSwap(StreamingRecognitionResult* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.alternatives_.InternalSwap(&other->_impl_.alternatives_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.language_code_, &other->_impl_.language_code_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.channel_tag_)
      + sizeof(StreamingRecognitionResult::_impl_.channel_tag_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.result_end_time_)>(
          reinterpret_cast<char*>(&_impl_.result_end_time_),
          reinterpret_cast<char*>(&other->_impl_.result_end_time_));
}

::google::protobuf::Metadata StreamingRecognitionResult::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeechRecognitionResult::_Internal {
 public:
  using HasBits =
      decltype(std::declval<SpeechRecognitionResult>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_._has_bits_);
};

void SpeechRecognitionResult::clear_result_end_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.result_end_time_ != nullptr) _impl_.result_end_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
SpeechRecognitionResult::SpeechRecognitionResult(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeechRecognitionResult)
}
inline PROTOBUF_NDEBUG_INLINE SpeechRecognitionResult::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::SpeechRecognitionResult& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        alternatives_{visibility, arena, from.alternatives_},
        language_code_(arena, from.language_code_) {}

SpeechRecognitionResult::SpeechRecognitionResult(
    ::google::protobuf::Arena* arena,
    const SpeechRecognitionResult& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SpeechRecognitionResult* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.result_end_time_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.result_end_time_)
                        : nullptr;
  _impl_.channel_tag_ = from._impl_.channel_tag_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.SpeechRecognitionResult)
}
inline PROTOBUF_NDEBUG_INLINE SpeechRecognitionResult::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        alternatives_{visibility, arena},
        language_code_(arena) {}

inline void SpeechRecognitionResult::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, result_end_time_),
           0,
           offsetof(Impl_, channel_tag_) -
               offsetof(Impl_, result_end_time_) +
               sizeof(Impl_::channel_tag_));
}
SpeechRecognitionResult::~SpeechRecognitionResult() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeechRecognitionResult)
  SharedDtor(*this);
}
inline void SpeechRecognitionResult::SharedDtor(MessageLite& self) {
  SpeechRecognitionResult& this_ = static_cast<SpeechRecognitionResult&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.language_code_.Destroy();
  delete this_._impl_.result_end_time_;
  this_._impl_.~Impl_();
}

inline void* SpeechRecognitionResult::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) SpeechRecognitionResult(arena);
}
constexpr auto SpeechRecognitionResult::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.alternatives_) +
          decltype(SpeechRecognitionResult::_impl_.alternatives_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(SpeechRecognitionResult), alignof(SpeechRecognitionResult), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&SpeechRecognitionResult::PlacementNew_,
                                 sizeof(SpeechRecognitionResult),
                                 alignof(SpeechRecognitionResult));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull SpeechRecognitionResult::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_SpeechRecognitionResult_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &SpeechRecognitionResult::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<SpeechRecognitionResult>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &SpeechRecognitionResult::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<SpeechRecognitionResult>(), &SpeechRecognitionResult::ByteSizeLong,
            &SpeechRecognitionResult::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_._cached_size_),
        false,
    },
    &SpeechRecognitionResult::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* SpeechRecognitionResult::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 4, 2, 68, 2> SpeechRecognitionResult::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_._has_bits_),
    0, // no _extensions_
    5, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967268,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionResult>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.alternatives_)}},
    // int32 channel_tag = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeechRecognitionResult, _impl_.channel_tag_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.protobuf.Duration result_end_time = 4;
    {::_pbi::TcParser::FastMtS1,
     {34, 0, 1, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.result_end_time_)}},
    // string language_code = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::FastUS1,
     {42, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.language_code_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.alternatives_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // int32 channel_tag = 2;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // .google.protobuf.Duration result_end_time = 4;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.result_end_time_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // string language_code = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.language_code_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionAlternative>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
  }}, {{
    "\56\0\0\0\15\0\0\0"
    "google.cloud.speech.v1.SpeechRecognitionResult"
    "language_code"
  }},
};

PROTOBUF_NOINLINE void SpeechRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeechRecognitionResult)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.alternatives_.Clear();
  _impl_.language_code_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.result_end_time_ != nullptr);
    _impl_.result_end_time_->Clear();
  }
  _impl_.channel_tag_ = 0;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* SpeechRecognitionResult::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const SpeechRecognitionResult& this_ = static_cast<const SpeechRecognitionResult&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* SpeechRecognitionResult::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const SpeechRecognitionResult& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeechRecognitionResult)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_alternatives_size());
               i < n; i++) {
            const auto& repfield = this_._internal_alternatives().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    1, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // int32 channel_tag = 2;
          if (this_._internal_channel_tag() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<2>(
                    stream, this_._internal_channel_tag(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.protobuf.Duration result_end_time = 4;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                4, *this_._impl_.result_end_time_, this_._impl_.result_end_time_->GetCachedSize(), target,
                stream);
          }

          // string language_code = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
          if (!this_._internal_language_code().empty()) {
            const std::string& _s = this_._internal_language_code();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.SpeechRecognitionResult.language_code");
            target = stream->WriteStringMaybeAliased(5, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeechRecognitionResult)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t SpeechRecognitionResult::ByteSizeLong(const MessageLite& base) {
          const SpeechRecognitionResult& this_ = static_cast<const SpeechRecognitionResult&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t SpeechRecognitionResult::ByteSizeLong() const {
          const SpeechRecognitionResult& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeechRecognitionResult)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
            {
              total_size += 1UL * this_._internal_alternatives_size();
              for (const auto& msg : this_._internal_alternatives()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
           {
            // string language_code = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
            if (!this_._internal_language_code().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_language_code());
            }
          }
           {
            // .google.protobuf.Duration result_end_time = 4;
            cached_has_bits = this_._impl_._has_bits_[0];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.result_end_time_);
            }
          }
           {
            // int32 channel_tag = 2;
            if (this_._internal_channel_tag() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_channel_tag());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void SpeechRecognitionResult::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeechRecognitionResult*>(&to_msg);
  auto& from = static_cast<const SpeechRecognitionResult&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeechRecognitionResult)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_alternatives()->MergeFrom(
      from._internal_alternatives());
  if (!from._internal_language_code().empty()) {
    _this->_internal_set_language_code(from._internal_language_code());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(from._impl_.result_end_time_ != nullptr);
    if (_this->_impl_.result_end_time_ == nullptr) {
      _this->_impl_.result_end_time_ =
          ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.result_end_time_);
    } else {
      _this->_impl_.result_end_time_->MergeFrom(*from._impl_.result_end_time_);
    }
  }
  if (from._internal_channel_tag() != 0) {
    _this->_impl_.channel_tag_ = from._impl_.channel_tag_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechRecognitionResult::CopyFrom(const SpeechRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeechRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeechRecognitionResult::InternalSwap(SpeechRecognitionResult* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.alternatives_.InternalSwap(&other->_impl_.alternatives_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.language_code_, &other->_impl_.language_code_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_)
      + sizeof(SpeechRecognitionResult::_impl_.channel_tag_)
      - PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.result_end_time_)>(
          reinterpret_cast<char*>(&_impl_.result_end_time_),
          reinterpret_cast<char*>(&other->_impl_.result_end_time_));
}

::google::protobuf::Metadata SpeechRecognitionResult::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeechRecognitionAlternative::_Internal {
 public:
};

SpeechRecognitionAlternative::SpeechRecognitionAlternative(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeechRecognitionAlternative)
}
inline PROTOBUF_NDEBUG_INLINE SpeechRecognitionAlternative::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::SpeechRecognitionAlternative& from_msg)
      : words_{visibility, arena, from.words_},
        transcript_(arena, from.transcript_),
        _cached_size_{0} {}

SpeechRecognitionAlternative::SpeechRecognitionAlternative(
    ::google::protobuf::Arena* arena,
    const SpeechRecognitionAlternative& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SpeechRecognitionAlternative* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  _impl_.confidence_ = from._impl_.confidence_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.SpeechRecognitionAlternative)
}
inline PROTOBUF_NDEBUG_INLINE SpeechRecognitionAlternative::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : words_{visibility, arena},
        transcript_(arena),
        _cached_size_{0} {}

inline void SpeechRecognitionAlternative::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.confidence_ = {};
}
SpeechRecognitionAlternative::~SpeechRecognitionAlternative() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeechRecognitionAlternative)
  SharedDtor(*this);
}
inline void SpeechRecognitionAlternative::SharedDtor(MessageLite& self) {
  SpeechRecognitionAlternative& this_ = static_cast<SpeechRecognitionAlternative&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.transcript_.Destroy();
  this_._impl_.~Impl_();
}

inline void* SpeechRecognitionAlternative::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) SpeechRecognitionAlternative(arena);
}
constexpr auto SpeechRecognitionAlternative::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.words_) +
          decltype(SpeechRecognitionAlternative::_impl_.words_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(SpeechRecognitionAlternative), alignof(SpeechRecognitionAlternative), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&SpeechRecognitionAlternative::PlacementNew_,
                                 sizeof(SpeechRecognitionAlternative),
                                 alignof(SpeechRecognitionAlternative));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull SpeechRecognitionAlternative::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_SpeechRecognitionAlternative_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &SpeechRecognitionAlternative::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<SpeechRecognitionAlternative>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &SpeechRecognitionAlternative::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<SpeechRecognitionAlternative>(), &SpeechRecognitionAlternative::ByteSizeLong,
            &SpeechRecognitionAlternative::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_._cached_size_),
        false,
    },
    &SpeechRecognitionAlternative::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* SpeechRecognitionAlternative::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 1, 70, 2> SpeechRecognitionAlternative::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    3, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967288,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionAlternative>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // string transcript = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.transcript_)}},
    // float confidence = 2;
    {::_pbi::TcParser::FastF32S1,
     {21, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.confidence_)}},
    // repeated .google.cloud.speech.v1.WordInfo words = 3;
    {::_pbi::TcParser::FastMtR1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.words_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string transcript = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.transcript_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // float confidence = 2;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.confidence_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
    // repeated .google.cloud.speech.v1.WordInfo words = 3;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.words_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::WordInfo>()},
  }}, {{
    "\63\12\0\0\0\0\0\0"
    "google.cloud.speech.v1.SpeechRecognitionAlternative"
    "transcript"
  }},
};

PROTOBUF_NOINLINE void SpeechRecognitionAlternative::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.words_.Clear();
  _impl_.transcript_.ClearToEmpty();
  _impl_.confidence_ = 0;
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* SpeechRecognitionAlternative::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const SpeechRecognitionAlternative& this_ = static_cast<const SpeechRecognitionAlternative&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* SpeechRecognitionAlternative::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const SpeechRecognitionAlternative& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // string transcript = 1;
          if (!this_._internal_transcript().empty()) {
            const std::string& _s = this_._internal_transcript();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.SpeechRecognitionAlternative.transcript");
            target = stream->WriteStringMaybeAliased(1, _s, target);
          }

          // float confidence = 2;
          if (::absl::bit_cast<::uint32_t>(this_._internal_confidence()) != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteFloatToArray(
                2, this_._internal_confidence(), target);
          }

          // repeated .google.cloud.speech.v1.WordInfo words = 3;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_words_size());
               i < n; i++) {
            const auto& repfield = this_._internal_words().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    3, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeechRecognitionAlternative)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t SpeechRecognitionAlternative::ByteSizeLong(const MessageLite& base) {
          const SpeechRecognitionAlternative& this_ = static_cast<const SpeechRecognitionAlternative&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t SpeechRecognitionAlternative::ByteSizeLong() const {
          const SpeechRecognitionAlternative& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .google.cloud.speech.v1.WordInfo words = 3;
            {
              total_size += 1UL * this_._internal_words_size();
              for (const auto& msg : this_._internal_words()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
           {
            // string transcript = 1;
            if (!this_._internal_transcript().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_transcript());
            }
            // float confidence = 2;
            if (::absl::bit_cast<::uint32_t>(this_._internal_confidence()) != 0) {
              total_size += 5;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void SpeechRecognitionAlternative::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeechRecognitionAlternative*>(&to_msg);
  auto& from = static_cast<const SpeechRecognitionAlternative&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_words()->MergeFrom(
      from._internal_words());
  if (!from._internal_transcript().empty()) {
    _this->_internal_set_transcript(from._internal_transcript());
  }
  if (::absl::bit_cast<::uint32_t>(from._internal_confidence()) != 0) {
    _this->_impl_.confidence_ = from._impl_.confidence_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechRecognitionAlternative::CopyFrom(const SpeechRecognitionAlternative& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeechRecognitionAlternative::InternalSwap(SpeechRecognitionAlternative* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.words_.InternalSwap(&other->_impl_.words_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.transcript_, &other->_impl_.transcript_, arena);
        swap(_impl_.confidence_, other->_impl_.confidence_);
}

::google::protobuf::Metadata SpeechRecognitionAlternative::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class WordInfo::_Internal {
 public:
  using HasBits =
      decltype(std::declval<WordInfo>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(WordInfo, _impl_._has_bits_);
};

void WordInfo::clear_start_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.start_time_ != nullptr) _impl_.start_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
void WordInfo::clear_end_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.end_time_ != nullptr) _impl_.end_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
WordInfo::WordInfo(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.WordInfo)
}
inline PROTOBUF_NDEBUG_INLINE WordInfo::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::WordInfo& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        word_(arena, from.word_),
        speaker_label_(arena, from.speaker_label_) {}

WordInfo::WordInfo(
    ::google::protobuf::Arena* arena,
    const WordInfo& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  WordInfo* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.start_time_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.start_time_)
                        : nullptr;
  _impl_.end_time_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(
                              arena, *from._impl_.end_time_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, confidence_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, confidence_),
           offsetof(Impl_, speaker_tag_) -
               offsetof(Impl_, confidence_) +
               sizeof(Impl_::speaker_tag_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.WordInfo)
}
inline PROTOBUF_NDEBUG_INLINE WordInfo::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        word_(arena),
        speaker_label_(arena) {}

inline void WordInfo::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, start_time_),
           0,
           offsetof(Impl_, speaker_tag_) -
               offsetof(Impl_, start_time_) +
               sizeof(Impl_::speaker_tag_));
}
WordInfo::~WordInfo() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.WordInfo)
  SharedDtor(*this);
}
inline void WordInfo::SharedDtor(MessageLite& self) {
  WordInfo& this_ = static_cast<WordInfo&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.word_.Destroy();
  this_._impl_.speaker_label_.Destroy();
  delete this_._impl_.start_time_;
  delete this_._impl_.end_time_;
  this_._impl_.~Impl_();
}

inline void* WordInfo::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) WordInfo(arena);
}
constexpr auto WordInfo::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(WordInfo),
                                            alignof(WordInfo));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull WordInfo::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_WordInfo_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &WordInfo::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<WordInfo>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &WordInfo::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<WordInfo>(), &WordInfo::ByteSizeLong,
            &WordInfo::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(WordInfo, _impl_._cached_size_),
        false,
    },
    &WordInfo::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* WordInfo::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 2, 57, 2> WordInfo::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(WordInfo, _impl_._has_bits_),
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967232,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::WordInfo>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // .google.protobuf.Duration start_time = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_)}},
    // .google.protobuf.Duration end_time = 2;
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 1, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.end_time_)}},
    // string word = 3;
    {::_pbi::TcParser::FastUS1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.word_)}},
    // float confidence = 4;
    {::_pbi::TcParser::FastF32S1,
     {37, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.confidence_)}},
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(WordInfo, _impl_.speaker_tag_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_)}},
    // string speaker_label = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::FastUS1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_label_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.protobuf.Duration start_time = 1;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration end_time = 2;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.end_time_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // string word = 3;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.word_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // float confidence = 4;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.confidence_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // string speaker_label = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_label_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }}, {{
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
    {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
  }}, {{
    "\37\0\0\4\0\0\15\0"
    "google.cloud.speech.v1.WordInfo"
    "word"
    "speaker_label"
  }},
};

PROTOBUF_NOINLINE void WordInfo::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.WordInfo)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.word_.ClearToEmpty();
  _impl_.speaker_label_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.start_time_ != nullptr);
      _impl_.start_time_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.end_time_ != nullptr);
      _impl_.end_time_->Clear();
    }
  }
  ::memset(&_impl_.confidence_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.speaker_tag_) -
      reinterpret_cast<char*>(&_impl_.confidence_)) + sizeof(_impl_.speaker_tag_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* WordInfo::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const WordInfo& this_ = static_cast<const WordInfo&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* WordInfo::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const WordInfo& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.WordInfo)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          cached_has_bits = this_._impl_._has_bits_[0];
          // .google.protobuf.Duration start_time = 1;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                1, *this_._impl_.start_time_, this_._impl_.start_time_->GetCachedSize(), target,
                stream);
          }

          // .google.protobuf.Duration end_time = 2;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                2, *this_._impl_.end_time_, this_._impl_.end_time_->GetCachedSize(), target,
                stream);
          }

          // string word = 3;
          if (!this_._internal_word().empty()) {
            const std::string& _s = this_._internal_word();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.WordInfo.word");
            target = stream->WriteStringMaybeAliased(3, _s, target);
          }

          // float confidence = 4;
          if (::absl::bit_cast<::uint32_t>(this_._internal_confidence()) != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteFloatToArray(
                4, this_._internal_confidence(), target);
          }

          // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
          if (this_._internal_speaker_tag() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<5>(
                    stream, this_._internal_speaker_tag(), target);
          }

          // string speaker_label = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
          if (!this_._internal_speaker_label().empty()) {
            const std::string& _s = this_._internal_speaker_label();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.WordInfo.speaker_label");
            target = stream->WriteStringMaybeAliased(6, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.WordInfo)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t WordInfo::ByteSizeLong(const MessageLite& base) {
          const WordInfo& this_ = static_cast<const WordInfo&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t WordInfo::ByteSizeLong() const {
          const WordInfo& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.WordInfo)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string word = 3;
            if (!this_._internal_word().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_word());
            }
            // string speaker_label = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
            if (!this_._internal_speaker_label().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_speaker_label());
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .google.protobuf.Duration start_time = 1;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.start_time_);
            }
            // .google.protobuf.Duration end_time = 2;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.end_time_);
            }
          }
           {
            // float confidence = 4;
            if (::absl::bit_cast<::uint32_t>(this_._internal_confidence()) != 0) {
              total_size += 5;
            }
            // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
            if (this_._internal_speaker_tag() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_speaker_tag());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void WordInfo::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<WordInfo*>(&to_msg);
  auto& from = static_cast<const WordInfo&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.WordInfo)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_word().empty()) {
    _this->_internal_set_word(from._internal_word());
  }
  if (!from._internal_speaker_label().empty()) {
    _this->_internal_set_speaker_label(from._internal_speaker_label());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.start_time_ != nullptr);
      if (_this->_impl_.start_time_ == nullptr) {
        _this->_impl_.start_time_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.start_time_);
      } else {
        _this->_impl_.start_time_->MergeFrom(*from._impl_.start_time_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.end_time_ != nullptr);
      if (_this->_impl_.end_time_ == nullptr) {
        _this->_impl_.end_time_ =
            ::google::protobuf::Message::CopyConstruct<::google::protobuf::Duration>(arena, *from._impl_.end_time_);
      } else {
        _this->_impl_.end_time_->MergeFrom(*from._impl_.end_time_);
      }
    }
  }
  if (::absl::bit_cast<::uint32_t>(from._internal_confidence()) != 0) {
    _this->_impl_.confidence_ = from._impl_.confidence_;
  }
  if (from._internal_speaker_tag() != 0) {
    _this->_impl_.speaker_tag_ = from._impl_.speaker_tag_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void WordInfo::CopyFrom(const WordInfo& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.WordInfo)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void WordInfo::InternalSwap(WordInfo* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.word_, &other->_impl_.word_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.speaker_label_, &other->_impl_.speaker_label_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_)
      + sizeof(WordInfo::_impl_.speaker_tag_)
      - PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_)>(
          reinterpret_cast<char*>(&_impl_.start_time_),
          reinterpret_cast<char*>(&other->_impl_.start_time_));
}

::google::protobuf::Metadata WordInfo::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeechAdaptationInfo::_Internal {
 public:
};

SpeechAdaptationInfo::SpeechAdaptationInfo(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeechAdaptationInfo)
}
inline PROTOBUF_NDEBUG_INLINE SpeechAdaptationInfo::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::google::cloud::speech::v1::SpeechAdaptationInfo& from_msg)
      : timeout_message_(arena, from.timeout_message_),
        _cached_size_{0} {}

SpeechAdaptationInfo::SpeechAdaptationInfo(
    ::google::protobuf::Arena* arena,
    const SpeechAdaptationInfo& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SpeechAdaptationInfo* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  _impl_.adaptation_timeout_ = from._impl_.adaptation_timeout_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.SpeechAdaptationInfo)
}
inline PROTOBUF_NDEBUG_INLINE SpeechAdaptationInfo::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : timeout_message_(arena),
        _cached_size_{0} {}

inline void SpeechAdaptationInfo::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.adaptation_timeout_ = {};
}
SpeechAdaptationInfo::~SpeechAdaptationInfo() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeechAdaptationInfo)
  SharedDtor(*this);
}
inline void SpeechAdaptationInfo::SharedDtor(MessageLite& self) {
  SpeechAdaptationInfo& this_ = static_cast<SpeechAdaptationInfo&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.timeout_message_.Destroy();
  this_._impl_.~Impl_();
}

inline void* SpeechAdaptationInfo::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) SpeechAdaptationInfo(arena);
}
constexpr auto SpeechAdaptationInfo::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(SpeechAdaptationInfo),
                                            alignof(SpeechAdaptationInfo));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull SpeechAdaptationInfo::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_SpeechAdaptationInfo_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &SpeechAdaptationInfo::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<SpeechAdaptationInfo>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &SpeechAdaptationInfo::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<SpeechAdaptationInfo>(), &SpeechAdaptationInfo::ByteSizeLong,
            &SpeechAdaptationInfo::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_._cached_size_),
        false,
    },
    &SpeechAdaptationInfo::kDescriptorMethods,
    &descriptor_table_cloud_5fspeech_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* SpeechAdaptationInfo::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 67, 2> SpeechAdaptationInfo::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    4, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967286,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptationInfo>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string timeout_message = 4;
    {::_pbi::TcParser::FastUS1,
     {34, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_.timeout_message_)}},
    // bool adaptation_timeout = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(SpeechAdaptationInfo, _impl_.adaptation_timeout_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_.adaptation_timeout_)}},
  }}, {{
    65535, 65535
  }}, {{
    // bool adaptation_timeout = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_.adaptation_timeout_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // string timeout_message = 4;
    {PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_.timeout_message_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\53\0\17\0\0\0\0\0"
    "google.cloud.speech.v1.SpeechAdaptationInfo"
    "timeout_message"
  }},
};

PROTOBUF_NOINLINE void SpeechAdaptationInfo::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeechAdaptationInfo)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.timeout_message_.ClearToEmpty();
  _impl_.adaptation_timeout_ = false;
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* SpeechAdaptationInfo::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const SpeechAdaptationInfo& this_ = static_cast<const SpeechAdaptationInfo&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* SpeechAdaptationInfo::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const SpeechAdaptationInfo& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeechAdaptationInfo)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // bool adaptation_timeout = 1;
          if (this_._internal_adaptation_timeout() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                1, this_._internal_adaptation_timeout(), target);
          }

          // string timeout_message = 4;
          if (!this_._internal_timeout_message().empty()) {
            const std::string& _s = this_._internal_timeout_message();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.SpeechAdaptationInfo.timeout_message");
            target = stream->WriteStringMaybeAliased(4, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeechAdaptationInfo)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t SpeechAdaptationInfo::ByteSizeLong(const MessageLite& base) {
          const SpeechAdaptationInfo& this_ = static_cast<const SpeechAdaptationInfo&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t SpeechAdaptationInfo::ByteSizeLong() const {
          const SpeechAdaptationInfo& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeechAdaptationInfo)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string timeout_message = 4;
            if (!this_._internal_timeout_message().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_timeout_message());
            }
            // bool adaptation_timeout = 1;
            if (this_._internal_adaptation_timeout() != 0) {
              total_size += 2;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void SpeechAdaptationInfo::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeechAdaptationInfo*>(&to_msg);
  auto& from = static_cast<const SpeechAdaptationInfo&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeechAdaptationInfo)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_timeout_message().empty()) {
    _this->_internal_set_timeout_message(from._internal_timeout_message());
  }
  if (from._internal_adaptation_timeout() != 0) {
    _this->_impl_.adaptation_timeout_ = from._impl_.adaptation_timeout_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechAdaptationInfo::CopyFrom(const SpeechAdaptationInfo& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeechAdaptationInfo)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeechAdaptationInfo::InternalSwap(SpeechAdaptationInfo* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.timeout_message_, &other->_impl_.timeout_message_, arena);
        swap(_impl_.adaptation_timeout_, other->_impl_.adaptation_timeout_);
}

::google::protobuf::Metadata SpeechAdaptationInfo::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// @@protoc_insertion_point(namespace_scope)
}  // namespace v1
}  // namespace speech
}  // namespace cloud
}  // namespace google
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google
// @@protoc_insertion_point(global_scope)
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::std::false_type
    _static_init2_ PROTOBUF_UNUSED =
        (::_pbi::AddDescriptors(&descriptor_table_cloud_5fspeech_2eproto),
         ::std::false_type{});
#include "google/protobuf/port_undef.inc"
