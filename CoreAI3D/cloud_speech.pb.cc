// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: CoreAI3D/cloud_speech.proto
// Protobuf C++ Version: 6.32.1

#include "CoreAI3D/cloud_speech.pb.h"

#include <algorithm>
#include <type_traits>
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/generated_message_tctable_impl.h"
#include "google/protobuf/extension_set.h"
#include "google/protobuf/generated_message_util.h"
#include "google/protobuf/wire_format_lite.h"
#include "google/protobuf/descriptor.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/reflection_ops.h"
#include "google/protobuf/wire_format.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"
PROTOBUF_PRAGMA_INIT_SEG
namespace _pb = ::google::protobuf;
namespace _pbi = ::google::protobuf::internal;
namespace _fl = ::google::protobuf::internal::field_layout;
namespace google {
namespace cloud {
namespace speech {
namespace v1 {

inline constexpr TranscriptOutputConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : output_type_{},
        _cached_size_{0},
        _oneof_case_{} {}

template <typename>
PROTOBUF_CONSTEXPR TranscriptOutputConfig::TranscriptOutputConfig(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(TranscriptOutputConfig_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct TranscriptOutputConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR TranscriptOutputConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~TranscriptOutputConfigDefaultTypeInternal() {}
  union {
    TranscriptOutputConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 TranscriptOutputConfigDefaultTypeInternal _TranscriptOutputConfig_default_instance_;

inline constexpr SpeechContext::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        phrases_{},
        boost_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechContext::SpeechContext(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(SpeechContext_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeechContextDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechContextDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechContextDefaultTypeInternal() {}
  union {
    SpeechContext _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechContextDefaultTypeInternal _SpeechContext_default_instance_;

inline constexpr SpeechAdaptationInfo::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        timeout_message_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        adaptation_timeout_{false} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechAdaptationInfo::SpeechAdaptationInfo(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(SpeechAdaptationInfo_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeechAdaptationInfoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechAdaptationInfoDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechAdaptationInfoDefaultTypeInternal() {}
  union {
    SpeechAdaptationInfo _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechAdaptationInfoDefaultTypeInternal _SpeechAdaptationInfo_default_instance_;

inline constexpr SpeakerDiarizationConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        enable_speaker_diarization_{false},
        min_speaker_count_{0},
        max_speaker_count_{0},
        speaker_tag_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeakerDiarizationConfig::SpeakerDiarizationConfig(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(SpeakerDiarizationConfig_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeakerDiarizationConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeakerDiarizationConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeakerDiarizationConfigDefaultTypeInternal() {}
  union {
    SpeakerDiarizationConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeakerDiarizationConfigDefaultTypeInternal _SpeakerDiarizationConfig_default_instance_;

inline constexpr RecognitionMetadata::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        recording_device_name_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        original_mime_type_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        audio_topic_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        interaction_type_{static_cast< ::google::cloud::speech::v1::RecognitionMetadata_InteractionType >(0)},
        industry_naics_code_of_audio_{0u},
        microphone_distance_{static_cast< ::google::cloud::speech::v1::RecognitionMetadata_MicrophoneDistance >(0)},
        original_media_type_{static_cast< ::google::cloud::speech::v1::RecognitionMetadata_OriginalMediaType >(0)},
        recording_device_type_{static_cast< ::google::cloud::speech::v1::RecognitionMetadata_RecordingDeviceType >(0)} {}

template <typename>
PROTOBUF_CONSTEXPR RecognitionMetadata::RecognitionMetadata(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(RecognitionMetadata_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognitionMetadataDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognitionMetadataDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognitionMetadataDefaultTypeInternal() {}
  union {
    RecognitionMetadata _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognitionMetadataDefaultTypeInternal _RecognitionMetadata_default_instance_;

inline constexpr RecognitionAudio::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : audio_source_{},
        _cached_size_{0},
        _oneof_case_{} {}

template <typename>
PROTOBUF_CONSTEXPR RecognitionAudio::RecognitionAudio(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(RecognitionAudio_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognitionAudioDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognitionAudioDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognitionAudioDefaultTypeInternal() {}
  union {
    RecognitionAudio _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognitionAudioDefaultTypeInternal _RecognitionAudio_default_instance_;

inline constexpr WordInfo::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        word_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        speaker_label_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        start_time_{nullptr},
        end_time_{nullptr},
        confidence_{0},
        speaker_tag_{0} {}

template <typename>
PROTOBUF_CONSTEXPR WordInfo::WordInfo(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(WordInfo_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct WordInfoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR WordInfoDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~WordInfoDefaultTypeInternal() {}
  union {
    WordInfo _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 WordInfoDefaultTypeInternal _WordInfo_default_instance_;

inline constexpr StreamingRecognitionConfig_VoiceActivityTimeout::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        speech_start_timeout_{nullptr},
        speech_end_timeout_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognitionConfig_VoiceActivityTimeout::StreamingRecognitionConfig_VoiceActivityTimeout(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(StreamingRecognitionConfig_VoiceActivityTimeout_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognitionConfig_VoiceActivityTimeoutDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognitionConfig_VoiceActivityTimeoutDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognitionConfig_VoiceActivityTimeoutDefaultTypeInternal() {}
  union {
    StreamingRecognitionConfig_VoiceActivityTimeout _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognitionConfig_VoiceActivityTimeoutDefaultTypeInternal _StreamingRecognitionConfig_VoiceActivityTimeout_default_instance_;

inline constexpr LongRunningRecognizeMetadata::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        uri_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        start_time_{nullptr},
        last_update_time_{nullptr},
        progress_percent_{0} {}

template <typename>
PROTOBUF_CONSTEXPR LongRunningRecognizeMetadata::LongRunningRecognizeMetadata(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(LongRunningRecognizeMetadata_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct LongRunningRecognizeMetadataDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LongRunningRecognizeMetadataDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~LongRunningRecognizeMetadataDefaultTypeInternal() {}
  union {
    LongRunningRecognizeMetadata _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LongRunningRecognizeMetadataDefaultTypeInternal _LongRunningRecognizeMetadata_default_instance_;

inline constexpr SpeechRecognitionAlternative::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        words_{},
        transcript_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        confidence_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechRecognitionAlternative::SpeechRecognitionAlternative(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(SpeechRecognitionAlternative_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeechRecognitionAlternativeDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechRecognitionAlternativeDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechRecognitionAlternativeDefaultTypeInternal() {}
  union {
    SpeechRecognitionAlternative _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechRecognitionAlternativeDefaultTypeInternal _SpeechRecognitionAlternative_default_instance_;

inline constexpr StreamingRecognitionResult::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        alternatives_{},
        language_code_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        result_end_time_{nullptr},
        is_final_{false},
        stability_{0},
        channel_tag_{0} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognitionResult::StreamingRecognitionResult(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(StreamingRecognitionResult_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognitionResultDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognitionResultDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognitionResultDefaultTypeInternal() {}
  union {
    StreamingRecognitionResult _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognitionResultDefaultTypeInternal _StreamingRecognitionResult_default_instance_;

inline constexpr SpeechRecognitionResult::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        alternatives_{},
        language_code_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        result_end_time_{nullptr},
        channel_tag_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SpeechRecognitionResult::SpeechRecognitionResult(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(SpeechRecognitionResult_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SpeechRecognitionResultDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SpeechRecognitionResultDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SpeechRecognitionResultDefaultTypeInternal() {}
  union {
    SpeechRecognitionResult _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SpeechRecognitionResultDefaultTypeInternal _SpeechRecognitionResult_default_instance_;

inline constexpr RecognitionConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        speech_contexts_{},
        alternative_language_codes_{},
        language_code_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        model_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        metadata_{nullptr},
        diarization_config_{nullptr},
        adaptation_{nullptr},
        enable_spoken_punctuation_{nullptr},
        enable_spoken_emojis_{nullptr},
        transcript_normalization_{nullptr},
        encoding_{static_cast< ::google::cloud::speech::v1::RecognitionConfig_AudioEncoding >(0)},
        sample_rate_hertz_{0},
        max_alternatives_{0},
        audio_channel_count_{0},
        profanity_filter_{false},
        enable_word_time_offsets_{false},
        enable_automatic_punctuation_{false},
        enable_separate_recognition_per_channel_{false},
        use_enhanced_{false},
        enable_word_confidence_{false} {}

template <typename>
PROTOBUF_CONSTEXPR RecognitionConfig::RecognitionConfig(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(RecognitionConfig_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognitionConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognitionConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognitionConfigDefaultTypeInternal() {}
  union {
    RecognitionConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognitionConfigDefaultTypeInternal _RecognitionConfig_default_instance_;

inline constexpr StreamingRecognizeResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        results_{},
        error_{nullptr},
        total_billed_time_{nullptr},
        speech_event_time_{nullptr},
        speech_adaptation_info_{nullptr},
        request_id_{::int64_t{0}},
        speech_event_type_{static_cast< ::google::cloud::speech::v1::StreamingRecognizeResponse_SpeechEventType >(0)} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognizeResponse::StreamingRecognizeResponse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(StreamingRecognizeResponse_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognizeResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognizeResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognizeResponseDefaultTypeInternal() {}
  union {
    StreamingRecognizeResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognizeResponseDefaultTypeInternal _StreamingRecognizeResponse_default_instance_;

inline constexpr StreamingRecognitionConfig::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        config_{nullptr},
        voice_activity_timeout_{nullptr},
        single_utterance_{false},
        interim_results_{false},
        enable_voice_activity_events_{false} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognitionConfig::StreamingRecognitionConfig(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(StreamingRecognitionConfig_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognitionConfigDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognitionConfigDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognitionConfigDefaultTypeInternal() {}
  union {
    StreamingRecognitionConfig _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognitionConfigDefaultTypeInternal _StreamingRecognitionConfig_default_instance_;

inline constexpr RecognizeResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        results_{},
        total_billed_time_{nullptr},
        speech_adaptation_info_{nullptr},
        request_id_{::int64_t{0}} {}

template <typename>
PROTOBUF_CONSTEXPR RecognizeResponse::RecognizeResponse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(RecognizeResponse_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognizeResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognizeResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognizeResponseDefaultTypeInternal() {}
  union {
    RecognizeResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognizeResponseDefaultTypeInternal _RecognizeResponse_default_instance_;

inline constexpr RecognizeRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        config_{nullptr},
        audio_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR RecognizeRequest::RecognizeRequest(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(RecognizeRequest_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RecognizeRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RecognizeRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RecognizeRequestDefaultTypeInternal() {}
  union {
    RecognizeRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RecognizeRequestDefaultTypeInternal _RecognizeRequest_default_instance_;

inline constexpr LongRunningRecognizeResponse::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        results_{},
        total_billed_time_{nullptr},
        output_config_{nullptr},
        output_error_{nullptr},
        speech_adaptation_info_{nullptr},
        request_id_{::int64_t{0}} {}

template <typename>
PROTOBUF_CONSTEXPR LongRunningRecognizeResponse::LongRunningRecognizeResponse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(LongRunningRecognizeResponse_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct LongRunningRecognizeResponseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LongRunningRecognizeResponseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~LongRunningRecognizeResponseDefaultTypeInternal() {}
  union {
    LongRunningRecognizeResponse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LongRunningRecognizeResponseDefaultTypeInternal _LongRunningRecognizeResponse_default_instance_;

inline constexpr LongRunningRecognizeRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        config_{nullptr},
        audio_{nullptr},
        output_config_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR LongRunningRecognizeRequest::LongRunningRecognizeRequest(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(LongRunningRecognizeRequest_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct LongRunningRecognizeRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR LongRunningRecognizeRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~LongRunningRecognizeRequestDefaultTypeInternal() {}
  union {
    LongRunningRecognizeRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 LongRunningRecognizeRequestDefaultTypeInternal _LongRunningRecognizeRequest_default_instance_;

inline constexpr StreamingRecognizeRequest::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : streaming_request_{},
        _cached_size_{0},
        _oneof_case_{} {}

template <typename>
PROTOBUF_CONSTEXPR StreamingRecognizeRequest::StreamingRecognizeRequest(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(StreamingRecognizeRequest_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StreamingRecognizeRequestDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StreamingRecognizeRequestDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StreamingRecognizeRequestDefaultTypeInternal() {}
  union {
    StreamingRecognizeRequest _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StreamingRecognizeRequestDefaultTypeInternal _StreamingRecognizeRequest_default_instance_;
}  // namespace v1
}  // namespace speech
}  // namespace cloud
}  // namespace google
static const ::_pb::EnumDescriptor* PROTOBUF_NONNULL
    file_level_enum_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto[6];
static constexpr const ::_pb::ServiceDescriptor *PROTOBUF_NONNULL *PROTOBUF_NULLABLE
    file_level_service_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto = nullptr;
const ::uint32_t
    TableStruct_CoreAI3D_2fcloud_5fspeech_2eproto::offsets[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
        protodesc_cold) = {
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeRequest, _impl_._has_bits_),
        5, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeRequest, _impl_.config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeRequest, _impl_.audio_),
        0,
        1,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _impl_._has_bits_),
        6, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _impl_.config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _impl_.audio_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeRequest, _impl_.output_config_),
        0,
        1,
        2,
        0x004, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::TranscriptOutputConfig, _impl_._oneof_case_[0]),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::TranscriptOutputConfig, _impl_.output_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::TranscriptOutputConfig, _impl_.output_type_),
        0x004, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _impl_._oneof_case_[0]),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _impl_.streaming_request_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _impl_.streaming_request_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _impl_.streaming_request_),
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout, _impl_._has_bits_),
        5, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_start_timeout_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_end_timeout_),
        0,
        1,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_._has_bits_),
        8, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.single_utterance_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.interim_results_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.enable_voice_activity_events_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionConfig, _impl_.voice_activity_timeout_),
        0,
        2,
        3,
        4,
        1,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_._has_bits_),
        23, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.encoding_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.sample_rate_hertz_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.audio_channel_count_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_separate_recognition_per_channel_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.language_code_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.alternative_language_codes_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.max_alternatives_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.profanity_filter_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.adaptation_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.transcript_normalization_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.speech_contexts_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_word_time_offsets_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_word_confidence_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_automatic_punctuation_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_spoken_punctuation_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.enable_spoken_emojis_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.diarization_config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.metadata_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.model_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionConfig, _impl_.use_enhanced_),
        8,
        9,
        11,
        15,
        0,
        ~0u,
        10,
        12,
        4,
        7,
        ~0u,
        13,
        17,
        14,
        5,
        6,
        3,
        2,
        1,
        16,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_._has_bits_),
        7, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_.min_speaker_count_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_.max_speaker_count_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeakerDiarizationConfig, _impl_.speaker_tag_),
        0,
        1,
        2,
        3,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_._has_bits_),
        11, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.interaction_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.industry_naics_code_of_audio_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.microphone_distance_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.original_media_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.recording_device_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.recording_device_name_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.original_mime_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionMetadata, _impl_.audio_topic_),
        3,
        4,
        5,
        6,
        7,
        0,
        1,
        2,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechContext, _impl_._has_bits_),
        5, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechContext, _impl_.phrases_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechContext, _impl_.boost_),
        ~0u,
        0,
        0x004, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _impl_._oneof_case_[0]),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _impl_.audio_source_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _impl_.audio_source_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _impl_.audio_source_),
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_._has_bits_),
        7, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_.results_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_.total_billed_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_.speech_adaptation_info_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognizeResponse, _impl_.request_id_),
        ~0u,
        0,
        1,
        2,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_._has_bits_),
        9, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.results_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.total_billed_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.output_config_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.output_error_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.speech_adaptation_info_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeResponse, _impl_.request_id_),
        ~0u,
        0,
        1,
        2,
        3,
        4,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_._has_bits_),
        7, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_.progress_percent_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_.start_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_.last_update_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::LongRunningRecognizeMetadata, _impl_.uri_),
        3,
        1,
        2,
        0,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_._has_bits_),
        10, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.error_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.results_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.speech_event_type_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.speech_event_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.total_billed_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.speech_adaptation_info_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeResponse, _impl_.request_id_),
        0,
        ~0u,
        5,
        2,
        1,
        3,
        4,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_._has_bits_),
        9, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.alternatives_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.is_final_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.stability_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.result_end_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.channel_tag_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognitionResult, _impl_.language_code_),
        ~0u,
        2,
        3,
        1,
        4,
        0,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_._has_bits_),
        7, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_.alternatives_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_.channel_tag_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_.result_end_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionResult, _impl_.language_code_),
        ~0u,
        2,
        1,
        0,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionAlternative, _impl_._has_bits_),
        6, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionAlternative, _impl_.transcript_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionAlternative, _impl_.confidence_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechRecognitionAlternative, _impl_.words_),
        0,
        1,
        ~0u,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_._has_bits_),
        9, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.start_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.end_time_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.word_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.confidence_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.speaker_tag_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::WordInfo, _impl_.speaker_label_),
        2,
        3,
        0,
        4,
        5,
        1,
        0x081, // bitmap
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechAdaptationInfo, _impl_._has_bits_),
        5, // hasbit index offset
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechAdaptationInfo, _impl_.adaptation_timeout_),
        PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::SpeechAdaptationInfo, _impl_.timeout_message_),
        1,
        0,
};

static const ::_pbi::MigrationSchema
    schemas[] ABSL_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
        {0, sizeof(::google::cloud::speech::v1::RecognizeRequest)},
        {7, sizeof(::google::cloud::speech::v1::LongRunningRecognizeRequest)},
        {16, sizeof(::google::cloud::speech::v1::TranscriptOutputConfig)},
        {20, sizeof(::google::cloud::speech::v1::StreamingRecognizeRequest)},
        {25, sizeof(::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout)},
        {32, sizeof(::google::cloud::speech::v1::StreamingRecognitionConfig)},
        {45, sizeof(::google::cloud::speech::v1::RecognitionConfig)},
        {88, sizeof(::google::cloud::speech::v1::SpeakerDiarizationConfig)},
        {99, sizeof(::google::cloud::speech::v1::RecognitionMetadata)},
        {118, sizeof(::google::cloud::speech::v1::SpeechContext)},
        {125, sizeof(::google::cloud::speech::v1::RecognitionAudio)},
        {130, sizeof(::google::cloud::speech::v1::RecognizeResponse)},
        {141, sizeof(::google::cloud::speech::v1::LongRunningRecognizeResponse)},
        {156, sizeof(::google::cloud::speech::v1::LongRunningRecognizeMetadata)},
        {167, sizeof(::google::cloud::speech::v1::StreamingRecognizeResponse)},
        {184, sizeof(::google::cloud::speech::v1::StreamingRecognitionResult)},
        {199, sizeof(::google::cloud::speech::v1::SpeechRecognitionResult)},
        {210, sizeof(::google::cloud::speech::v1::SpeechRecognitionAlternative)},
        {219, sizeof(::google::cloud::speech::v1::WordInfo)},
        {234, sizeof(::google::cloud::speech::v1::SpeechAdaptationInfo)},
};
static const ::_pb::Message* PROTOBUF_NONNULL const file_default_instances[] = {
    &::google::cloud::speech::v1::_RecognizeRequest_default_instance_._instance,
    &::google::cloud::speech::v1::_LongRunningRecognizeRequest_default_instance_._instance,
    &::google::cloud::speech::v1::_TranscriptOutputConfig_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognizeRequest_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognitionConfig_VoiceActivityTimeout_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognitionConfig_default_instance_._instance,
    &::google::cloud::speech::v1::_RecognitionConfig_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeakerDiarizationConfig_default_instance_._instance,
    &::google::cloud::speech::v1::_RecognitionMetadata_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeechContext_default_instance_._instance,
    &::google::cloud::speech::v1::_RecognitionAudio_default_instance_._instance,
    &::google::cloud::speech::v1::_RecognizeResponse_default_instance_._instance,
    &::google::cloud::speech::v1::_LongRunningRecognizeResponse_default_instance_._instance,
    &::google::cloud::speech::v1::_LongRunningRecognizeMetadata_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognizeResponse_default_instance_._instance,
    &::google::cloud::speech::v1::_StreamingRecognitionResult_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeechRecognitionResult_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeechRecognitionAlternative_default_instance_._instance,
    &::google::cloud::speech::v1::_WordInfo_default_instance_._instance,
    &::google::cloud::speech::v1::_SpeechAdaptationInfo_default_instance_._instance,
};
const char descriptor_table_protodef_CoreAI3D_2fcloud_5fspeech_2eproto[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
    protodesc_cold) = {
    "\n\033CoreAI3D/cloud_speech.proto\022\026google.cl"
    "oud.speech.v1\032\034google/api/annotations.pr"
    "oto\032\027google/api/client.proto\032\037google/api"
    "/field_behavior.proto\032%google/cloud/spee"
    "ch/v1/resource.proto\032#google/longrunning"
    "/operations.proto\032\036google/protobuf/durat"
    "ion.proto\032\037google/protobuf/timestamp.pro"
    "to\032\036google/protobuf/wrappers.proto\032\027goog"
    "le/rpc/status.proto\"\220\001\n\020RecognizeRequest"
    "\022>\n\006config\030\001 \001(\0132).google.cloud.speech.v"
    "1.RecognitionConfigB\003\340A\002\022<\n\005audio\030\002 \001(\0132"
    "(.google.cloud.speech.v1.RecognitionAudi"
    "oB\003\340A\002\"\347\001\n\033LongRunningRecognizeRequest\022>"
    "\n\006config\030\001 \001(\0132).google.cloud.speech.v1."
    "RecognitionConfigB\003\340A\002\022<\n\005audio\030\002 \001(\0132(."
    "google.cloud.speech.v1.RecognitionAudioB"
    "\003\340A\002\022J\n\routput_config\030\004 \001(\0132..google.clo"
    "ud.speech.v1.TranscriptOutputConfigB\003\340A\001"
    "\":\n\026TranscriptOutputConfig\022\021\n\007gcs_uri\030\001 "
    "\001(\tH\000B\r\n\013output_type\"\231\001\n\031StreamingRecogn"
    "izeRequest\022N\n\020streaming_config\030\001 \001(\01322.g"
    "oogle.cloud.speech.v1.StreamingRecogniti"
    "onConfigH\000\022\027\n\raudio_content\030\002 \001(\014H\000B\023\n\021s"
    "treaming_request\"\247\003\n\032StreamingRecognitio"
    "nConfig\022>\n\006config\030\001 \001(\0132).google.cloud.s"
    "peech.v1.RecognitionConfigB\003\340A\002\022\030\n\020singl"
    "e_utterance\030\002 \001(\010\022\027\n\017interim_results\030\003 \001"
    "(\010\022$\n\034enable_voice_activity_events\030\005 \001(\010"
    "\022g\n\026voice_activity_timeout\030\006 \001(\0132G.googl"
    "e.cloud.speech.v1.StreamingRecognitionCo"
    "nfig.VoiceActivityTimeout\032\206\001\n\024VoiceActiv"
    "ityTimeout\0227\n\024speech_start_timeout\030\001 \001(\013"
    "2\031.google.protobuf.Duration\0225\n\022speech_en"
    "d_timeout\030\002 \001(\0132\031.google.protobuf.Durati"
    "on\"\312\010\n\021RecognitionConfig\022I\n\010encoding\030\001 \001"
    "(\01627.google.cloud.speech.v1.RecognitionC"
    "onfig.AudioEncoding\022\031\n\021sample_rate_hertz"
    "\030\002 \001(\005\022\033\n\023audio_channel_count\030\007 \001(\005\022/\n\'e"
    "nable_separate_recognition_per_channel\030\014"
    " \001(\010\022\032\n\rlanguage_code\030\003 \001(\tB\003\340A\002\022\"\n\032alte"
    "rnative_language_codes\030\022 \003(\t\022\030\n\020max_alte"
    "rnatives\030\004 \001(\005\022\030\n\020profanity_filter\030\005 \001(\010"
    "\022<\n\nadaptation\030\024 \001(\0132(.google.cloud.spee"
    "ch.v1.SpeechAdaptation\022V\n\030transcript_nor"
    "malization\030\030 \001(\0132/.google.cloud.speech.v"
    "1.TranscriptNormalizationB\003\340A\001\022>\n\017speech"
    "_contexts\030\006 \003(\0132%.google.cloud.speech.v1"
    ".SpeechContext\022 \n\030enable_word_time_offse"
    "ts\030\010 \001(\010\022\036\n\026enable_word_confidence\030\017 \001(\010"
    "\022$\n\034enable_automatic_punctuation\030\013 \001(\010\022="
    "\n\031enable_spoken_punctuation\030\026 \001(\0132\032.goog"
    "le.protobuf.BoolValue\0228\n\024enable_spoken_e"
    "mojis\030\027 \001(\0132\032.google.protobuf.BoolValue\022"
    "L\n\022diarization_config\030\023 \001(\01320.google.clo"
    "ud.speech.v1.SpeakerDiarizationConfig\022=\n"
    "\010metadata\030\t \001(\0132+.google.cloud.speech.v1"
    ".RecognitionMetadata\022\r\n\005model\030\r \001(\t\022\024\n\014u"
    "se_enhanced\030\016 \001(\010\"\243\001\n\rAudioEncoding\022\030\n\024E"
    "NCODING_UNSPECIFIED\020\000\022\014\n\010LINEAR16\020\001\022\010\n\004F"
    "LAC\020\002\022\t\n\005MULAW\020\003\022\007\n\003AMR\020\004\022\n\n\006AMR_WB\020\005\022\014\n"
    "\010OGG_OPUS\020\006\022\032\n\026SPEEX_WITH_HEADER_BYTE\020\007\022"
    "\007\n\003MP3\020\010\022\r\n\tWEBM_OPUS\020\t\"\220\001\n\030SpeakerDiari"
    "zationConfig\022\"\n\032enable_speaker_diarizati"
    "on\030\001 \001(\010\022\031\n\021min_speaker_count\030\002 \001(\005\022\031\n\021m"
    "ax_speaker_count\030\003 \001(\005\022\032\n\013speaker_tag\030\005 "
    "\001(\005B\005\030\001\340A\003\"\244\010\n\023RecognitionMetadata\022U\n\020in"
    "teraction_type\030\001 \001(\0162;.google.cloud.spee"
    "ch.v1.RecognitionMetadata.InteractionTyp"
    "e\022$\n\034industry_naics_code_of_audio\030\003 \001(\r\022"
    "[\n\023microphone_distance\030\004 \001(\0162>.google.cl"
    "oud.speech.v1.RecognitionMetadata.Microp"
    "honeDistance\022Z\n\023original_media_type\030\005 \001("
    "\0162=.google.cloud.speech.v1.RecognitionMe"
    "tadata.OriginalMediaType\022^\n\025recording_de"
    "vice_type\030\006 \001(\0162\?.google.cloud.speech.v1"
    ".RecognitionMetadata.RecordingDeviceType"
    "\022\035\n\025recording_device_name\030\007 \001(\t\022\032\n\022origi"
    "nal_mime_type\030\010 \001(\t\022\023\n\013audio_topic\030\n \001(\t"
    "\"\305\001\n\017InteractionType\022 \n\034INTERACTION_TYPE"
    "_UNSPECIFIED\020\000\022\016\n\nDISCUSSION\020\001\022\020\n\014PRESEN"
    "TATION\020\002\022\016\n\nPHONE_CALL\020\003\022\r\n\tVOICEMAIL\020\004\022"
    "\033\n\027PROFESSIONALLY_PRODUCED\020\005\022\020\n\014VOICE_SE"
    "ARCH\020\006\022\021\n\rVOICE_COMMAND\020\007\022\r\n\tDICTATION\020\010"
    "\"d\n\022MicrophoneDistance\022#\n\037MICROPHONE_DIS"
    "TANCE_UNSPECIFIED\020\000\022\r\n\tNEARFIELD\020\001\022\014\n\010MI"
    "DFIELD\020\002\022\014\n\010FARFIELD\020\003\"N\n\021OriginalMediaT"
    "ype\022#\n\037ORIGINAL_MEDIA_TYPE_UNSPECIFIED\020\000"
    "\022\t\n\005AUDIO\020\001\022\t\n\005VIDEO\020\002\"\244\001\n\023RecordingDevi"
    "ceType\022%\n!RECORDING_DEVICE_TYPE_UNSPECIF"
    "IED\020\000\022\016\n\nSMARTPHONE\020\001\022\006\n\002PC\020\002\022\016\n\nPHONE_L"
    "INE\020\003\022\013\n\007VEHICLE\020\004\022\030\n\024OTHER_OUTDOOR_DEVI"
    "CE\020\005\022\027\n\023OTHER_INDOOR_DEVICE\020\006:\002\030\001\"/\n\rSpe"
    "echContext\022\017\n\007phrases\030\001 \003(\t\022\r\n\005boost\030\004 \001"
    "(\002\"D\n\020RecognitionAudio\022\021\n\007content\030\001 \001(\014H"
    "\000\022\r\n\003uri\030\002 \001(\tH\000B\016\n\014audio_source\"\355\001\n\021Rec"
    "ognizeResponse\022@\n\007results\030\002 \003(\0132/.google"
    ".cloud.speech.v1.SpeechRecognitionResult"
    "\0224\n\021total_billed_time\030\003 \001(\0132\031.google.pro"
    "tobuf.Duration\022L\n\026speech_adaptation_info"
    "\030\007 \001(\0132,.google.cloud.speech.v1.SpeechAd"
    "aptationInfo\022\022\n\nrequest_id\030\010 \001(\003\"\351\002\n\034Lon"
    "gRunningRecognizeResponse\022@\n\007results\030\002 \003"
    "(\0132/.google.cloud.speech.v1.SpeechRecogn"
    "itionResult\0224\n\021total_billed_time\030\003 \001(\0132\031"
    ".google.protobuf.Duration\022E\n\routput_conf"
    "ig\030\006 \001(\0132..google.cloud.speech.v1.Transc"
    "riptOutputConfig\022(\n\014output_error\030\007 \001(\0132\022"
    ".google.rpc.Status\022L\n\026speech_adaptation_"
    "info\030\010 \001(\0132,.google.cloud.speech.v1.Spee"
    "chAdaptationInfo\022\022\n\nrequest_id\030\t \001(\003\"\260\001\n"
    "\034LongRunningRecognizeMetadata\022\030\n\020progres"
    "s_percent\030\001 \001(\005\022.\n\nstart_time\030\002 \001(\0132\032.go"
    "ogle.protobuf.Timestamp\0224\n\020last_update_t"
    "ime\030\003 \001(\0132\032.google.protobuf.Timestamp\022\020\n"
    "\003uri\030\004 \001(\tB\003\340A\003\"\321\004\n\032StreamingRecognizeRe"
    "sponse\022!\n\005error\030\001 \001(\0132\022.google.rpc.Statu"
    "s\022C\n\007results\030\002 \003(\01322.google.cloud.speech"
    ".v1.StreamingRecognitionResult\022]\n\021speech"
    "_event_type\030\004 \001(\0162B.google.cloud.speech."
    "v1.StreamingRecognizeResponse.SpeechEven"
    "tType\0224\n\021speech_event_time\030\010 \001(\0132\031.googl"
    "e.protobuf.Duration\0224\n\021total_billed_time"
    "\030\005 \001(\0132\031.google.protobuf.Duration\022L\n\026spe"
    "ech_adaptation_info\030\t \001(\0132,.google.cloud"
    ".speech.v1.SpeechAdaptationInfo\022\022\n\nreque"
    "st_id\030\n \001(\003\"\235\001\n\017SpeechEventType\022\034\n\030SPEEC"
    "H_EVENT_UNSPECIFIED\020\000\022\033\n\027END_OF_SINGLE_U"
    "TTERANCE\020\001\022\031\n\025SPEECH_ACTIVITY_BEGIN\020\002\022\027\n"
    "\023SPEECH_ACTIVITY_END\020\003\022\033\n\027SPEECH_ACTIVIT"
    "Y_TIMEOUT\020\004\"\362\001\n\032StreamingRecognitionResu"
    "lt\022J\n\014alternatives\030\001 \003(\01324.google.cloud."
    "speech.v1.SpeechRecognitionAlternative\022\020"
    "\n\010is_final\030\002 \001(\010\022\021\n\tstability\030\003 \001(\002\0222\n\017r"
    "esult_end_time\030\004 \001(\0132\031.google.protobuf.D"
    "uration\022\023\n\013channel_tag\030\005 \001(\005\022\032\n\rlanguage"
    "_code\030\006 \001(\tB\003\340A\003\"\312\001\n\027SpeechRecognitionRe"
    "sult\022J\n\014alternatives\030\001 \003(\01324.google.clou"
    "d.speech.v1.SpeechRecognitionAlternative"
    "\022\023\n\013channel_tag\030\002 \001(\005\0222\n\017result_end_time"
    "\030\004 \001(\0132\031.google.protobuf.Duration\022\032\n\rlan"
    "guage_code\030\005 \001(\tB\003\340A\003\"w\n\034SpeechRecogniti"
    "onAlternative\022\022\n\ntranscript\030\001 \001(\t\022\022\n\ncon"
    "fidence\030\002 \001(\002\022/\n\005words\030\003 \003(\0132 .google.cl"
    "oud.speech.v1.WordInfo\"\300\001\n\010WordInfo\022-\n\ns"
    "tart_time\030\001 \001(\0132\031.google.protobuf.Durati"
    "on\022+\n\010end_time\030\002 \001(\0132\031.google.protobuf.D"
    "uration\022\014\n\004word\030\003 \001(\t\022\022\n\nconfidence\030\004 \001("
    "\002\022\032\n\013speaker_tag\030\005 \001(\005B\005\030\001\340A\003\022\032\n\rspeaker"
    "_label\030\006 \001(\tB\003\340A\003\"K\n\024SpeechAdaptationInf"
    "o\022\032\n\022adaptation_timeout\030\001 \001(\010\022\027\n\017timeout"
    "_message\030\004 \001(\t2\321\004\n\006Speech\022\220\001\n\tRecognize\022"
    "(.google.cloud.speech.v1.RecognizeReques"
    "t\032).google.cloud.speech.v1.RecognizeResp"
    "onse\".\332A\014config,audio\202\323\344\223\002\031\"\024/v1/speech:"
    "recognize:\001*\022\344\001\n\024LongRunningRecognize\0223."
    "google.cloud.speech.v1.LongRunningRecogn"
    "izeRequest\032\035.google.longrunning.Operatio"
    "n\"x\312A<\n\034LongRunningRecognizeResponse\022\034Lo"
    "ngRunningRecognizeMetadata\332A\014config,audi"
    "o\202\323\344\223\002$\"\037/v1/speech:longrunningrecognize"
    ":\001*\022\201\001\n\022StreamingRecognize\0221.google.clou"
    "d.speech.v1.StreamingRecognizeRequest\0322."
    "google.cloud.speech.v1.StreamingRecogniz"
    "eResponse\"\000(\0010\001\032I\312A\025speech.googleapis.co"
    "m\322A.https://www.googleapis.com/auth/clou"
    "d-platformBh\n\032com.google.cloud.speech.v1"
    "B\013SpeechProtoP\001Z2cloud.google.com/go/spe"
    "ech/apiv1/speechpb;speechpb\370\001\001\242\002\003GCSb\006pr"
    "oto3"
};
static const ::_pbi::DescriptorTable* PROTOBUF_NONNULL const
    descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto_deps[9] = {
        &::descriptor_table_google_2fapi_2fannotations_2eproto,
        &::descriptor_table_google_2fapi_2fclient_2eproto,
        &::descriptor_table_google_2fapi_2ffield_5fbehavior_2eproto,
        &::descriptor_table_google_2fcloud_2fspeech_2fv1_2fresource_2eproto,
        &::descriptor_table_google_2flongrunning_2foperations_2eproto,
        &::descriptor_table_google_2fprotobuf_2fduration_2eproto,
        &::descriptor_table_google_2fprotobuf_2ftimestamp_2eproto,
        &::descriptor_table_google_2fprotobuf_2fwrappers_2eproto,
        &::descriptor_table_google_2frpc_2fstatus_2eproto,
};
static ::absl::once_flag descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto_once;
PROTOBUF_CONSTINIT const ::_pbi::DescriptorTable descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto = {
    false,
    false,
    6724,
    descriptor_table_protodef_CoreAI3D_2fcloud_5fspeech_2eproto,
    "CoreAI3D/cloud_speech.proto",
    &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto_once,
    descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto_deps,
    9,
    20,
    schemas,
    file_default_instances,
    TableStruct_CoreAI3D_2fcloud_5fspeech_2eproto::offsets,
    file_level_enum_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto,
    file_level_service_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto,
};
namespace google {
namespace cloud {
namespace speech {
namespace v1 {
const ::google::protobuf::EnumDescriptor* PROTOBUF_NONNULL RecognitionConfig_AudioEncoding_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto);
  return file_level_enum_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto[0];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionConfig_AudioEncoding_internal_data_[] = {
    655360u, 0u, };
const ::google::protobuf::EnumDescriptor* PROTOBUF_NONNULL RecognitionMetadata_InteractionType_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto);
  return file_level_enum_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto[1];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionMetadata_InteractionType_internal_data_[] = {
    589824u, 0u, };
const ::google::protobuf::EnumDescriptor* PROTOBUF_NONNULL RecognitionMetadata_MicrophoneDistance_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto);
  return file_level_enum_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto[2];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionMetadata_MicrophoneDistance_internal_data_[] = {
    262144u, 0u, };
const ::google::protobuf::EnumDescriptor* PROTOBUF_NONNULL RecognitionMetadata_OriginalMediaType_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto);
  return file_level_enum_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto[3];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionMetadata_OriginalMediaType_internal_data_[] = {
    196608u, 0u, };
const ::google::protobuf::EnumDescriptor* PROTOBUF_NONNULL RecognitionMetadata_RecordingDeviceType_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto);
  return file_level_enum_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto[4];
}
PROTOBUF_CONSTINIT const uint32_t RecognitionMetadata_RecordingDeviceType_internal_data_[] = {
    458752u, 0u, };
const ::google::protobuf::EnumDescriptor* PROTOBUF_NONNULL StreamingRecognizeResponse_SpeechEventType_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto);
  return file_level_enum_descriptors_CoreAI3D_2fcloud_5fspeech_2eproto[5];
}
PROTOBUF_CONSTINIT const uint32_t StreamingRecognizeResponse_SpeechEventType_internal_data_[] = {
    327680u, 0u, };
// ===================================================================

class RecognizeRequest::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<RecognizeRequest>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_._has_bits_);
};

RecognizeRequest::RecognizeRequest(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognizeRequest_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognizeRequest)
}
PROTOBUF_NDEBUG_INLINE RecognizeRequest::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::RecognizeRequest& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

RecognizeRequest::RecognizeRequest(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const RecognizeRequest& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognizeRequest_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognizeRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.config_ = ((cached_has_bits & 0x00000001U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.config_)
                : nullptr;
  _impl_.audio_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.audio_)
                : nullptr;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognizeRequest)
}
PROTOBUF_NDEBUG_INLINE RecognizeRequest::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0} {}

inline void RecognizeRequest::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, config_),
           0,
           offsetof(Impl_, audio_) -
               offsetof(Impl_, config_) +
               sizeof(Impl_::audio_));
}
RecognizeRequest::~RecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognizeRequest)
  SharedDtor(*this);
}
inline void RecognizeRequest::SharedDtor(MessageLite& self) {
  RecognizeRequest& this_ = static_cast<RecognizeRequest&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.config_;
  delete this_._impl_.audio_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL RecognizeRequest::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) RecognizeRequest(arena);
}
constexpr auto RecognizeRequest::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(RecognizeRequest),
                                            alignof(RecognizeRequest));
}
constexpr auto RecognizeRequest::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_RecognizeRequest_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &RecognizeRequest::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<RecognizeRequest>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &RecognizeRequest::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<RecognizeRequest>(), &RecognizeRequest::ByteSizeLong,
              &RecognizeRequest::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_._cached_size_),
          false,
      },
      &RecognizeRequest::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull RecognizeRequest_class_data_ =
        RecognizeRequest::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
RecognizeRequest::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&RecognizeRequest_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(RecognizeRequest_class_data_.tc_table);
  return RecognizeRequest_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 2, 0, 2>
RecognizeRequest::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    RecognizeRequest_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognizeRequest>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 1, PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.audio_)}},
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_)}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.audio_), _Internal::kHasBitsOffset + 1, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionConfig>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionAudio>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void RecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognizeRequest)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(_impl_.config_ != nullptr);
      _impl_.config_->Clear();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.audio_ != nullptr);
      _impl_.audio_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL RecognizeRequest::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const RecognizeRequest& this_ = static_cast<const RecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL RecognizeRequest::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const RecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognizeRequest)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
  if ((cached_has_bits & 0x00000001U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        1, *this_._impl_.config_, this_._impl_.config_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        2, *this_._impl_.audio_, this_._impl_.audio_->GetCachedSize(), target,
        stream);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognizeRequest)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t RecognizeRequest::ByteSizeLong(const MessageLite& base) {
  const RecognizeRequest& this_ = static_cast<const RecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t RecognizeRequest::ByteSizeLong() const {
  const RecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognizeRequest)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    if ((cached_has_bits & 0x00000001U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.config_);
    }
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.audio_);
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void RecognizeRequest::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognizeRequest*>(&to_msg);
  auto& from = static_cast<const RecognizeRequest&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognizeRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(from._impl_.config_ != nullptr);
      if (_this->_impl_.config_ == nullptr) {
        _this->_impl_.config_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.config_);
      } else {
        _this->_impl_.config_->MergeFrom(*from._impl_.config_);
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.audio_ != nullptr);
      if (_this->_impl_.audio_ == nullptr) {
        _this->_impl_.audio_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.audio_);
      } else {
        _this->_impl_.audio_->MergeFrom(*from._impl_.audio_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognizeRequest::CopyFrom(const RecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognizeRequest::InternalSwap(RecognizeRequest* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.audio_)
      + sizeof(RecognizeRequest::_impl_.audio_)
      - PROTOBUF_FIELD_OFFSET(RecognizeRequest, _impl_.config_)>(
          reinterpret_cast<char*>(&_impl_.config_),
          reinterpret_cast<char*>(&other->_impl_.config_));
}

::google::protobuf::Metadata RecognizeRequest::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class LongRunningRecognizeRequest::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<LongRunningRecognizeRequest>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_._has_bits_);
};

LongRunningRecognizeRequest::LongRunningRecognizeRequest(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, LongRunningRecognizeRequest_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.LongRunningRecognizeRequest)
}
PROTOBUF_NDEBUG_INLINE LongRunningRecognizeRequest::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::LongRunningRecognizeRequest& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

LongRunningRecognizeRequest::LongRunningRecognizeRequest(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const LongRunningRecognizeRequest& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, LongRunningRecognizeRequest_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  LongRunningRecognizeRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.config_ = ((cached_has_bits & 0x00000001U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.config_)
                : nullptr;
  _impl_.audio_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.audio_)
                : nullptr;
  _impl_.output_config_ = ((cached_has_bits & 0x00000004U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.output_config_)
                : nullptr;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.LongRunningRecognizeRequest)
}
PROTOBUF_NDEBUG_INLINE LongRunningRecognizeRequest::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0} {}

inline void LongRunningRecognizeRequest::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, config_),
           0,
           offsetof(Impl_, output_config_) -
               offsetof(Impl_, config_) +
               sizeof(Impl_::output_config_));
}
LongRunningRecognizeRequest::~LongRunningRecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.LongRunningRecognizeRequest)
  SharedDtor(*this);
}
inline void LongRunningRecognizeRequest::SharedDtor(MessageLite& self) {
  LongRunningRecognizeRequest& this_ = static_cast<LongRunningRecognizeRequest&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.config_;
  delete this_._impl_.audio_;
  delete this_._impl_.output_config_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL LongRunningRecognizeRequest::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) LongRunningRecognizeRequest(arena);
}
constexpr auto LongRunningRecognizeRequest::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(LongRunningRecognizeRequest),
                                            alignof(LongRunningRecognizeRequest));
}
constexpr auto LongRunningRecognizeRequest::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_LongRunningRecognizeRequest_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &LongRunningRecognizeRequest::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<LongRunningRecognizeRequest>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &LongRunningRecognizeRequest::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<LongRunningRecognizeRequest>(), &LongRunningRecognizeRequest::ByteSizeLong,
              &LongRunningRecognizeRequest::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_._cached_size_),
          false,
      },
      &LongRunningRecognizeRequest::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull LongRunningRecognizeRequest_class_data_ =
        LongRunningRecognizeRequest::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
LongRunningRecognizeRequest::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&LongRunningRecognizeRequest_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(LongRunningRecognizeRequest_class_data_.tc_table);
  return LongRunningRecognizeRequest_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 3, 0, 2>
LongRunningRecognizeRequest::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_._has_bits_),
    0, // no _extensions_
    4, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967284,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    3,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    LongRunningRecognizeRequest_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::LongRunningRecognizeRequest>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 4 [(.google.api.field_behavior) = OPTIONAL];
    {::_pbi::TcParser::FastMtS1,
     {34, 2, 2, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.output_config_)}},
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.config_)}},
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 1, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.audio_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.config_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.audio_), _Internal::kHasBitsOffset + 1, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 4 [(.google.api.field_behavior) = OPTIONAL];
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.output_config_), _Internal::kHasBitsOffset + 2, 2, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionConfig>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionAudio>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::TranscriptOutputConfig>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void LongRunningRecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(_impl_.config_ != nullptr);
      _impl_.config_->Clear();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.audio_ != nullptr);
      _impl_.audio_->Clear();
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(_impl_.output_config_ != nullptr);
      _impl_.output_config_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL LongRunningRecognizeRequest::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const LongRunningRecognizeRequest& this_ = static_cast<const LongRunningRecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL LongRunningRecognizeRequest::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const LongRunningRecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
  if ((cached_has_bits & 0x00000001U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        1, *this_._impl_.config_, this_._impl_.config_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        2, *this_._impl_.audio_, this_._impl_.audio_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 4 [(.google.api.field_behavior) = OPTIONAL];
  if ((cached_has_bits & 0x00000004U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        4, *this_._impl_.output_config_, this_._impl_.output_config_->GetCachedSize(), target,
        stream);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.LongRunningRecognizeRequest)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t LongRunningRecognizeRequest::ByteSizeLong(const MessageLite& base) {
  const LongRunningRecognizeRequest& this_ = static_cast<const LongRunningRecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t LongRunningRecognizeRequest::ByteSizeLong() const {
  const LongRunningRecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    if ((cached_has_bits & 0x00000001U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.config_);
    }
    // .google.cloud.speech.v1.RecognitionAudio audio = 2 [(.google.api.field_behavior) = REQUIRED];
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.audio_);
    }
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 4 [(.google.api.field_behavior) = OPTIONAL];
    if ((cached_has_bits & 0x00000004U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.output_config_);
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void LongRunningRecognizeRequest::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<LongRunningRecognizeRequest*>(&to_msg);
  auto& from = static_cast<const LongRunningRecognizeRequest&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(from._impl_.config_ != nullptr);
      if (_this->_impl_.config_ == nullptr) {
        _this->_impl_.config_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.config_);
      } else {
        _this->_impl_.config_->MergeFrom(*from._impl_.config_);
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.audio_ != nullptr);
      if (_this->_impl_.audio_ == nullptr) {
        _this->_impl_.audio_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.audio_);
      } else {
        _this->_impl_.audio_->MergeFrom(*from._impl_.audio_);
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(from._impl_.output_config_ != nullptr);
      if (_this->_impl_.output_config_ == nullptr) {
        _this->_impl_.output_config_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.output_config_);
      } else {
        _this->_impl_.output_config_->MergeFrom(*from._impl_.output_config_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void LongRunningRecognizeRequest::CopyFrom(const LongRunningRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.LongRunningRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void LongRunningRecognizeRequest::InternalSwap(LongRunningRecognizeRequest* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.output_config_)
      + sizeof(LongRunningRecognizeRequest::_impl_.output_config_)
      - PROTOBUF_FIELD_OFFSET(LongRunningRecognizeRequest, _impl_.config_)>(
          reinterpret_cast<char*>(&_impl_.config_),
          reinterpret_cast<char*>(&other->_impl_.config_));
}

::google::protobuf::Metadata LongRunningRecognizeRequest::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class TranscriptOutputConfig::_Internal {
 public:
  static constexpr ::int32_t kOneofCaseOffset =
      PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::TranscriptOutputConfig, _impl_._oneof_case_);
};

TranscriptOutputConfig::TranscriptOutputConfig(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, TranscriptOutputConfig_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.TranscriptOutputConfig)
}
PROTOBUF_NDEBUG_INLINE TranscriptOutputConfig::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::TranscriptOutputConfig& from_msg)
      : output_type_{},
        _cached_size_{0},
        _oneof_case_{from._oneof_case_[0]} {}

TranscriptOutputConfig::TranscriptOutputConfig(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const TranscriptOutputConfig& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, TranscriptOutputConfig_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  TranscriptOutputConfig* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  switch (output_type_case()) {
    case OUTPUT_TYPE_NOT_SET:
      break;
      case kGcsUri:
        new (&_impl_.output_type_.gcs_uri_) decltype(_impl_.output_type_.gcs_uri_){arena, from._impl_.output_type_.gcs_uri_};
        break;
  }

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.TranscriptOutputConfig)
}
PROTOBUF_NDEBUG_INLINE TranscriptOutputConfig::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : output_type_{},
        _cached_size_{0},
        _oneof_case_{} {}

inline void TranscriptOutputConfig::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
TranscriptOutputConfig::~TranscriptOutputConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.TranscriptOutputConfig)
  SharedDtor(*this);
}
inline void TranscriptOutputConfig::SharedDtor(MessageLite& self) {
  TranscriptOutputConfig& this_ = static_cast<TranscriptOutputConfig&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  if (this_.has_output_type()) {
    this_.clear_output_type();
  }
  this_._impl_.~Impl_();
}

void TranscriptOutputConfig::clear_output_type() {
// @@protoc_insertion_point(one_of_clear_start:google.cloud.speech.v1.TranscriptOutputConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  switch (output_type_case()) {
    case kGcsUri: {
      _impl_.output_type_.gcs_uri_.Destroy();
      break;
    }
    case OUTPUT_TYPE_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = OUTPUT_TYPE_NOT_SET;
}


inline void* PROTOBUF_NONNULL TranscriptOutputConfig::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) TranscriptOutputConfig(arena);
}
constexpr auto TranscriptOutputConfig::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(TranscriptOutputConfig),
                                            alignof(TranscriptOutputConfig));
}
constexpr auto TranscriptOutputConfig::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_TranscriptOutputConfig_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &TranscriptOutputConfig::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<TranscriptOutputConfig>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &TranscriptOutputConfig::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<TranscriptOutputConfig>(), &TranscriptOutputConfig::ByteSizeLong,
              &TranscriptOutputConfig::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(TranscriptOutputConfig, _impl_._cached_size_),
          false,
      },
      &TranscriptOutputConfig::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull TranscriptOutputConfig_class_data_ =
        TranscriptOutputConfig::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
TranscriptOutputConfig::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&TranscriptOutputConfig_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(TranscriptOutputConfig_class_data_.tc_table);
  return TranscriptOutputConfig_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 1, 0, 61, 2>
TranscriptOutputConfig::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    1, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    1,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    TranscriptOutputConfig_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::TranscriptOutputConfig>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // string gcs_uri = 1;
    {PROTOBUF_FIELD_OFFSET(TranscriptOutputConfig, _impl_.output_type_.gcs_uri_), _Internal::kOneofCaseOffset + 0, 0, (0 | ::_fl::kFcOneof | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\55\7\0\0\0\0\0\0"
    "google.cloud.speech.v1.TranscriptOutputConfig"
    "gcs_uri"
  }},
};
PROTOBUF_NOINLINE void TranscriptOutputConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.TranscriptOutputConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_output_type();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL TranscriptOutputConfig::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const TranscriptOutputConfig& this_ = static_cast<const TranscriptOutputConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL TranscriptOutputConfig::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const TranscriptOutputConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.TranscriptOutputConfig)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // string gcs_uri = 1;
  if (this_.output_type_case() == kGcsUri) {
    const ::std::string& _s = this_._internal_gcs_uri();
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.TranscriptOutputConfig.gcs_uri");
    target = stream->WriteStringMaybeAliased(1, _s, target);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.TranscriptOutputConfig)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t TranscriptOutputConfig::ByteSizeLong(const MessageLite& base) {
  const TranscriptOutputConfig& this_ = static_cast<const TranscriptOutputConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t TranscriptOutputConfig::ByteSizeLong() const {
  const TranscriptOutputConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.TranscriptOutputConfig)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  switch (this_.output_type_case()) {
    // string gcs_uri = 1;
    case kGcsUri: {
      total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                      this_._internal_gcs_uri());
      break;
    }
    case OUTPUT_TYPE_NOT_SET: {
      break;
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void TranscriptOutputConfig::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<TranscriptOutputConfig*>(&to_msg);
  auto& from = static_cast<const TranscriptOutputConfig&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.TranscriptOutputConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (const uint32_t oneof_from_case = from._impl_._oneof_case_[0]) {
    const uint32_t oneof_to_case = _this->_impl_._oneof_case_[0];
    const bool oneof_needs_init = oneof_to_case != oneof_from_case;
    if (oneof_needs_init) {
      if (oneof_to_case != 0) {
        _this->clear_output_type();
      }
      _this->_impl_._oneof_case_[0] = oneof_from_case;
    }

    switch (oneof_from_case) {
      case kGcsUri: {
        if (oneof_needs_init) {
          _this->_impl_.output_type_.gcs_uri_.InitDefault();
        }
        _this->_impl_.output_type_.gcs_uri_.Set(from._internal_gcs_uri(), arena);
        break;
      }
      case OUTPUT_TYPE_NOT_SET:
        break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void TranscriptOutputConfig::CopyFrom(const TranscriptOutputConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.TranscriptOutputConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void TranscriptOutputConfig::InternalSwap(TranscriptOutputConfig* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.output_type_, other->_impl_.output_type_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::google::protobuf::Metadata TranscriptOutputConfig::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognizeRequest::_Internal {
 public:
  static constexpr ::int32_t kOneofCaseOffset =
      PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::StreamingRecognizeRequest, _impl_._oneof_case_);
};

void StreamingRecognizeRequest::set_allocated_streaming_config(::google::cloud::speech::v1::StreamingRecognitionConfig* PROTOBUF_NULLABLE streaming_config) {
  ::google::protobuf::Arena* message_arena = GetArena();
  clear_streaming_request();
  if (streaming_config) {
    ::google::protobuf::Arena* submessage_arena = streaming_config->GetArena();
    if (message_arena != submessage_arena) {
      streaming_config = ::google::protobuf::internal::GetOwnedMessage(message_arena, streaming_config, submessage_arena);
    }
    set_has_streaming_config();
    _impl_.streaming_request_.streaming_config_ = streaming_config;
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1.StreamingRecognizeRequest.streaming_config)
}
StreamingRecognizeRequest::StreamingRecognizeRequest(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognizeRequest_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognizeRequest)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognizeRequest::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::StreamingRecognizeRequest& from_msg)
      : streaming_request_{},
        _cached_size_{0},
        _oneof_case_{from._oneof_case_[0]} {}

StreamingRecognizeRequest::StreamingRecognizeRequest(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const StreamingRecognizeRequest& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognizeRequest_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognizeRequest* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  switch (streaming_request_case()) {
    case STREAMING_REQUEST_NOT_SET:
      break;
      case kStreamingConfig:
        _impl_.streaming_request_.streaming_config_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.streaming_request_.streaming_config_);
        break;
      case kAudioContent:
        new (&_impl_.streaming_request_.audio_content_) decltype(_impl_.streaming_request_.audio_content_){arena, from._impl_.streaming_request_.audio_content_};
        break;
  }

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognizeRequest)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognizeRequest::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : streaming_request_{},
        _cached_size_{0},
        _oneof_case_{} {}

inline void StreamingRecognizeRequest::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
StreamingRecognizeRequest::~StreamingRecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognizeRequest)
  SharedDtor(*this);
}
inline void StreamingRecognizeRequest::SharedDtor(MessageLite& self) {
  StreamingRecognizeRequest& this_ = static_cast<StreamingRecognizeRequest&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  if (this_.has_streaming_request()) {
    this_.clear_streaming_request();
  }
  this_._impl_.~Impl_();
}

void StreamingRecognizeRequest::clear_streaming_request() {
// @@protoc_insertion_point(one_of_clear_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  switch (streaming_request_case()) {
    case kStreamingConfig: {
      if (GetArena() == nullptr) {
        delete _impl_.streaming_request_.streaming_config_;
      } else if (::google::protobuf::internal::DebugHardenClearOneofMessageOnArena()) {
        ::google::protobuf::internal::MaybePoisonAfterClear(_impl_.streaming_request_.streaming_config_);
      }
      break;
    }
    case kAudioContent: {
      _impl_.streaming_request_.audio_content_.Destroy();
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = STREAMING_REQUEST_NOT_SET;
}


inline void* PROTOBUF_NONNULL StreamingRecognizeRequest::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) StreamingRecognizeRequest(arena);
}
constexpr auto StreamingRecognizeRequest::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(StreamingRecognizeRequest),
                                            alignof(StreamingRecognizeRequest));
}
constexpr auto StreamingRecognizeRequest::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_StreamingRecognizeRequest_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &StreamingRecognizeRequest::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<StreamingRecognizeRequest>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &StreamingRecognizeRequest::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<StreamingRecognizeRequest>(), &StreamingRecognizeRequest::ByteSizeLong,
              &StreamingRecognizeRequest::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_._cached_size_),
          false,
      },
      &StreamingRecognizeRequest::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull StreamingRecognizeRequest_class_data_ =
        StreamingRecognizeRequest::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
StreamingRecognizeRequest::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&StreamingRecognizeRequest_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(StreamingRecognizeRequest_class_data_.tc_table);
  return StreamingRecognizeRequest_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 2, 1, 0, 2>
StreamingRecognizeRequest::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    StreamingRecognizeRequest_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognizeRequest>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_.streaming_request_.streaming_config_), _Internal::kOneofCaseOffset + 0, 0, (0 | ::_fl::kFcOneof | ::_fl::kMessage | ::_fl::kTvTable)},
    // bytes audio_content = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeRequest, _impl_.streaming_request_.audio_content_), _Internal::kOneofCaseOffset + 0, 0, (0 | ::_fl::kFcOneof | ::_fl::kBytes | ::_fl::kRepAString)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionConfig>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void StreamingRecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_streaming_request();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL StreamingRecognizeRequest::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const StreamingRecognizeRequest& this_ = static_cast<const StreamingRecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL StreamingRecognizeRequest::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const StreamingRecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  switch (this_.streaming_request_case()) {
    case kStreamingConfig: {
      target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
          1, *this_._impl_.streaming_request_.streaming_config_, this_._impl_.streaming_request_.streaming_config_->GetCachedSize(), target,
          stream);
      break;
    }
    case kAudioContent: {
      const ::std::string& _s = this_._internal_audio_content();
      target = stream->WriteBytesMaybeAliased(2, _s, target);
      break;
    }
    default:
      break;
  }
  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognizeRequest)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t StreamingRecognizeRequest::ByteSizeLong(const MessageLite& base) {
  const StreamingRecognizeRequest& this_ = static_cast<const StreamingRecognizeRequest&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t StreamingRecognizeRequest::ByteSizeLong() const {
  const StreamingRecognizeRequest& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  switch (this_.streaming_request_case()) {
    // .google.cloud.speech.v1.StreamingRecognitionConfig streaming_config = 1;
    case kStreamingConfig: {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.streaming_request_.streaming_config_);
      break;
    }
    // bytes audio_content = 2;
    case kAudioContent: {
      total_size += 1 + ::google::protobuf::internal::WireFormatLite::BytesSize(
                                      this_._internal_audio_content());
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void StreamingRecognizeRequest::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognizeRequest*>(&to_msg);
  auto& from = static_cast<const StreamingRecognizeRequest&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (const uint32_t oneof_from_case = from._impl_._oneof_case_[0]) {
    const uint32_t oneof_to_case = _this->_impl_._oneof_case_[0];
    const bool oneof_needs_init = oneof_to_case != oneof_from_case;
    if (oneof_needs_init) {
      if (oneof_to_case != 0) {
        _this->clear_streaming_request();
      }
      _this->_impl_._oneof_case_[0] = oneof_from_case;
    }

    switch (oneof_from_case) {
      case kStreamingConfig: {
        if (oneof_needs_init) {
          _this->_impl_.streaming_request_.streaming_config_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.streaming_request_.streaming_config_);
        } else {
          _this->_impl_.streaming_request_.streaming_config_->MergeFrom(*from._impl_.streaming_request_.streaming_config_);
        }
        break;
      }
      case kAudioContent: {
        if (oneof_needs_init) {
          _this->_impl_.streaming_request_.audio_content_.InitDefault();
        }
        _this->_impl_.streaming_request_.audio_content_.Set(from._internal_audio_content(), arena);
        break;
      }
      case STREAMING_REQUEST_NOT_SET:
        break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognizeRequest::CopyFrom(const StreamingRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognizeRequest::InternalSwap(StreamingRecognizeRequest* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.streaming_request_, other->_impl_.streaming_request_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::google::protobuf::Metadata StreamingRecognizeRequest::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognitionConfig_VoiceActivityTimeout::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<StreamingRecognitionConfig_VoiceActivityTimeout>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_._has_bits_);
};

void StreamingRecognitionConfig_VoiceActivityTimeout::clear_speech_start_timeout() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.speech_start_timeout_ != nullptr) _impl_.speech_start_timeout_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001U;
}
void StreamingRecognitionConfig_VoiceActivityTimeout::clear_speech_end_timeout() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.speech_end_timeout_ != nullptr) _impl_.speech_end_timeout_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002U;
}
StreamingRecognitionConfig_VoiceActivityTimeout::StreamingRecognitionConfig_VoiceActivityTimeout(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognitionConfig_VoiceActivityTimeout_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig_VoiceActivityTimeout::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

StreamingRecognitionConfig_VoiceActivityTimeout::StreamingRecognitionConfig_VoiceActivityTimeout(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const StreamingRecognitionConfig_VoiceActivityTimeout& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognitionConfig_VoiceActivityTimeout_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognitionConfig_VoiceActivityTimeout* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.speech_start_timeout_ = ((cached_has_bits & 0x00000001U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_start_timeout_)
                : nullptr;
  _impl_.speech_end_timeout_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_end_timeout_)
                : nullptr;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig_VoiceActivityTimeout::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0} {}

inline void StreamingRecognitionConfig_VoiceActivityTimeout::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, speech_start_timeout_),
           0,
           offsetof(Impl_, speech_end_timeout_) -
               offsetof(Impl_, speech_start_timeout_) +
               sizeof(Impl_::speech_end_timeout_));
}
StreamingRecognitionConfig_VoiceActivityTimeout::~StreamingRecognitionConfig_VoiceActivityTimeout() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  SharedDtor(*this);
}
inline void StreamingRecognitionConfig_VoiceActivityTimeout::SharedDtor(MessageLite& self) {
  StreamingRecognitionConfig_VoiceActivityTimeout& this_ = static_cast<StreamingRecognitionConfig_VoiceActivityTimeout&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.speech_start_timeout_;
  delete this_._impl_.speech_end_timeout_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL StreamingRecognitionConfig_VoiceActivityTimeout::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) StreamingRecognitionConfig_VoiceActivityTimeout(arena);
}
constexpr auto StreamingRecognitionConfig_VoiceActivityTimeout::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(StreamingRecognitionConfig_VoiceActivityTimeout),
                                            alignof(StreamingRecognitionConfig_VoiceActivityTimeout));
}
constexpr auto StreamingRecognitionConfig_VoiceActivityTimeout::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_StreamingRecognitionConfig_VoiceActivityTimeout_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &StreamingRecognitionConfig_VoiceActivityTimeout::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<StreamingRecognitionConfig_VoiceActivityTimeout>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &StreamingRecognitionConfig_VoiceActivityTimeout::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<StreamingRecognitionConfig_VoiceActivityTimeout>(), &StreamingRecognitionConfig_VoiceActivityTimeout::ByteSizeLong,
              &StreamingRecognitionConfig_VoiceActivityTimeout::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_._cached_size_),
          false,
      },
      &StreamingRecognitionConfig_VoiceActivityTimeout::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull StreamingRecognitionConfig_VoiceActivityTimeout_class_data_ =
        StreamingRecognitionConfig_VoiceActivityTimeout::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
StreamingRecognitionConfig_VoiceActivityTimeout::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&StreamingRecognitionConfig_VoiceActivityTimeout_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(StreamingRecognitionConfig_VoiceActivityTimeout_class_data_.tc_table);
  return StreamingRecognitionConfig_VoiceActivityTimeout_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 2, 0, 2>
StreamingRecognitionConfig_VoiceActivityTimeout::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    StreamingRecognitionConfig_VoiceActivityTimeout_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.protobuf.Duration speech_end_timeout = 2;
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_end_timeout_)}},
    // .google.protobuf.Duration speech_start_timeout = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_start_timeout_)}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.protobuf.Duration speech_start_timeout = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_start_timeout_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration speech_end_timeout = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_end_timeout_), _Internal::kHasBitsOffset + 1, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void StreamingRecognitionConfig_VoiceActivityTimeout::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(_impl_.speech_start_timeout_ != nullptr);
      _impl_.speech_start_timeout_->Clear();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.speech_end_timeout_ != nullptr);
      _impl_.speech_end_timeout_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL StreamingRecognitionConfig_VoiceActivityTimeout::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const StreamingRecognitionConfig_VoiceActivityTimeout& this_ = static_cast<const StreamingRecognitionConfig_VoiceActivityTimeout&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL StreamingRecognitionConfig_VoiceActivityTimeout::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const StreamingRecognitionConfig_VoiceActivityTimeout& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.protobuf.Duration speech_start_timeout = 1;
  if ((cached_has_bits & 0x00000001U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        1, *this_._impl_.speech_start_timeout_, this_._impl_.speech_start_timeout_->GetCachedSize(), target,
        stream);
  }

  // .google.protobuf.Duration speech_end_timeout = 2;
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        2, *this_._impl_.speech_end_timeout_, this_._impl_.speech_end_timeout_->GetCachedSize(), target,
        stream);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t StreamingRecognitionConfig_VoiceActivityTimeout::ByteSizeLong(const MessageLite& base) {
  const StreamingRecognitionConfig_VoiceActivityTimeout& this_ = static_cast<const StreamingRecognitionConfig_VoiceActivityTimeout&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t StreamingRecognitionConfig_VoiceActivityTimeout::ByteSizeLong() const {
  const StreamingRecognitionConfig_VoiceActivityTimeout& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    // .google.protobuf.Duration speech_start_timeout = 1;
    if ((cached_has_bits & 0x00000001U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_start_timeout_);
    }
    // .google.protobuf.Duration speech_end_timeout = 2;
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_end_timeout_);
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void StreamingRecognitionConfig_VoiceActivityTimeout::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognitionConfig_VoiceActivityTimeout*>(&to_msg);
  auto& from = static_cast<const StreamingRecognitionConfig_VoiceActivityTimeout&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(from._impl_.speech_start_timeout_ != nullptr);
      if (_this->_impl_.speech_start_timeout_ == nullptr) {
        _this->_impl_.speech_start_timeout_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_start_timeout_);
      } else {
        _this->_impl_.speech_start_timeout_->MergeFrom(*from._impl_.speech_start_timeout_);
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.speech_end_timeout_ != nullptr);
      if (_this->_impl_.speech_end_timeout_ == nullptr) {
        _this->_impl_.speech_end_timeout_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_end_timeout_);
      } else {
        _this->_impl_.speech_end_timeout_->MergeFrom(*from._impl_.speech_end_timeout_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognitionConfig_VoiceActivityTimeout::CopyFrom(const StreamingRecognitionConfig_VoiceActivityTimeout& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognitionConfig_VoiceActivityTimeout::InternalSwap(StreamingRecognitionConfig_VoiceActivityTimeout* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_end_timeout_)
      + sizeof(StreamingRecognitionConfig_VoiceActivityTimeout::_impl_.speech_end_timeout_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig_VoiceActivityTimeout, _impl_.speech_start_timeout_)>(
          reinterpret_cast<char*>(&_impl_.speech_start_timeout_),
          reinterpret_cast<char*>(&other->_impl_.speech_start_timeout_));
}

::google::protobuf::Metadata StreamingRecognitionConfig_VoiceActivityTimeout::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognitionConfig::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<StreamingRecognitionConfig>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_._has_bits_);
};

StreamingRecognitionConfig::StreamingRecognitionConfig(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognitionConfig_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognitionConfig)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::StreamingRecognitionConfig& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

StreamingRecognitionConfig::StreamingRecognitionConfig(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const StreamingRecognitionConfig& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognitionConfig_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognitionConfig* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.config_ = ((cached_has_bits & 0x00000001U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.config_)
                : nullptr;
  _impl_.voice_activity_timeout_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.voice_activity_timeout_)
                : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, single_utterance_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, single_utterance_),
           offsetof(Impl_, enable_voice_activity_events_) -
               offsetof(Impl_, single_utterance_) +
               sizeof(Impl_::enable_voice_activity_events_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognitionConfig)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognitionConfig::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0} {}

inline void StreamingRecognitionConfig::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, config_),
           0,
           offsetof(Impl_, enable_voice_activity_events_) -
               offsetof(Impl_, config_) +
               sizeof(Impl_::enable_voice_activity_events_));
}
StreamingRecognitionConfig::~StreamingRecognitionConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognitionConfig)
  SharedDtor(*this);
}
inline void StreamingRecognitionConfig::SharedDtor(MessageLite& self) {
  StreamingRecognitionConfig& this_ = static_cast<StreamingRecognitionConfig&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.config_;
  delete this_._impl_.voice_activity_timeout_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL StreamingRecognitionConfig::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) StreamingRecognitionConfig(arena);
}
constexpr auto StreamingRecognitionConfig::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(StreamingRecognitionConfig),
                                            alignof(StreamingRecognitionConfig));
}
constexpr auto StreamingRecognitionConfig::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_StreamingRecognitionConfig_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &StreamingRecognitionConfig::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<StreamingRecognitionConfig>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &StreamingRecognitionConfig::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<StreamingRecognitionConfig>(), &StreamingRecognitionConfig::ByteSizeLong,
              &StreamingRecognitionConfig::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_._cached_size_),
          false,
      },
      &StreamingRecognitionConfig::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull StreamingRecognitionConfig_class_data_ =
        StreamingRecognitionConfig::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
StreamingRecognitionConfig::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&StreamingRecognitionConfig_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(StreamingRecognitionConfig_class_data_.tc_table);
  return StreamingRecognitionConfig_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 5, 2, 0, 2>
StreamingRecognitionConfig::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_._has_bits_),
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967240,  // skipmap
    offsetof(decltype(_table_), field_entries),
    5,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    StreamingRecognitionConfig_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionConfig>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_)}},
    // bool single_utterance = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionConfig, _impl_.single_utterance_), 2>(),
     {16, 2, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.single_utterance_)}},
    // bool interim_results = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionConfig, _impl_.interim_results_), 3>(),
     {24, 3, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.interim_results_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool enable_voice_activity_events = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionConfig, _impl_.enable_voice_activity_events_), 4>(),
     {40, 4, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.enable_voice_activity_events_)}},
    // .google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout voice_activity_timeout = 6;
    {::_pbi::TcParser::FastMtS1,
     {50, 1, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.voice_activity_timeout_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool single_utterance = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.single_utterance_), _Internal::kHasBitsOffset + 2, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // bool interim_results = 3;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.interim_results_), _Internal::kHasBitsOffset + 3, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // bool enable_voice_activity_events = 5;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.enable_voice_activity_events_), _Internal::kHasBitsOffset + 4, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // .google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout voice_activity_timeout = 6;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.voice_activity_timeout_), _Internal::kHasBitsOffset + 1, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionConfig>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionConfig_VoiceActivityTimeout>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void StreamingRecognitionConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognitionConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(_impl_.config_ != nullptr);
      _impl_.config_->Clear();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.voice_activity_timeout_ != nullptr);
      _impl_.voice_activity_timeout_->Clear();
    }
  }
  ::memset(&_impl_.single_utterance_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.enable_voice_activity_events_) -
      reinterpret_cast<char*>(&_impl_.single_utterance_)) + sizeof(_impl_.enable_voice_activity_events_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL StreamingRecognitionConfig::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const StreamingRecognitionConfig& this_ = static_cast<const StreamingRecognitionConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL StreamingRecognitionConfig::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const StreamingRecognitionConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognitionConfig)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
  if ((cached_has_bits & 0x00000001U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        1, *this_._impl_.config_, this_._impl_.config_->GetCachedSize(), target,
        stream);
  }

  // bool single_utterance = 2;
  if ((cached_has_bits & 0x00000004U) != 0) {
    if (this_._internal_single_utterance() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          2, this_._internal_single_utterance(), target);
    }
  }

  // bool interim_results = 3;
  if ((cached_has_bits & 0x00000008U) != 0) {
    if (this_._internal_interim_results() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          3, this_._internal_interim_results(), target);
    }
  }

  // bool enable_voice_activity_events = 5;
  if ((cached_has_bits & 0x00000010U) != 0) {
    if (this_._internal_enable_voice_activity_events() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          5, this_._internal_enable_voice_activity_events(), target);
    }
  }

  // .google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout voice_activity_timeout = 6;
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        6, *this_._impl_.voice_activity_timeout_, this_._impl_.voice_activity_timeout_->GetCachedSize(), target,
        stream);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognitionConfig)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t StreamingRecognitionConfig::ByteSizeLong(const MessageLite& base) {
  const StreamingRecognitionConfig& this_ = static_cast<const StreamingRecognitionConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t StreamingRecognitionConfig::ByteSizeLong() const {
  const StreamingRecognitionConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognitionConfig)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000001fU) != 0) {
    // .google.cloud.speech.v1.RecognitionConfig config = 1 [(.google.api.field_behavior) = REQUIRED];
    if ((cached_has_bits & 0x00000001U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.config_);
    }
    // .google.cloud.speech.v1.StreamingRecognitionConfig.VoiceActivityTimeout voice_activity_timeout = 6;
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.voice_activity_timeout_);
    }
    // bool single_utterance = 2;
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (this_._internal_single_utterance() != 0) {
        total_size += 2;
      }
    }
    // bool interim_results = 3;
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (this_._internal_interim_results() != 0) {
        total_size += 2;
      }
    }
    // bool enable_voice_activity_events = 5;
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (this_._internal_enable_voice_activity_events() != 0) {
        total_size += 2;
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void StreamingRecognitionConfig::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognitionConfig*>(&to_msg);
  auto& from = static_cast<const StreamingRecognitionConfig&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognitionConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000001fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(from._impl_.config_ != nullptr);
      if (_this->_impl_.config_ == nullptr) {
        _this->_impl_.config_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.config_);
      } else {
        _this->_impl_.config_->MergeFrom(*from._impl_.config_);
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.voice_activity_timeout_ != nullptr);
      if (_this->_impl_.voice_activity_timeout_ == nullptr) {
        _this->_impl_.voice_activity_timeout_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.voice_activity_timeout_);
      } else {
        _this->_impl_.voice_activity_timeout_->MergeFrom(*from._impl_.voice_activity_timeout_);
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (from._internal_single_utterance() != 0) {
        _this->_impl_.single_utterance_ = from._impl_.single_utterance_;
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (from._internal_interim_results() != 0) {
        _this->_impl_.interim_results_ = from._impl_.interim_results_;
      }
    }
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (from._internal_enable_voice_activity_events() != 0) {
        _this->_impl_.enable_voice_activity_events_ = from._impl_.enable_voice_activity_events_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognitionConfig::CopyFrom(const StreamingRecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognitionConfig::InternalSwap(StreamingRecognitionConfig* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.enable_voice_activity_events_)
      + sizeof(StreamingRecognitionConfig::_impl_.enable_voice_activity_events_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognitionConfig, _impl_.config_)>(
          reinterpret_cast<char*>(&_impl_.config_),
          reinterpret_cast<char*>(&other->_impl_.config_));
}

::google::protobuf::Metadata StreamingRecognitionConfig::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RecognitionConfig::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<RecognitionConfig>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_._has_bits_);
};

void RecognitionConfig::clear_adaptation() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.adaptation_ != nullptr) _impl_.adaptation_->Clear();
  _impl_._has_bits_[0] &= ~0x00000010U;
}
void RecognitionConfig::clear_transcript_normalization() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.transcript_normalization_ != nullptr) _impl_.transcript_normalization_->Clear();
  _impl_._has_bits_[0] &= ~0x00000080U;
}
void RecognitionConfig::clear_enable_spoken_punctuation() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.enable_spoken_punctuation_ != nullptr) _impl_.enable_spoken_punctuation_->Clear();
  _impl_._has_bits_[0] &= ~0x00000020U;
}
void RecognitionConfig::clear_enable_spoken_emojis() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.enable_spoken_emojis_ != nullptr) _impl_.enable_spoken_emojis_->Clear();
  _impl_._has_bits_[0] &= ~0x00000040U;
}
RecognitionConfig::RecognitionConfig(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognitionConfig_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognitionConfig)
}
PROTOBUF_NDEBUG_INLINE RecognitionConfig::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::RecognitionConfig& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        speech_contexts_{visibility, arena, from.speech_contexts_},
        alternative_language_codes_{visibility, arena, from.alternative_language_codes_},
        language_code_(arena, from.language_code_),
        model_(arena, from.model_) {}

RecognitionConfig::RecognitionConfig(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const RecognitionConfig& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognitionConfig_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognitionConfig* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.metadata_ = ((cached_has_bits & 0x00000004U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.metadata_)
                : nullptr;
  _impl_.diarization_config_ = ((cached_has_bits & 0x00000008U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.diarization_config_)
                : nullptr;
  _impl_.adaptation_ = ((cached_has_bits & 0x00000010U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.adaptation_)
                : nullptr;
  _impl_.enable_spoken_punctuation_ = ((cached_has_bits & 0x00000020U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.enable_spoken_punctuation_)
                : nullptr;
  _impl_.enable_spoken_emojis_ = ((cached_has_bits & 0x00000040U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.enable_spoken_emojis_)
                : nullptr;
  _impl_.transcript_normalization_ = ((cached_has_bits & 0x00000080U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.transcript_normalization_)
                : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, encoding_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, encoding_),
           offsetof(Impl_, enable_word_confidence_) -
               offsetof(Impl_, encoding_) +
               sizeof(Impl_::enable_word_confidence_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognitionConfig)
}
PROTOBUF_NDEBUG_INLINE RecognitionConfig::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        speech_contexts_{visibility, arena},
        alternative_language_codes_{visibility, arena},
        language_code_(arena),
        model_(arena) {}

inline void RecognitionConfig::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, metadata_),
           0,
           offsetof(Impl_, enable_word_confidence_) -
               offsetof(Impl_, metadata_) +
               sizeof(Impl_::enable_word_confidence_));
}
RecognitionConfig::~RecognitionConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognitionConfig)
  SharedDtor(*this);
}
inline void RecognitionConfig::SharedDtor(MessageLite& self) {
  RecognitionConfig& this_ = static_cast<RecognitionConfig&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.language_code_.Destroy();
  this_._impl_.model_.Destroy();
  delete this_._impl_.metadata_;
  delete this_._impl_.diarization_config_;
  delete this_._impl_.adaptation_;
  delete this_._impl_.enable_spoken_punctuation_;
  delete this_._impl_.enable_spoken_emojis_;
  delete this_._impl_.transcript_normalization_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL RecognitionConfig::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) RecognitionConfig(arena);
}
constexpr auto RecognitionConfig::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.alternative_language_codes_) +
          decltype(RecognitionConfig::_impl_.alternative_language_codes_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.speech_contexts_) +
          decltype(RecognitionConfig::_impl_.speech_contexts_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(RecognitionConfig), alignof(RecognitionConfig), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&RecognitionConfig::PlacementNew_,
                                 sizeof(RecognitionConfig),
                                 alignof(RecognitionConfig));
  }
}
constexpr auto RecognitionConfig::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_RecognitionConfig_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &RecognitionConfig::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<RecognitionConfig>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &RecognitionConfig::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<RecognitionConfig>(), &RecognitionConfig::ByteSizeLong,
              &RecognitionConfig::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_._cached_size_),
          false,
      },
      &RecognitionConfig::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull RecognitionConfig_class_data_ =
        RecognitionConfig::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
RecognitionConfig::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&RecognitionConfig_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(RecognitionConfig_class_data_.tc_table);
  return RecognitionConfig_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<5, 20, 7, 109, 2>
RecognitionConfig::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_._has_bits_),
    0, // no _extensions_
    24, 248,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4279337472,  // skipmap
    offsetof(decltype(_table_), field_entries),
    20,  // num_field_entries
    7,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    RecognitionConfig_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionConfig>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.encoding_), 8>(),
     {8, 8, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.encoding_)}},
    // int32 sample_rate_hertz = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.sample_rate_hertz_), 9>(),
     {16, 9, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.sample_rate_hertz_)}},
    // string language_code = 3 [(.google.api.field_behavior) = REQUIRED];
    {::_pbi::TcParser::FastUS1,
     {26, 0, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.language_code_)}},
    // int32 max_alternatives = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.max_alternatives_), 10>(),
     {32, 10, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.max_alternatives_)}},
    // bool profanity_filter = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.profanity_filter_), 12>(),
     {40, 12, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.profanity_filter_)}},
    // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;
    {::_pbi::TcParser::FastMtR1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.speech_contexts_)}},
    // int32 audio_channel_count = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionConfig, _impl_.audio_channel_count_), 11>(),
     {56, 11, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.audio_channel_count_)}},
    // bool enable_word_time_offsets = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_word_time_offsets_), 13>(),
     {64, 13, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_time_offsets_)}},
    // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;
    {::_pbi::TcParser::FastMtS1,
     {74, 2, 1, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.metadata_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool enable_automatic_punctuation = 11;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_automatic_punctuation_), 14>(),
     {88, 14, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_automatic_punctuation_)}},
    // bool enable_separate_recognition_per_channel = 12;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_), 15>(),
     {96, 15, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_)}},
    // string model = 13;
    {::_pbi::TcParser::FastUS1,
     {106, 1, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.model_)}},
    // bool use_enhanced = 14;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.use_enhanced_), 16>(),
     {112, 16, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.use_enhanced_)}},
    // bool enable_word_confidence = 15;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RecognitionConfig, _impl_.enable_word_confidence_), 17>(),
     {120, 17, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_confidence_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // repeated string alternative_language_codes = 18;
    {::_pbi::TcParser::FastUR2,
     {402, 63, 0, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.alternative_language_codes_)}},
    // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;
    {::_pbi::TcParser::FastMtS2,
     {410, 3, 2, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.diarization_config_)}},
    // .google.cloud.speech.v1.SpeechAdaptation adaptation = 20;
    {::_pbi::TcParser::FastMtS2,
     {418, 4, 3, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.adaptation_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.protobuf.BoolValue enable_spoken_punctuation = 22;
    {::_pbi::TcParser::FastMtS2,
     {434, 5, 4, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_spoken_punctuation_)}},
    // .google.protobuf.BoolValue enable_spoken_emojis = 23;
    {::_pbi::TcParser::FastMtS2,
     {442, 6, 5, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_spoken_emojis_)}},
    // .google.cloud.speech.v1.TranscriptNormalization transcript_normalization = 24 [(.google.api.field_behavior) = OPTIONAL];
    {::_pbi::TcParser::FastMtS2,
     {450, 7, 6, PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.transcript_normalization_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.encoding_), _Internal::kHasBitsOffset + 8, 0, (0 | ::_fl::kFcOptional | ::_fl::kOpenEnum)},
    // int32 sample_rate_hertz = 2;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.sample_rate_hertz_), _Internal::kHasBitsOffset + 9, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // string language_code = 3 [(.google.api.field_behavior) = REQUIRED];
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.language_code_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int32 max_alternatives = 4;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.max_alternatives_), _Internal::kHasBitsOffset + 10, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // bool profanity_filter = 5;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.profanity_filter_), _Internal::kHasBitsOffset + 12, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.speech_contexts_), -1, 0, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // int32 audio_channel_count = 7;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.audio_channel_count_), _Internal::kHasBitsOffset + 11, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // bool enable_word_time_offsets = 8;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_time_offsets_), _Internal::kHasBitsOffset + 13, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.metadata_), _Internal::kHasBitsOffset + 2, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool enable_automatic_punctuation = 11;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_automatic_punctuation_), _Internal::kHasBitsOffset + 14, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // bool enable_separate_recognition_per_channel = 12;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_separate_recognition_per_channel_), _Internal::kHasBitsOffset + 15, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // string model = 13;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.model_), _Internal::kHasBitsOffset + 1, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // bool use_enhanced = 14;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.use_enhanced_), _Internal::kHasBitsOffset + 16, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // bool enable_word_confidence = 15;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_confidence_), _Internal::kHasBitsOffset + 17, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // repeated string alternative_language_codes = 18;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.alternative_language_codes_), -1, 0, (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.diarization_config_), _Internal::kHasBitsOffset + 3, 2, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.SpeechAdaptation adaptation = 20;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.adaptation_), _Internal::kHasBitsOffset + 4, 3, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.BoolValue enable_spoken_punctuation = 22;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_spoken_punctuation_), _Internal::kHasBitsOffset + 5, 4, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.BoolValue enable_spoken_emojis = 23;
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_spoken_emojis_), _Internal::kHasBitsOffset + 6, 5, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.TranscriptNormalization transcript_normalization = 24 [(.google.api.field_behavior) = OPTIONAL];
    {PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.transcript_normalization_), _Internal::kHasBitsOffset + 7, 6, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechContext>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionMetadata>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeakerDiarizationConfig>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptation>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::BoolValue>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::BoolValue>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::TranscriptNormalization>()},
  }},
  {{
    "\50\0\0\15\0\0\0\0\0\0\0\0\5\0\0\32\0\0\0\0\0\0\0\0"
    "google.cloud.speech.v1.RecognitionConfig"
    "language_code"
    "model"
    "alternative_language_codes"
  }},
};
PROTOBUF_NOINLINE void RecognitionConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognitionConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.speech_contexts_.Clear();
  _impl_.alternative_language_codes_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x000000ffU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      _impl_.language_code_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      _impl_.model_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(_impl_.metadata_ != nullptr);
      _impl_.metadata_->Clear();
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      ABSL_DCHECK(_impl_.diarization_config_ != nullptr);
      _impl_.diarization_config_->Clear();
    }
    if ((cached_has_bits & 0x00000010U) != 0) {
      ABSL_DCHECK(_impl_.adaptation_ != nullptr);
      _impl_.adaptation_->Clear();
    }
    if ((cached_has_bits & 0x00000020U) != 0) {
      ABSL_DCHECK(_impl_.enable_spoken_punctuation_ != nullptr);
      _impl_.enable_spoken_punctuation_->Clear();
    }
    if ((cached_has_bits & 0x00000040U) != 0) {
      ABSL_DCHECK(_impl_.enable_spoken_emojis_ != nullptr);
      _impl_.enable_spoken_emojis_->Clear();
    }
    if ((cached_has_bits & 0x00000080U) != 0) {
      ABSL_DCHECK(_impl_.transcript_normalization_ != nullptr);
      _impl_.transcript_normalization_->Clear();
    }
  }
  if ((cached_has_bits & 0x0000ff00U) != 0) {
    ::memset(&_impl_.encoding_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.enable_separate_recognition_per_channel_) -
        reinterpret_cast<char*>(&_impl_.encoding_)) + sizeof(_impl_.enable_separate_recognition_per_channel_));
  }
  if ((cached_has_bits & 0x00030000U) != 0) {
    ::memset(&_impl_.use_enhanced_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.enable_word_confidence_) -
        reinterpret_cast<char*>(&_impl_.use_enhanced_)) + sizeof(_impl_.enable_word_confidence_));
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL RecognitionConfig::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const RecognitionConfig& this_ = static_cast<const RecognitionConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL RecognitionConfig::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const RecognitionConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognitionConfig)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;
  if ((this_._impl_._has_bits_[0] & 0x00000100U) != 0) {
    if (this_._internal_encoding() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteEnumToArray(
          1, this_._internal_encoding(), target);
    }
  }

  // int32 sample_rate_hertz = 2;
  if ((this_._impl_._has_bits_[0] & 0x00000200U) != 0) {
    if (this_._internal_sample_rate_hertz() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<2>(
              stream, this_._internal_sample_rate_hertz(), target);
    }
  }

  // string language_code = 3 [(.google.api.field_behavior) = REQUIRED];
  if ((this_._impl_._has_bits_[0] & 0x00000001U) != 0) {
    if (!this_._internal_language_code().empty()) {
      const ::std::string& _s = this_._internal_language_code();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionConfig.language_code");
      target = stream->WriteStringMaybeAliased(3, _s, target);
    }
  }

  // int32 max_alternatives = 4;
  if ((this_._impl_._has_bits_[0] & 0x00000400U) != 0) {
    if (this_._internal_max_alternatives() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<4>(
              stream, this_._internal_max_alternatives(), target);
    }
  }

  // bool profanity_filter = 5;
  if ((this_._impl_._has_bits_[0] & 0x00001000U) != 0) {
    if (this_._internal_profanity_filter() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          5, this_._internal_profanity_filter(), target);
    }
  }

  // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;
  for (unsigned i = 0, n = static_cast<unsigned>(
                           this_._internal_speech_contexts_size());
       i < n; i++) {
    const auto& repfield = this_._internal_speech_contexts().Get(i);
    target =
        ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
            6, repfield, repfield.GetCachedSize(),
            target, stream);
  }

  // int32 audio_channel_count = 7;
  if ((this_._impl_._has_bits_[0] & 0x00000800U) != 0) {
    if (this_._internal_audio_channel_count() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<7>(
              stream, this_._internal_audio_channel_count(), target);
    }
  }

  // bool enable_word_time_offsets = 8;
  if ((this_._impl_._has_bits_[0] & 0x00002000U) != 0) {
    if (this_._internal_enable_word_time_offsets() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          8, this_._internal_enable_word_time_offsets(), target);
    }
  }

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;
  if ((cached_has_bits & 0x00000004U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        9, *this_._impl_.metadata_, this_._impl_.metadata_->GetCachedSize(), target,
        stream);
  }

  // bool enable_automatic_punctuation = 11;
  if ((cached_has_bits & 0x00004000U) != 0) {
    if (this_._internal_enable_automatic_punctuation() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          11, this_._internal_enable_automatic_punctuation(), target);
    }
  }

  // bool enable_separate_recognition_per_channel = 12;
  if ((cached_has_bits & 0x00008000U) != 0) {
    if (this_._internal_enable_separate_recognition_per_channel() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          12, this_._internal_enable_separate_recognition_per_channel(), target);
    }
  }

  // string model = 13;
  if ((cached_has_bits & 0x00000002U) != 0) {
    if (!this_._internal_model().empty()) {
      const ::std::string& _s = this_._internal_model();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionConfig.model");
      target = stream->WriteStringMaybeAliased(13, _s, target);
    }
  }

  // bool use_enhanced = 14;
  if ((cached_has_bits & 0x00010000U) != 0) {
    if (this_._internal_use_enhanced() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          14, this_._internal_use_enhanced(), target);
    }
  }

  // bool enable_word_confidence = 15;
  if ((cached_has_bits & 0x00020000U) != 0) {
    if (this_._internal_enable_word_confidence() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          15, this_._internal_enable_word_confidence(), target);
    }
  }

  // repeated string alternative_language_codes = 18;
  for (int i = 0, n = this_._internal_alternative_language_codes_size(); i < n; ++i) {
    const auto& s = this_._internal_alternative_language_codes().Get(i);
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionConfig.alternative_language_codes");
    target = stream->WriteString(18, s, target);
  }

  // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;
  if ((cached_has_bits & 0x00000008U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        19, *this_._impl_.diarization_config_, this_._impl_.diarization_config_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.SpeechAdaptation adaptation = 20;
  if ((cached_has_bits & 0x00000010U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        20, *this_._impl_.adaptation_, this_._impl_.adaptation_->GetCachedSize(), target,
        stream);
  }

  // .google.protobuf.BoolValue enable_spoken_punctuation = 22;
  if ((cached_has_bits & 0x00000020U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        22, *this_._impl_.enable_spoken_punctuation_, this_._impl_.enable_spoken_punctuation_->GetCachedSize(), target,
        stream);
  }

  // .google.protobuf.BoolValue enable_spoken_emojis = 23;
  if ((cached_has_bits & 0x00000040U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        23, *this_._impl_.enable_spoken_emojis_, this_._impl_.enable_spoken_emojis_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.TranscriptNormalization transcript_normalization = 24 [(.google.api.field_behavior) = OPTIONAL];
  if ((cached_has_bits & 0x00000080U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        24, *this_._impl_.transcript_normalization_, this_._impl_.transcript_normalization_->GetCachedSize(), target,
        stream);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognitionConfig)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t RecognitionConfig::ByteSizeLong(const MessageLite& base) {
  const RecognitionConfig& this_ = static_cast<const RecognitionConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t RecognitionConfig::ByteSizeLong() const {
  const RecognitionConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognitionConfig)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
   {
    // repeated .google.cloud.speech.v1.SpeechContext speech_contexts = 6;
    {
      total_size += 1UL * this_._internal_speech_contexts_size();
      for (const auto& msg : this_._internal_speech_contexts()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
    // repeated string alternative_language_codes = 18;
    {
      total_size +=
          2 * ::google::protobuf::internal::FromIntSize(this_._internal_alternative_language_codes().size());
      for (int i = 0, n = this_._internal_alternative_language_codes().size(); i < n; ++i) {
        total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
            this_._internal_alternative_language_codes().Get(i));
      }
    }
  }
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x000000ffU) != 0) {
    // string language_code = 3 [(.google.api.field_behavior) = REQUIRED];
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!this_._internal_language_code().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_language_code());
      }
    }
    // string model = 13;
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (!this_._internal_model().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_model());
      }
    }
    // .google.cloud.speech.v1.RecognitionMetadata metadata = 9;
    if ((cached_has_bits & 0x00000004U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.metadata_);
    }
    // .google.cloud.speech.v1.SpeakerDiarizationConfig diarization_config = 19;
    if ((cached_has_bits & 0x00000008U) != 0) {
      total_size += 2 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.diarization_config_);
    }
    // .google.cloud.speech.v1.SpeechAdaptation adaptation = 20;
    if ((cached_has_bits & 0x00000010U) != 0) {
      total_size += 2 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.adaptation_);
    }
    // .google.protobuf.BoolValue enable_spoken_punctuation = 22;
    if ((cached_has_bits & 0x00000020U) != 0) {
      total_size += 2 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.enable_spoken_punctuation_);
    }
    // .google.protobuf.BoolValue enable_spoken_emojis = 23;
    if ((cached_has_bits & 0x00000040U) != 0) {
      total_size += 2 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.enable_spoken_emojis_);
    }
    // .google.cloud.speech.v1.TranscriptNormalization transcript_normalization = 24 [(.google.api.field_behavior) = OPTIONAL];
    if ((cached_has_bits & 0x00000080U) != 0) {
      total_size += 2 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.transcript_normalization_);
    }
  }
  if ((cached_has_bits & 0x0000ff00U) != 0) {
    // .google.cloud.speech.v1.RecognitionConfig.AudioEncoding encoding = 1;
    if ((cached_has_bits & 0x00000100U) != 0) {
      if (this_._internal_encoding() != 0) {
        total_size += 1 +
                      ::_pbi::WireFormatLite::EnumSize(this_._internal_encoding());
      }
    }
    // int32 sample_rate_hertz = 2;
    if ((cached_has_bits & 0x00000200U) != 0) {
      if (this_._internal_sample_rate_hertz() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_sample_rate_hertz());
      }
    }
    // int32 max_alternatives = 4;
    if ((cached_has_bits & 0x00000400U) != 0) {
      if (this_._internal_max_alternatives() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_max_alternatives());
      }
    }
    // int32 audio_channel_count = 7;
    if ((cached_has_bits & 0x00000800U) != 0) {
      if (this_._internal_audio_channel_count() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_audio_channel_count());
      }
    }
    // bool profanity_filter = 5;
    if ((cached_has_bits & 0x00001000U) != 0) {
      if (this_._internal_profanity_filter() != 0) {
        total_size += 2;
      }
    }
    // bool enable_word_time_offsets = 8;
    if ((cached_has_bits & 0x00002000U) != 0) {
      if (this_._internal_enable_word_time_offsets() != 0) {
        total_size += 2;
      }
    }
    // bool enable_automatic_punctuation = 11;
    if ((cached_has_bits & 0x00004000U) != 0) {
      if (this_._internal_enable_automatic_punctuation() != 0) {
        total_size += 2;
      }
    }
    // bool enable_separate_recognition_per_channel = 12;
    if ((cached_has_bits & 0x00008000U) != 0) {
      if (this_._internal_enable_separate_recognition_per_channel() != 0) {
        total_size += 2;
      }
    }
  }
  if ((cached_has_bits & 0x00030000U) != 0) {
    // bool use_enhanced = 14;
    if ((cached_has_bits & 0x00010000U) != 0) {
      if (this_._internal_use_enhanced() != 0) {
        total_size += 2;
      }
    }
    // bool enable_word_confidence = 15;
    if ((cached_has_bits & 0x00020000U) != 0) {
      if (this_._internal_enable_word_confidence() != 0) {
        total_size += 2;
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void RecognitionConfig::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognitionConfig*>(&to_msg);
  auto& from = static_cast<const RecognitionConfig&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognitionConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_speech_contexts()->MergeFrom(
      from._internal_speech_contexts());
  _this->_internal_mutable_alternative_language_codes()->MergeFrom(from._internal_alternative_language_codes());
  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x000000ffU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!from._internal_language_code().empty()) {
        _this->_internal_set_language_code(from._internal_language_code());
      } else {
        if (_this->_impl_.language_code_.IsDefault()) {
          _this->_internal_set_language_code("");
        }
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (!from._internal_model().empty()) {
        _this->_internal_set_model(from._internal_model());
      } else {
        if (_this->_impl_.model_.IsDefault()) {
          _this->_internal_set_model("");
        }
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(from._impl_.metadata_ != nullptr);
      if (_this->_impl_.metadata_ == nullptr) {
        _this->_impl_.metadata_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.metadata_);
      } else {
        _this->_impl_.metadata_->MergeFrom(*from._impl_.metadata_);
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      ABSL_DCHECK(from._impl_.diarization_config_ != nullptr);
      if (_this->_impl_.diarization_config_ == nullptr) {
        _this->_impl_.diarization_config_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.diarization_config_);
      } else {
        _this->_impl_.diarization_config_->MergeFrom(*from._impl_.diarization_config_);
      }
    }
    if ((cached_has_bits & 0x00000010U) != 0) {
      ABSL_DCHECK(from._impl_.adaptation_ != nullptr);
      if (_this->_impl_.adaptation_ == nullptr) {
        _this->_impl_.adaptation_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.adaptation_);
      } else {
        _this->_impl_.adaptation_->MergeFrom(*from._impl_.adaptation_);
      }
    }
    if ((cached_has_bits & 0x00000020U) != 0) {
      ABSL_DCHECK(from._impl_.enable_spoken_punctuation_ != nullptr);
      if (_this->_impl_.enable_spoken_punctuation_ == nullptr) {
        _this->_impl_.enable_spoken_punctuation_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.enable_spoken_punctuation_);
      } else {
        _this->_impl_.enable_spoken_punctuation_->MergeFrom(*from._impl_.enable_spoken_punctuation_);
      }
    }
    if ((cached_has_bits & 0x00000040U) != 0) {
      ABSL_DCHECK(from._impl_.enable_spoken_emojis_ != nullptr);
      if (_this->_impl_.enable_spoken_emojis_ == nullptr) {
        _this->_impl_.enable_spoken_emojis_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.enable_spoken_emojis_);
      } else {
        _this->_impl_.enable_spoken_emojis_->MergeFrom(*from._impl_.enable_spoken_emojis_);
      }
    }
    if ((cached_has_bits & 0x00000080U) != 0) {
      ABSL_DCHECK(from._impl_.transcript_normalization_ != nullptr);
      if (_this->_impl_.transcript_normalization_ == nullptr) {
        _this->_impl_.transcript_normalization_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.transcript_normalization_);
      } else {
        _this->_impl_.transcript_normalization_->MergeFrom(*from._impl_.transcript_normalization_);
      }
    }
  }
  if ((cached_has_bits & 0x0000ff00U) != 0) {
    if ((cached_has_bits & 0x00000100U) != 0) {
      if (from._internal_encoding() != 0) {
        _this->_impl_.encoding_ = from._impl_.encoding_;
      }
    }
    if ((cached_has_bits & 0x00000200U) != 0) {
      if (from._internal_sample_rate_hertz() != 0) {
        _this->_impl_.sample_rate_hertz_ = from._impl_.sample_rate_hertz_;
      }
    }
    if ((cached_has_bits & 0x00000400U) != 0) {
      if (from._internal_max_alternatives() != 0) {
        _this->_impl_.max_alternatives_ = from._impl_.max_alternatives_;
      }
    }
    if ((cached_has_bits & 0x00000800U) != 0) {
      if (from._internal_audio_channel_count() != 0) {
        _this->_impl_.audio_channel_count_ = from._impl_.audio_channel_count_;
      }
    }
    if ((cached_has_bits & 0x00001000U) != 0) {
      if (from._internal_profanity_filter() != 0) {
        _this->_impl_.profanity_filter_ = from._impl_.profanity_filter_;
      }
    }
    if ((cached_has_bits & 0x00002000U) != 0) {
      if (from._internal_enable_word_time_offsets() != 0) {
        _this->_impl_.enable_word_time_offsets_ = from._impl_.enable_word_time_offsets_;
      }
    }
    if ((cached_has_bits & 0x00004000U) != 0) {
      if (from._internal_enable_automatic_punctuation() != 0) {
        _this->_impl_.enable_automatic_punctuation_ = from._impl_.enable_automatic_punctuation_;
      }
    }
    if ((cached_has_bits & 0x00008000U) != 0) {
      if (from._internal_enable_separate_recognition_per_channel() != 0) {
        _this->_impl_.enable_separate_recognition_per_channel_ = from._impl_.enable_separate_recognition_per_channel_;
      }
    }
  }
  if ((cached_has_bits & 0x00030000U) != 0) {
    if ((cached_has_bits & 0x00010000U) != 0) {
      if (from._internal_use_enhanced() != 0) {
        _this->_impl_.use_enhanced_ = from._impl_.use_enhanced_;
      }
    }
    if ((cached_has_bits & 0x00020000U) != 0) {
      if (from._internal_enable_word_confidence() != 0) {
        _this->_impl_.enable_word_confidence_ = from._impl_.enable_word_confidence_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognitionConfig::CopyFrom(const RecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognitionConfig::InternalSwap(RecognitionConfig* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.speech_contexts_.InternalSwap(&other->_impl_.speech_contexts_);
  _impl_.alternative_language_codes_.InternalSwap(&other->_impl_.alternative_language_codes_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.language_code_, &other->_impl_.language_code_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.model_, &other->_impl_.model_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.enable_word_confidence_)
      + sizeof(RecognitionConfig::_impl_.enable_word_confidence_)
      - PROTOBUF_FIELD_OFFSET(RecognitionConfig, _impl_.metadata_)>(
          reinterpret_cast<char*>(&_impl_.metadata_),
          reinterpret_cast<char*>(&other->_impl_.metadata_));
}

::google::protobuf::Metadata RecognitionConfig::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeakerDiarizationConfig::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<SpeakerDiarizationConfig>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_._has_bits_);
};

SpeakerDiarizationConfig::SpeakerDiarizationConfig(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeakerDiarizationConfig_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeakerDiarizationConfig)
}
SpeakerDiarizationConfig::SpeakerDiarizationConfig(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const SpeakerDiarizationConfig& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeakerDiarizationConfig_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(from._impl_) {
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
}
PROTOBUF_NDEBUG_INLINE SpeakerDiarizationConfig::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0} {}

inline void SpeakerDiarizationConfig::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, enable_speaker_diarization_),
           0,
           offsetof(Impl_, speaker_tag_) -
               offsetof(Impl_, enable_speaker_diarization_) +
               sizeof(Impl_::speaker_tag_));
}
SpeakerDiarizationConfig::~SpeakerDiarizationConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeakerDiarizationConfig)
  SharedDtor(*this);
}
inline void SpeakerDiarizationConfig::SharedDtor(MessageLite& self) {
  SpeakerDiarizationConfig& this_ = static_cast<SpeakerDiarizationConfig&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL SpeakerDiarizationConfig::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) SpeakerDiarizationConfig(arena);
}
constexpr auto SpeakerDiarizationConfig::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(SpeakerDiarizationConfig),
                                            alignof(SpeakerDiarizationConfig));
}
constexpr auto SpeakerDiarizationConfig::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_SpeakerDiarizationConfig_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &SpeakerDiarizationConfig::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<SpeakerDiarizationConfig>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &SpeakerDiarizationConfig::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<SpeakerDiarizationConfig>(), &SpeakerDiarizationConfig::ByteSizeLong,
              &SpeakerDiarizationConfig::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_._cached_size_),
          false,
      },
      &SpeakerDiarizationConfig::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull SpeakerDiarizationConfig_class_data_ =
        SpeakerDiarizationConfig::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
SpeakerDiarizationConfig::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&SpeakerDiarizationConfig_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(SpeakerDiarizationConfig_class_data_.tc_table);
  return SpeakerDiarizationConfig_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 4, 0, 0, 2>
SpeakerDiarizationConfig::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_._has_bits_),
    0, // no _extensions_
    5, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967272,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    SpeakerDiarizationConfig_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeakerDiarizationConfig>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // bool enable_speaker_diarization = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_), 0>(),
     {8, 0, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_)}},
    // int32 min_speaker_count = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeakerDiarizationConfig, _impl_.min_speaker_count_), 1>(),
     {16, 1, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.min_speaker_count_)}},
    // int32 max_speaker_count = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeakerDiarizationConfig, _impl_.max_speaker_count_), 2>(),
     {24, 2, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.max_speaker_count_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeakerDiarizationConfig, _impl_.speaker_tag_), 3>(),
     {40, 3, 0, PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.speaker_tag_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // bool enable_speaker_diarization = 1;
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // int32 min_speaker_count = 2;
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.min_speaker_count_), _Internal::kHasBitsOffset + 1, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // int32 max_speaker_count = 3;
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.max_speaker_count_), _Internal::kHasBitsOffset + 2, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.speaker_tag_), _Internal::kHasBitsOffset + 3, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
  }},
  // no aux_entries
  {{
  }},
};
PROTOBUF_NOINLINE void SpeakerDiarizationConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000000fU) != 0) {
    ::memset(&_impl_.enable_speaker_diarization_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.speaker_tag_) -
        reinterpret_cast<char*>(&_impl_.enable_speaker_diarization_)) + sizeof(_impl_.speaker_tag_));
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL SpeakerDiarizationConfig::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const SpeakerDiarizationConfig& this_ = static_cast<const SpeakerDiarizationConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL SpeakerDiarizationConfig::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const SpeakerDiarizationConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // bool enable_speaker_diarization = 1;
  if ((this_._impl_._has_bits_[0] & 0x00000001U) != 0) {
    if (this_._internal_enable_speaker_diarization() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          1, this_._internal_enable_speaker_diarization(), target);
    }
  }

  // int32 min_speaker_count = 2;
  if ((this_._impl_._has_bits_[0] & 0x00000002U) != 0) {
    if (this_._internal_min_speaker_count() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<2>(
              stream, this_._internal_min_speaker_count(), target);
    }
  }

  // int32 max_speaker_count = 3;
  if ((this_._impl_._has_bits_[0] & 0x00000004U) != 0) {
    if (this_._internal_max_speaker_count() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<3>(
              stream, this_._internal_max_speaker_count(), target);
    }
  }

  // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
  if ((this_._impl_._has_bits_[0] & 0x00000008U) != 0) {
    if (this_._internal_speaker_tag() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<5>(
              stream, this_._internal_speaker_tag(), target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeakerDiarizationConfig)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t SpeakerDiarizationConfig::ByteSizeLong(const MessageLite& base) {
  const SpeakerDiarizationConfig& this_ = static_cast<const SpeakerDiarizationConfig&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t SpeakerDiarizationConfig::ByteSizeLong() const {
  const SpeakerDiarizationConfig& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000000fU) != 0) {
    // bool enable_speaker_diarization = 1;
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (this_._internal_enable_speaker_diarization() != 0) {
        total_size += 2;
      }
    }
    // int32 min_speaker_count = 2;
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (this_._internal_min_speaker_count() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_min_speaker_count());
      }
    }
    // int32 max_speaker_count = 3;
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (this_._internal_max_speaker_count() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_max_speaker_count());
      }
    }
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (this_._internal_speaker_tag() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_speaker_tag());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void SpeakerDiarizationConfig::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeakerDiarizationConfig*>(&to_msg);
  auto& from = static_cast<const SpeakerDiarizationConfig&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000000fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (from._internal_enable_speaker_diarization() != 0) {
        _this->_impl_.enable_speaker_diarization_ = from._impl_.enable_speaker_diarization_;
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (from._internal_min_speaker_count() != 0) {
        _this->_impl_.min_speaker_count_ = from._impl_.min_speaker_count_;
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (from._internal_max_speaker_count() != 0) {
        _this->_impl_.max_speaker_count_ = from._impl_.max_speaker_count_;
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (from._internal_speaker_tag() != 0) {
        _this->_impl_.speaker_tag_ = from._impl_.speaker_tag_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeakerDiarizationConfig::CopyFrom(const SpeakerDiarizationConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeakerDiarizationConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeakerDiarizationConfig::InternalSwap(SpeakerDiarizationConfig* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.speaker_tag_)
      + sizeof(SpeakerDiarizationConfig::_impl_.speaker_tag_)
      - PROTOBUF_FIELD_OFFSET(SpeakerDiarizationConfig, _impl_.enable_speaker_diarization_)>(
          reinterpret_cast<char*>(&_impl_.enable_speaker_diarization_),
          reinterpret_cast<char*>(&other->_impl_.enable_speaker_diarization_));
}

::google::protobuf::Metadata SpeakerDiarizationConfig::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RecognitionMetadata::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<RecognitionMetadata>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_._has_bits_);
};

RecognitionMetadata::RecognitionMetadata(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognitionMetadata_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognitionMetadata)
}
PROTOBUF_NDEBUG_INLINE RecognitionMetadata::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::RecognitionMetadata& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        recording_device_name_(arena, from.recording_device_name_),
        original_mime_type_(arena, from.original_mime_type_),
        audio_topic_(arena, from.audio_topic_) {}

RecognitionMetadata::RecognitionMetadata(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const RecognitionMetadata& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognitionMetadata_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognitionMetadata* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, interaction_type_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, interaction_type_),
           offsetof(Impl_, recording_device_type_) -
               offsetof(Impl_, interaction_type_) +
               sizeof(Impl_::recording_device_type_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognitionMetadata)
}
PROTOBUF_NDEBUG_INLINE RecognitionMetadata::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        recording_device_name_(arena),
        original_mime_type_(arena),
        audio_topic_(arena) {}

inline void RecognitionMetadata::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, interaction_type_),
           0,
           offsetof(Impl_, recording_device_type_) -
               offsetof(Impl_, interaction_type_) +
               sizeof(Impl_::recording_device_type_));
}
RecognitionMetadata::~RecognitionMetadata() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognitionMetadata)
  SharedDtor(*this);
}
inline void RecognitionMetadata::SharedDtor(MessageLite& self) {
  RecognitionMetadata& this_ = static_cast<RecognitionMetadata&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.recording_device_name_.Destroy();
  this_._impl_.original_mime_type_.Destroy();
  this_._impl_.audio_topic_.Destroy();
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL RecognitionMetadata::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) RecognitionMetadata(arena);
}
constexpr auto RecognitionMetadata::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(RecognitionMetadata),
                                            alignof(RecognitionMetadata));
}
constexpr auto RecognitionMetadata::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_RecognitionMetadata_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &RecognitionMetadata::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<RecognitionMetadata>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &RecognitionMetadata::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<RecognitionMetadata>(), &RecognitionMetadata::ByteSizeLong,
              &RecognitionMetadata::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_._cached_size_),
          false,
      },
      &RecognitionMetadata::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull RecognitionMetadata_class_data_ =
        RecognitionMetadata::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
RecognitionMetadata::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&RecognitionMetadata_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(RecognitionMetadata_class_data_.tc_table);
  return RecognitionMetadata_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 8, 0, 109, 2>
RecognitionMetadata::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_._has_bits_),
    0, // no _extensions_
    10, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294966530,  // skipmap
    offsetof(decltype(_table_), field_entries),
    8,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    RecognitionMetadata_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionMetadata>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string original_mime_type = 8;
    {::_pbi::TcParser::FastUS1,
     {66, 1, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.original_mime_type_)}},
    // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.interaction_type_), 3>(),
     {8, 3, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.interaction_type_)}},
    // string audio_topic = 10;
    {::_pbi::TcParser::FastUS1,
     {82, 2, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.audio_topic_)}},
    // uint32 industry_naics_code_of_audio = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.industry_naics_code_of_audio_), 4>(),
     {24, 4, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.industry_naics_code_of_audio_)}},
    // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.microphone_distance_), 5>(),
     {32, 5, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.microphone_distance_)}},
    // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.original_media_type_), 6>(),
     {40, 6, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.original_media_type_)}},
    // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RecognitionMetadata, _impl_.recording_device_type_), 7>(),
     {48, 7, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_type_)}},
    // string recording_device_name = 7;
    {::_pbi::TcParser::FastUS1,
     {58, 0, 0, PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_name_)}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.interaction_type_), _Internal::kHasBitsOffset + 3, 0, (0 | ::_fl::kFcOptional | ::_fl::kOpenEnum)},
    // uint32 industry_naics_code_of_audio = 3;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.industry_naics_code_of_audio_), _Internal::kHasBitsOffset + 4, 0, (0 | ::_fl::kFcOptional | ::_fl::kUInt32)},
    // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.microphone_distance_), _Internal::kHasBitsOffset + 5, 0, (0 | ::_fl::kFcOptional | ::_fl::kOpenEnum)},
    // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.original_media_type_), _Internal::kHasBitsOffset + 6, 0, (0 | ::_fl::kFcOptional | ::_fl::kOpenEnum)},
    // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_type_), _Internal::kHasBitsOffset + 7, 0, (0 | ::_fl::kFcOptional | ::_fl::kOpenEnum)},
    // string recording_device_name = 7;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_name_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // string original_mime_type = 8;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.original_mime_type_), _Internal::kHasBitsOffset + 1, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // string audio_topic = 10;
    {PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.audio_topic_), _Internal::kHasBitsOffset + 2, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\52\0\0\0\0\0\25\22\13\0\0\0\0\0\0\0"
    "google.cloud.speech.v1.RecognitionMetadata"
    "recording_device_name"
    "original_mime_type"
    "audio_topic"
  }},
};
PROTOBUF_NOINLINE void RecognitionMetadata::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognitionMetadata)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      _impl_.recording_device_name_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      _impl_.original_mime_type_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      _impl_.audio_topic_.ClearNonDefaultToEmpty();
    }
  }
  if ((cached_has_bits & 0x000000f8U) != 0) {
    ::memset(&_impl_.interaction_type_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.recording_device_type_) -
        reinterpret_cast<char*>(&_impl_.interaction_type_)) + sizeof(_impl_.recording_device_type_));
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL RecognitionMetadata::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const RecognitionMetadata& this_ = static_cast<const RecognitionMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL RecognitionMetadata::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const RecognitionMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognitionMetadata)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;
  if ((this_._impl_._has_bits_[0] & 0x00000008U) != 0) {
    if (this_._internal_interaction_type() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteEnumToArray(
          1, this_._internal_interaction_type(), target);
    }
  }

  // uint32 industry_naics_code_of_audio = 3;
  if ((this_._impl_._has_bits_[0] & 0x00000010U) != 0) {
    if (this_._internal_industry_naics_code_of_audio() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteUInt32ToArray(
          3, this_._internal_industry_naics_code_of_audio(), target);
    }
  }

  // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;
  if ((this_._impl_._has_bits_[0] & 0x00000020U) != 0) {
    if (this_._internal_microphone_distance() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteEnumToArray(
          4, this_._internal_microphone_distance(), target);
    }
  }

  // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;
  if ((this_._impl_._has_bits_[0] & 0x00000040U) != 0) {
    if (this_._internal_original_media_type() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteEnumToArray(
          5, this_._internal_original_media_type(), target);
    }
  }

  // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;
  if ((this_._impl_._has_bits_[0] & 0x00000080U) != 0) {
    if (this_._internal_recording_device_type() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteEnumToArray(
          6, this_._internal_recording_device_type(), target);
    }
  }

  // string recording_device_name = 7;
  if ((this_._impl_._has_bits_[0] & 0x00000001U) != 0) {
    if (!this_._internal_recording_device_name().empty()) {
      const ::std::string& _s = this_._internal_recording_device_name();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionMetadata.recording_device_name");
      target = stream->WriteStringMaybeAliased(7, _s, target);
    }
  }

  // string original_mime_type = 8;
  if ((this_._impl_._has_bits_[0] & 0x00000002U) != 0) {
    if (!this_._internal_original_mime_type().empty()) {
      const ::std::string& _s = this_._internal_original_mime_type();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionMetadata.original_mime_type");
      target = stream->WriteStringMaybeAliased(8, _s, target);
    }
  }

  // string audio_topic = 10;
  if ((this_._impl_._has_bits_[0] & 0x00000004U) != 0) {
    if (!this_._internal_audio_topic().empty()) {
      const ::std::string& _s = this_._internal_audio_topic();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionMetadata.audio_topic");
      target = stream->WriteStringMaybeAliased(10, _s, target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognitionMetadata)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t RecognitionMetadata::ByteSizeLong(const MessageLite& base) {
  const RecognitionMetadata& this_ = static_cast<const RecognitionMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t RecognitionMetadata::ByteSizeLong() const {
  const RecognitionMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognitionMetadata)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x000000ffU) != 0) {
    // string recording_device_name = 7;
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!this_._internal_recording_device_name().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_recording_device_name());
      }
    }
    // string original_mime_type = 8;
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (!this_._internal_original_mime_type().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_original_mime_type());
      }
    }
    // string audio_topic = 10;
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (!this_._internal_audio_topic().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_audio_topic());
      }
    }
    // .google.cloud.speech.v1.RecognitionMetadata.InteractionType interaction_type = 1;
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (this_._internal_interaction_type() != 0) {
        total_size += 1 +
                      ::_pbi::WireFormatLite::EnumSize(this_._internal_interaction_type());
      }
    }
    // uint32 industry_naics_code_of_audio = 3;
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (this_._internal_industry_naics_code_of_audio() != 0) {
        total_size += ::_pbi::WireFormatLite::UInt32SizePlusOne(
            this_._internal_industry_naics_code_of_audio());
      }
    }
    // .google.cloud.speech.v1.RecognitionMetadata.MicrophoneDistance microphone_distance = 4;
    if ((cached_has_bits & 0x00000020U) != 0) {
      if (this_._internal_microphone_distance() != 0) {
        total_size += 1 +
                      ::_pbi::WireFormatLite::EnumSize(this_._internal_microphone_distance());
      }
    }
    // .google.cloud.speech.v1.RecognitionMetadata.OriginalMediaType original_media_type = 5;
    if ((cached_has_bits & 0x00000040U) != 0) {
      if (this_._internal_original_media_type() != 0) {
        total_size += 1 +
                      ::_pbi::WireFormatLite::EnumSize(this_._internal_original_media_type());
      }
    }
    // .google.cloud.speech.v1.RecognitionMetadata.RecordingDeviceType recording_device_type = 6;
    if ((cached_has_bits & 0x00000080U) != 0) {
      if (this_._internal_recording_device_type() != 0) {
        total_size += 1 +
                      ::_pbi::WireFormatLite::EnumSize(this_._internal_recording_device_type());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void RecognitionMetadata::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognitionMetadata*>(&to_msg);
  auto& from = static_cast<const RecognitionMetadata&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognitionMetadata)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x000000ffU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!from._internal_recording_device_name().empty()) {
        _this->_internal_set_recording_device_name(from._internal_recording_device_name());
      } else {
        if (_this->_impl_.recording_device_name_.IsDefault()) {
          _this->_internal_set_recording_device_name("");
        }
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (!from._internal_original_mime_type().empty()) {
        _this->_internal_set_original_mime_type(from._internal_original_mime_type());
      } else {
        if (_this->_impl_.original_mime_type_.IsDefault()) {
          _this->_internal_set_original_mime_type("");
        }
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (!from._internal_audio_topic().empty()) {
        _this->_internal_set_audio_topic(from._internal_audio_topic());
      } else {
        if (_this->_impl_.audio_topic_.IsDefault()) {
          _this->_internal_set_audio_topic("");
        }
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (from._internal_interaction_type() != 0) {
        _this->_impl_.interaction_type_ = from._impl_.interaction_type_;
      }
    }
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (from._internal_industry_naics_code_of_audio() != 0) {
        _this->_impl_.industry_naics_code_of_audio_ = from._impl_.industry_naics_code_of_audio_;
      }
    }
    if ((cached_has_bits & 0x00000020U) != 0) {
      if (from._internal_microphone_distance() != 0) {
        _this->_impl_.microphone_distance_ = from._impl_.microphone_distance_;
      }
    }
    if ((cached_has_bits & 0x00000040U) != 0) {
      if (from._internal_original_media_type() != 0) {
        _this->_impl_.original_media_type_ = from._impl_.original_media_type_;
      }
    }
    if ((cached_has_bits & 0x00000080U) != 0) {
      if (from._internal_recording_device_type() != 0) {
        _this->_impl_.recording_device_type_ = from._impl_.recording_device_type_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognitionMetadata::CopyFrom(const RecognitionMetadata& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognitionMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognitionMetadata::InternalSwap(RecognitionMetadata* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.recording_device_name_, &other->_impl_.recording_device_name_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.original_mime_type_, &other->_impl_.original_mime_type_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.audio_topic_, &other->_impl_.audio_topic_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.recording_device_type_)
      + sizeof(RecognitionMetadata::_impl_.recording_device_type_)
      - PROTOBUF_FIELD_OFFSET(RecognitionMetadata, _impl_.interaction_type_)>(
          reinterpret_cast<char*>(&_impl_.interaction_type_),
          reinterpret_cast<char*>(&other->_impl_.interaction_type_));
}

::google::protobuf::Metadata RecognitionMetadata::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeechContext::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<SpeechContext>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_._has_bits_);
};

SpeechContext::SpeechContext(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeechContext_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeechContext)
}
PROTOBUF_NDEBUG_INLINE SpeechContext::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::SpeechContext& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        phrases_{visibility, arena, from.phrases_} {}

SpeechContext::SpeechContext(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const SpeechContext& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeechContext_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SpeechContext* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  _impl_.boost_ = from._impl_.boost_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.SpeechContext)
}
PROTOBUF_NDEBUG_INLINE SpeechContext::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        phrases_{visibility, arena} {}

inline void SpeechContext::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.boost_ = {};
}
SpeechContext::~SpeechContext() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeechContext)
  SharedDtor(*this);
}
inline void SpeechContext::SharedDtor(MessageLite& self) {
  SpeechContext& this_ = static_cast<SpeechContext&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL SpeechContext::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) SpeechContext(arena);
}
constexpr auto SpeechContext::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.phrases_) +
          decltype(SpeechContext::_impl_.phrases_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(SpeechContext), alignof(SpeechContext), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&SpeechContext::PlacementNew_,
                                 sizeof(SpeechContext),
                                 alignof(SpeechContext));
  }
}
constexpr auto SpeechContext::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_SpeechContext_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &SpeechContext::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<SpeechContext>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &SpeechContext::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<SpeechContext>(), &SpeechContext::ByteSizeLong,
              &SpeechContext::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_._cached_size_),
          false,
      },
      &SpeechContext::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull SpeechContext_class_data_ =
        SpeechContext::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
SpeechContext::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&SpeechContext_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(SpeechContext_class_data_.tc_table);
  return SpeechContext_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 52, 2>
SpeechContext::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_._has_bits_),
    0, // no _extensions_
    4, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967286,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    SpeechContext_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechContext>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // float boost = 4;
    {::_pbi::TcParser::FastF32S1,
     {37, 0, 0, PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.boost_)}},
    // repeated string phrases = 1;
    {::_pbi::TcParser::FastUR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.phrases_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated string phrases = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.phrases_), -1, 0, (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // float boost = 4;
    {PROTOBUF_FIELD_OFFSET(SpeechContext, _impl_.boost_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kFloat)},
  }},
  // no aux_entries
  {{
    "\44\7\0\0\0\0\0\0"
    "google.cloud.speech.v1.SpeechContext"
    "phrases"
  }},
};
PROTOBUF_NOINLINE void SpeechContext::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeechContext)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.phrases_.Clear();
  _impl_.boost_ = 0;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL SpeechContext::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const SpeechContext& this_ = static_cast<const SpeechContext&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL SpeechContext::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const SpeechContext& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeechContext)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated string phrases = 1;
  for (int i = 0, n = this_._internal_phrases_size(); i < n; ++i) {
    const auto& s = this_._internal_phrases().Get(i);
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
        s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.SpeechContext.phrases");
    target = stream->WriteString(1, s, target);
  }

  // float boost = 4;
  if ((this_._impl_._has_bits_[0] & 0x00000001U) != 0) {
    if (::absl::bit_cast<::uint32_t>(this_._internal_boost()) != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteFloatToArray(
          4, this_._internal_boost(), target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeechContext)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t SpeechContext::ByteSizeLong(const MessageLite& base) {
  const SpeechContext& this_ = static_cast<const SpeechContext&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t SpeechContext::ByteSizeLong() const {
  const SpeechContext& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeechContext)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
   {
    // repeated string phrases = 1;
    {
      total_size +=
          1 * ::google::protobuf::internal::FromIntSize(this_._internal_phrases().size());
      for (int i = 0, n = this_._internal_phrases().size(); i < n; ++i) {
        total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
            this_._internal_phrases().Get(i));
      }
    }
  }
   {
    // float boost = 4;
    cached_has_bits = this_._impl_._has_bits_[0];
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (::absl::bit_cast<::uint32_t>(this_._internal_boost()) != 0) {
        total_size += 5;
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void SpeechContext::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeechContext*>(&to_msg);
  auto& from = static_cast<const SpeechContext&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeechContext)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_phrases()->MergeFrom(from._internal_phrases());
  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000001U) != 0) {
    if (::absl::bit_cast<::uint32_t>(from._internal_boost()) != 0) {
      _this->_impl_.boost_ = from._impl_.boost_;
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechContext::CopyFrom(const SpeechContext& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeechContext)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeechContext::InternalSwap(SpeechContext* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.phrases_.InternalSwap(&other->_impl_.phrases_);
  swap(_impl_.boost_, other->_impl_.boost_);
}

::google::protobuf::Metadata SpeechContext::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RecognitionAudio::_Internal {
 public:
  static constexpr ::int32_t kOneofCaseOffset =
      PROTOBUF_FIELD_OFFSET(::google::cloud::speech::v1::RecognitionAudio, _impl_._oneof_case_);
};

RecognitionAudio::RecognitionAudio(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognitionAudio_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognitionAudio)
}
PROTOBUF_NDEBUG_INLINE RecognitionAudio::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::RecognitionAudio& from_msg)
      : audio_source_{},
        _cached_size_{0},
        _oneof_case_{from._oneof_case_[0]} {}

RecognitionAudio::RecognitionAudio(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const RecognitionAudio& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognitionAudio_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognitionAudio* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  switch (audio_source_case()) {
    case AUDIO_SOURCE_NOT_SET:
      break;
      case kContent:
        new (&_impl_.audio_source_.content_) decltype(_impl_.audio_source_.content_){arena, from._impl_.audio_source_.content_};
        break;
      case kUri:
        new (&_impl_.audio_source_.uri_) decltype(_impl_.audio_source_.uri_){arena, from._impl_.audio_source_.uri_};
        break;
  }

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognitionAudio)
}
PROTOBUF_NDEBUG_INLINE RecognitionAudio::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : audio_source_{},
        _cached_size_{0},
        _oneof_case_{} {}

inline void RecognitionAudio::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
RecognitionAudio::~RecognitionAudio() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognitionAudio)
  SharedDtor(*this);
}
inline void RecognitionAudio::SharedDtor(MessageLite& self) {
  RecognitionAudio& this_ = static_cast<RecognitionAudio&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  if (this_.has_audio_source()) {
    this_.clear_audio_source();
  }
  this_._impl_.~Impl_();
}

void RecognitionAudio::clear_audio_source() {
// @@protoc_insertion_point(one_of_clear_start:google.cloud.speech.v1.RecognitionAudio)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  switch (audio_source_case()) {
    case kContent: {
      _impl_.audio_source_.content_.Destroy();
      break;
    }
    case kUri: {
      _impl_.audio_source_.uri_.Destroy();
      break;
    }
    case AUDIO_SOURCE_NOT_SET: {
      break;
    }
  }
  _impl_._oneof_case_[0] = AUDIO_SOURCE_NOT_SET;
}


inline void* PROTOBUF_NONNULL RecognitionAudio::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) RecognitionAudio(arena);
}
constexpr auto RecognitionAudio::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(RecognitionAudio),
                                            alignof(RecognitionAudio));
}
constexpr auto RecognitionAudio::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_RecognitionAudio_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &RecognitionAudio::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<RecognitionAudio>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &RecognitionAudio::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<RecognitionAudio>(), &RecognitionAudio::ByteSizeLong,
              &RecognitionAudio::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(RecognitionAudio, _impl_._cached_size_),
          false,
      },
      &RecognitionAudio::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull RecognitionAudio_class_data_ =
        RecognitionAudio::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
RecognitionAudio::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&RecognitionAudio_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(RecognitionAudio_class_data_.tc_table);
  return RecognitionAudio_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 2, 0, 51, 2>
RecognitionAudio::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    RecognitionAudio_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognitionAudio>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // bytes content = 1;
    {PROTOBUF_FIELD_OFFSET(RecognitionAudio, _impl_.audio_source_.content_), _Internal::kOneofCaseOffset + 0, 0, (0 | ::_fl::kFcOneof | ::_fl::kBytes | ::_fl::kRepAString)},
    // string uri = 2;
    {PROTOBUF_FIELD_OFFSET(RecognitionAudio, _impl_.audio_source_.uri_), _Internal::kOneofCaseOffset + 0, 0, (0 | ::_fl::kFcOneof | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\47\0\3\0\0\0\0\0"
    "google.cloud.speech.v1.RecognitionAudio"
    "uri"
  }},
};
PROTOBUF_NOINLINE void RecognitionAudio::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognitionAudio)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_audio_source();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL RecognitionAudio::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const RecognitionAudio& this_ = static_cast<const RecognitionAudio&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL RecognitionAudio::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const RecognitionAudio& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognitionAudio)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  switch (this_.audio_source_case()) {
    case kContent: {
      const ::std::string& _s = this_._internal_content();
      target = stream->WriteBytesMaybeAliased(1, _s, target);
      break;
    }
    case kUri: {
      const ::std::string& _s = this_._internal_uri();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.RecognitionAudio.uri");
      target = stream->WriteStringMaybeAliased(2, _s, target);
      break;
    }
    default:
      break;
  }
  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognitionAudio)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t RecognitionAudio::ByteSizeLong(const MessageLite& base) {
  const RecognitionAudio& this_ = static_cast<const RecognitionAudio&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t RecognitionAudio::ByteSizeLong() const {
  const RecognitionAudio& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognitionAudio)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  switch (this_.audio_source_case()) {
    // bytes content = 1;
    case kContent: {
      total_size += 1 + ::google::protobuf::internal::WireFormatLite::BytesSize(
                                      this_._internal_content());
      break;
    }
    // string uri = 2;
    case kUri: {
      total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                      this_._internal_uri());
      break;
    }
    case AUDIO_SOURCE_NOT_SET: {
      break;
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void RecognitionAudio::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognitionAudio*>(&to_msg);
  auto& from = static_cast<const RecognitionAudio&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognitionAudio)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (const uint32_t oneof_from_case = from._impl_._oneof_case_[0]) {
    const uint32_t oneof_to_case = _this->_impl_._oneof_case_[0];
    const bool oneof_needs_init = oneof_to_case != oneof_from_case;
    if (oneof_needs_init) {
      if (oneof_to_case != 0) {
        _this->clear_audio_source();
      }
      _this->_impl_._oneof_case_[0] = oneof_from_case;
    }

    switch (oneof_from_case) {
      case kContent: {
        if (oneof_needs_init) {
          _this->_impl_.audio_source_.content_.InitDefault();
        }
        _this->_impl_.audio_source_.content_.Set(from._internal_content(), arena);
        break;
      }
      case kUri: {
        if (oneof_needs_init) {
          _this->_impl_.audio_source_.uri_.InitDefault();
        }
        _this->_impl_.audio_source_.uri_.Set(from._internal_uri(), arena);
        break;
      }
      case AUDIO_SOURCE_NOT_SET:
        break;
    }
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognitionAudio::CopyFrom(const RecognitionAudio& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognitionAudio)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognitionAudio::InternalSwap(RecognitionAudio* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_.audio_source_, other->_impl_.audio_source_);
  swap(_impl_._oneof_case_[0], other->_impl_._oneof_case_[0]);
}

::google::protobuf::Metadata RecognitionAudio::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RecognizeResponse::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<RecognizeResponse>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_._has_bits_);
};

void RecognizeResponse::clear_total_billed_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.total_billed_time_ != nullptr) _impl_.total_billed_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001U;
}
RecognizeResponse::RecognizeResponse(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognizeResponse_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.RecognizeResponse)
}
PROTOBUF_NDEBUG_INLINE RecognizeResponse::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::RecognizeResponse& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        results_{visibility, arena, from.results_} {}

RecognizeResponse::RecognizeResponse(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const RecognizeResponse& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, RecognizeResponse_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RecognizeResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.total_billed_time_ = ((cached_has_bits & 0x00000001U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.total_billed_time_)
                : nullptr;
  _impl_.speech_adaptation_info_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_adaptation_info_)
                : nullptr;
  _impl_.request_id_ = from._impl_.request_id_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.RecognizeResponse)
}
PROTOBUF_NDEBUG_INLINE RecognizeResponse::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        results_{visibility, arena} {}

inline void RecognizeResponse::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, total_billed_time_),
           0,
           offsetof(Impl_, request_id_) -
               offsetof(Impl_, total_billed_time_) +
               sizeof(Impl_::request_id_));
}
RecognizeResponse::~RecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.RecognizeResponse)
  SharedDtor(*this);
}
inline void RecognizeResponse::SharedDtor(MessageLite& self) {
  RecognizeResponse& this_ = static_cast<RecognizeResponse&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.total_billed_time_;
  delete this_._impl_.speech_adaptation_info_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL RecognizeResponse::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) RecognizeResponse(arena);
}
constexpr auto RecognizeResponse::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.results_) +
          decltype(RecognizeResponse::_impl_.results_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(RecognizeResponse), alignof(RecognizeResponse), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&RecognizeResponse::PlacementNew_,
                                 sizeof(RecognizeResponse),
                                 alignof(RecognizeResponse));
  }
}
constexpr auto RecognizeResponse::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_RecognizeResponse_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &RecognizeResponse::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<RecognizeResponse>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &RecognizeResponse::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<RecognizeResponse>(), &RecognizeResponse::ByteSizeLong,
              &RecognizeResponse::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_._cached_size_),
          false,
      },
      &RecognizeResponse::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull RecognizeResponse_class_data_ =
        RecognizeResponse::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
RecognizeResponse::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&RecognizeResponse_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(RecognizeResponse_class_data_.tc_table);
  return RecognizeResponse_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 4, 3, 0, 2>
RecognizeResponse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_._has_bits_),
    0, // no _extensions_
    8, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967097,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    3,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    RecognizeResponse_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::RecognizeResponse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // int64 request_id = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(RecognizeResponse, _impl_.request_id_), 2>(),
     {64, 2, 0, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.request_id_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {::_pbi::TcParser::FastMtR1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.results_)}},
    // .google.protobuf.Duration total_billed_time = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 0, 1, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.total_billed_time_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 7;
    {::_pbi::TcParser::FastMtS1,
     {58, 1, 2, PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.speech_adaptation_info_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.results_), -1, 0, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration total_billed_time = 3;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.total_billed_time_), _Internal::kHasBitsOffset + 0, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 7;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.speech_adaptation_info_), _Internal::kHasBitsOffset + 1, 2, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 request_id = 8;
    {PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.request_id_), _Internal::kHasBitsOffset + 2, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt64)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionResult>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptationInfo>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void RecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.RecognizeResponse)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.results_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(_impl_.total_billed_time_ != nullptr);
      _impl_.total_billed_time_->Clear();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.speech_adaptation_info_ != nullptr);
      _impl_.speech_adaptation_info_->Clear();
    }
  }
  _impl_.request_id_ = ::int64_t{0};
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL RecognizeResponse::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const RecognizeResponse& this_ = static_cast<const RecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL RecognizeResponse::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const RecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.RecognizeResponse)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
  for (unsigned i = 0, n = static_cast<unsigned>(
                           this_._internal_results_size());
       i < n; i++) {
    const auto& repfield = this_._internal_results().Get(i);
    target =
        ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
            2, repfield, repfield.GetCachedSize(),
            target, stream);
  }

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.protobuf.Duration total_billed_time = 3;
  if ((cached_has_bits & 0x00000001U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        3, *this_._impl_.total_billed_time_, this_._impl_.total_billed_time_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 7;
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        7, *this_._impl_.speech_adaptation_info_, this_._impl_.speech_adaptation_info_->GetCachedSize(), target,
        stream);
  }

  // int64 request_id = 8;
  if ((cached_has_bits & 0x00000004U) != 0) {
    if (this_._internal_request_id() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt64ToArrayWithField<8>(
              stream, this_._internal_request_id(), target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.RecognizeResponse)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t RecognizeResponse::ByteSizeLong(const MessageLite& base) {
  const RecognizeResponse& this_ = static_cast<const RecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t RecognizeResponse::ByteSizeLong() const {
  const RecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.RecognizeResponse)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
   {
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {
      total_size += 1UL * this_._internal_results_size();
      for (const auto& msg : this_._internal_results()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
  }
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    // .google.protobuf.Duration total_billed_time = 3;
    if ((cached_has_bits & 0x00000001U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.total_billed_time_);
    }
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 7;
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_adaptation_info_);
    }
    // int64 request_id = 8;
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (this_._internal_request_id() != 0) {
        total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
            this_._internal_request_id());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void RecognizeResponse::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RecognizeResponse*>(&to_msg);
  auto& from = static_cast<const RecognizeResponse&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.RecognizeResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_results()->MergeFrom(
      from._internal_results());
  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(from._impl_.total_billed_time_ != nullptr);
      if (_this->_impl_.total_billed_time_ == nullptr) {
        _this->_impl_.total_billed_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.total_billed_time_);
      } else {
        _this->_impl_.total_billed_time_->MergeFrom(*from._impl_.total_billed_time_);
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.speech_adaptation_info_ != nullptr);
      if (_this->_impl_.speech_adaptation_info_ == nullptr) {
        _this->_impl_.speech_adaptation_info_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_adaptation_info_);
      } else {
        _this->_impl_.speech_adaptation_info_->MergeFrom(*from._impl_.speech_adaptation_info_);
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (from._internal_request_id() != 0) {
        _this->_impl_.request_id_ = from._impl_.request_id_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RecognizeResponse::CopyFrom(const RecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.RecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RecognizeResponse::InternalSwap(RecognizeResponse* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.results_.InternalSwap(&other->_impl_.results_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.request_id_)
      + sizeof(RecognizeResponse::_impl_.request_id_)
      - PROTOBUF_FIELD_OFFSET(RecognizeResponse, _impl_.total_billed_time_)>(
          reinterpret_cast<char*>(&_impl_.total_billed_time_),
          reinterpret_cast<char*>(&other->_impl_.total_billed_time_));
}

::google::protobuf::Metadata RecognizeResponse::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class LongRunningRecognizeResponse::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<LongRunningRecognizeResponse>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_._has_bits_);
};

void LongRunningRecognizeResponse::clear_total_billed_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.total_billed_time_ != nullptr) _impl_.total_billed_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001U;
}
void LongRunningRecognizeResponse::clear_output_error() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.output_error_ != nullptr) _impl_.output_error_->Clear();
  _impl_._has_bits_[0] &= ~0x00000004U;
}
LongRunningRecognizeResponse::LongRunningRecognizeResponse(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, LongRunningRecognizeResponse_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.LongRunningRecognizeResponse)
}
PROTOBUF_NDEBUG_INLINE LongRunningRecognizeResponse::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::LongRunningRecognizeResponse& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        results_{visibility, arena, from.results_} {}

LongRunningRecognizeResponse::LongRunningRecognizeResponse(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const LongRunningRecognizeResponse& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, LongRunningRecognizeResponse_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  LongRunningRecognizeResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.total_billed_time_ = ((cached_has_bits & 0x00000001U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.total_billed_time_)
                : nullptr;
  _impl_.output_config_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.output_config_)
                : nullptr;
  _impl_.output_error_ = ((cached_has_bits & 0x00000004U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.output_error_)
                : nullptr;
  _impl_.speech_adaptation_info_ = ((cached_has_bits & 0x00000008U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_adaptation_info_)
                : nullptr;
  _impl_.request_id_ = from._impl_.request_id_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.LongRunningRecognizeResponse)
}
PROTOBUF_NDEBUG_INLINE LongRunningRecognizeResponse::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        results_{visibility, arena} {}

inline void LongRunningRecognizeResponse::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, total_billed_time_),
           0,
           offsetof(Impl_, request_id_) -
               offsetof(Impl_, total_billed_time_) +
               sizeof(Impl_::request_id_));
}
LongRunningRecognizeResponse::~LongRunningRecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.LongRunningRecognizeResponse)
  SharedDtor(*this);
}
inline void LongRunningRecognizeResponse::SharedDtor(MessageLite& self) {
  LongRunningRecognizeResponse& this_ = static_cast<LongRunningRecognizeResponse&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.total_billed_time_;
  delete this_._impl_.output_config_;
  delete this_._impl_.output_error_;
  delete this_._impl_.speech_adaptation_info_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL LongRunningRecognizeResponse::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) LongRunningRecognizeResponse(arena);
}
constexpr auto LongRunningRecognizeResponse::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.results_) +
          decltype(LongRunningRecognizeResponse::_impl_.results_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(LongRunningRecognizeResponse), alignof(LongRunningRecognizeResponse), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&LongRunningRecognizeResponse::PlacementNew_,
                                 sizeof(LongRunningRecognizeResponse),
                                 alignof(LongRunningRecognizeResponse));
  }
}
constexpr auto LongRunningRecognizeResponse::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_LongRunningRecognizeResponse_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &LongRunningRecognizeResponse::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<LongRunningRecognizeResponse>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &LongRunningRecognizeResponse::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<LongRunningRecognizeResponse>(), &LongRunningRecognizeResponse::ByteSizeLong,
              &LongRunningRecognizeResponse::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_._cached_size_),
          false,
      },
      &LongRunningRecognizeResponse::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull LongRunningRecognizeResponse_class_data_ =
        LongRunningRecognizeResponse::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
LongRunningRecognizeResponse::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&LongRunningRecognizeResponse_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(LongRunningRecognizeResponse_class_data_.tc_table);
  return LongRunningRecognizeResponse_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 5, 0, 2>
LongRunningRecognizeResponse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_._has_bits_),
    0, // no _extensions_
    9, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294966809,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    5,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    LongRunningRecognizeResponse_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::LongRunningRecognizeResponse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 8;
    {::_pbi::TcParser::FastMtS1,
     {66, 3, 4, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.speech_adaptation_info_)}},
    // int64 request_id = 9;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(LongRunningRecognizeResponse, _impl_.request_id_), 4>(),
     {72, 4, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.request_id_)}},
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {::_pbi::TcParser::FastMtR1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.results_)}},
    // .google.protobuf.Duration total_billed_time = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 0, 1, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.total_billed_time_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 6;
    {::_pbi::TcParser::FastMtS1,
     {50, 1, 2, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.output_config_)}},
    // .google.rpc.Status output_error = 7;
    {::_pbi::TcParser::FastMtS1,
     {58, 2, 3, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.output_error_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.results_), -1, 0, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration total_billed_time = 3;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.total_billed_time_), _Internal::kHasBitsOffset + 0, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 6;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.output_config_), _Internal::kHasBitsOffset + 1, 2, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.rpc.Status output_error = 7;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.output_error_), _Internal::kHasBitsOffset + 2, 3, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 8;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.speech_adaptation_info_), _Internal::kHasBitsOffset + 3, 4, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 request_id = 9;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.request_id_), _Internal::kHasBitsOffset + 4, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt64)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionResult>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::TranscriptOutputConfig>()},
      {::_pbi::TcParser::GetTable<::google::rpc::Status>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptationInfo>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void LongRunningRecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.results_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000000fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(_impl_.total_billed_time_ != nullptr);
      _impl_.total_billed_time_->Clear();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.output_config_ != nullptr);
      _impl_.output_config_->Clear();
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(_impl_.output_error_ != nullptr);
      _impl_.output_error_->Clear();
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      ABSL_DCHECK(_impl_.speech_adaptation_info_ != nullptr);
      _impl_.speech_adaptation_info_->Clear();
    }
  }
  _impl_.request_id_ = ::int64_t{0};
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL LongRunningRecognizeResponse::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const LongRunningRecognizeResponse& this_ = static_cast<const LongRunningRecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL LongRunningRecognizeResponse::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const LongRunningRecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
  for (unsigned i = 0, n = static_cast<unsigned>(
                           this_._internal_results_size());
       i < n; i++) {
    const auto& repfield = this_._internal_results().Get(i);
    target =
        ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
            2, repfield, repfield.GetCachedSize(),
            target, stream);
  }

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.protobuf.Duration total_billed_time = 3;
  if ((cached_has_bits & 0x00000001U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        3, *this_._impl_.total_billed_time_, this_._impl_.total_billed_time_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 6;
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        6, *this_._impl_.output_config_, this_._impl_.output_config_->GetCachedSize(), target,
        stream);
  }

  // .google.rpc.Status output_error = 7;
  if ((cached_has_bits & 0x00000004U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        7, *this_._impl_.output_error_, this_._impl_.output_error_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 8;
  if ((cached_has_bits & 0x00000008U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        8, *this_._impl_.speech_adaptation_info_, this_._impl_.speech_adaptation_info_->GetCachedSize(), target,
        stream);
  }

  // int64 request_id = 9;
  if ((cached_has_bits & 0x00000010U) != 0) {
    if (this_._internal_request_id() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt64ToArrayWithField<9>(
              stream, this_._internal_request_id(), target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.LongRunningRecognizeResponse)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t LongRunningRecognizeResponse::ByteSizeLong(const MessageLite& base) {
  const LongRunningRecognizeResponse& this_ = static_cast<const LongRunningRecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t LongRunningRecognizeResponse::ByteSizeLong() const {
  const LongRunningRecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
   {
    // repeated .google.cloud.speech.v1.SpeechRecognitionResult results = 2;
    {
      total_size += 1UL * this_._internal_results_size();
      for (const auto& msg : this_._internal_results()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
  }
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000001fU) != 0) {
    // .google.protobuf.Duration total_billed_time = 3;
    if ((cached_has_bits & 0x00000001U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.total_billed_time_);
    }
    // .google.cloud.speech.v1.TranscriptOutputConfig output_config = 6;
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.output_config_);
    }
    // .google.rpc.Status output_error = 7;
    if ((cached_has_bits & 0x00000004U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.output_error_);
    }
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 8;
    if ((cached_has_bits & 0x00000008U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_adaptation_info_);
    }
    // int64 request_id = 9;
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (this_._internal_request_id() != 0) {
        total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
            this_._internal_request_id());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void LongRunningRecognizeResponse::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<LongRunningRecognizeResponse*>(&to_msg);
  auto& from = static_cast<const LongRunningRecognizeResponse&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_results()->MergeFrom(
      from._internal_results());
  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000001fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(from._impl_.total_billed_time_ != nullptr);
      if (_this->_impl_.total_billed_time_ == nullptr) {
        _this->_impl_.total_billed_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.total_billed_time_);
      } else {
        _this->_impl_.total_billed_time_->MergeFrom(*from._impl_.total_billed_time_);
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.output_config_ != nullptr);
      if (_this->_impl_.output_config_ == nullptr) {
        _this->_impl_.output_config_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.output_config_);
      } else {
        _this->_impl_.output_config_->MergeFrom(*from._impl_.output_config_);
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(from._impl_.output_error_ != nullptr);
      if (_this->_impl_.output_error_ == nullptr) {
        _this->_impl_.output_error_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.output_error_);
      } else {
        _this->_impl_.output_error_->MergeFrom(*from._impl_.output_error_);
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      ABSL_DCHECK(from._impl_.speech_adaptation_info_ != nullptr);
      if (_this->_impl_.speech_adaptation_info_ == nullptr) {
        _this->_impl_.speech_adaptation_info_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_adaptation_info_);
      } else {
        _this->_impl_.speech_adaptation_info_->MergeFrom(*from._impl_.speech_adaptation_info_);
      }
    }
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (from._internal_request_id() != 0) {
        _this->_impl_.request_id_ = from._impl_.request_id_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void LongRunningRecognizeResponse::CopyFrom(const LongRunningRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.LongRunningRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void LongRunningRecognizeResponse::InternalSwap(LongRunningRecognizeResponse* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.results_.InternalSwap(&other->_impl_.results_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.request_id_)
      + sizeof(LongRunningRecognizeResponse::_impl_.request_id_)
      - PROTOBUF_FIELD_OFFSET(LongRunningRecognizeResponse, _impl_.total_billed_time_)>(
          reinterpret_cast<char*>(&_impl_.total_billed_time_),
          reinterpret_cast<char*>(&other->_impl_.total_billed_time_));
}

::google::protobuf::Metadata LongRunningRecognizeResponse::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class LongRunningRecognizeMetadata::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<LongRunningRecognizeMetadata>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_._has_bits_);
};

void LongRunningRecognizeMetadata::clear_start_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.start_time_ != nullptr) _impl_.start_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002U;
}
void LongRunningRecognizeMetadata::clear_last_update_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.last_update_time_ != nullptr) _impl_.last_update_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000004U;
}
LongRunningRecognizeMetadata::LongRunningRecognizeMetadata(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, LongRunningRecognizeMetadata_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.LongRunningRecognizeMetadata)
}
PROTOBUF_NDEBUG_INLINE LongRunningRecognizeMetadata::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::LongRunningRecognizeMetadata& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        uri_(arena, from.uri_) {}

LongRunningRecognizeMetadata::LongRunningRecognizeMetadata(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const LongRunningRecognizeMetadata& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, LongRunningRecognizeMetadata_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  LongRunningRecognizeMetadata* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.start_time_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.start_time_)
                : nullptr;
  _impl_.last_update_time_ = ((cached_has_bits & 0x00000004U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.last_update_time_)
                : nullptr;
  _impl_.progress_percent_ = from._impl_.progress_percent_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.LongRunningRecognizeMetadata)
}
PROTOBUF_NDEBUG_INLINE LongRunningRecognizeMetadata::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        uri_(arena) {}

inline void LongRunningRecognizeMetadata::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, start_time_),
           0,
           offsetof(Impl_, progress_percent_) -
               offsetof(Impl_, start_time_) +
               sizeof(Impl_::progress_percent_));
}
LongRunningRecognizeMetadata::~LongRunningRecognizeMetadata() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  SharedDtor(*this);
}
inline void LongRunningRecognizeMetadata::SharedDtor(MessageLite& self) {
  LongRunningRecognizeMetadata& this_ = static_cast<LongRunningRecognizeMetadata&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.uri_.Destroy();
  delete this_._impl_.start_time_;
  delete this_._impl_.last_update_time_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL LongRunningRecognizeMetadata::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) LongRunningRecognizeMetadata(arena);
}
constexpr auto LongRunningRecognizeMetadata::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(LongRunningRecognizeMetadata),
                                            alignof(LongRunningRecognizeMetadata));
}
constexpr auto LongRunningRecognizeMetadata::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_LongRunningRecognizeMetadata_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &LongRunningRecognizeMetadata::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<LongRunningRecognizeMetadata>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &LongRunningRecognizeMetadata::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<LongRunningRecognizeMetadata>(), &LongRunningRecognizeMetadata::ByteSizeLong,
              &LongRunningRecognizeMetadata::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_._cached_size_),
          false,
      },
      &LongRunningRecognizeMetadata::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull LongRunningRecognizeMetadata_class_data_ =
        LongRunningRecognizeMetadata::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
LongRunningRecognizeMetadata::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&LongRunningRecognizeMetadata_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(LongRunningRecognizeMetadata_class_data_.tc_table);
  return LongRunningRecognizeMetadata_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 4, 2, 63, 2>
LongRunningRecognizeMetadata::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_._has_bits_),
    0, // no _extensions_
    4, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967280,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    LongRunningRecognizeMetadata_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::LongRunningRecognizeMetadata>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string uri = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::FastUS1,
     {34, 0, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.uri_)}},
    // int32 progress_percent = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(LongRunningRecognizeMetadata, _impl_.progress_percent_), 3>(),
     {8, 3, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.progress_percent_)}},
    // .google.protobuf.Timestamp start_time = 2;
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 0, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.start_time_)}},
    // .google.protobuf.Timestamp last_update_time = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 2, 1, PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.last_update_time_)}},
  }}, {{
    65535, 65535
  }}, {{
    // int32 progress_percent = 1;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.progress_percent_), _Internal::kHasBitsOffset + 3, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // .google.protobuf.Timestamp start_time = 2;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.start_time_), _Internal::kHasBitsOffset + 1, 0, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Timestamp last_update_time = 3;
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.last_update_time_), _Internal::kHasBitsOffset + 2, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // string uri = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.uri_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::protobuf::Timestamp>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Timestamp>()},
  }},
  {{
    "\63\0\0\0\3\0\0\0"
    "google.cloud.speech.v1.LongRunningRecognizeMetadata"
    "uri"
  }},
};
PROTOBUF_NOINLINE void LongRunningRecognizeMetadata::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      _impl_.uri_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.start_time_ != nullptr);
      _impl_.start_time_->Clear();
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(_impl_.last_update_time_ != nullptr);
      _impl_.last_update_time_->Clear();
    }
  }
  _impl_.progress_percent_ = 0;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL LongRunningRecognizeMetadata::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const LongRunningRecognizeMetadata& this_ = static_cast<const LongRunningRecognizeMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL LongRunningRecognizeMetadata::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const LongRunningRecognizeMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // int32 progress_percent = 1;
  if ((this_._impl_._has_bits_[0] & 0x00000008U) != 0) {
    if (this_._internal_progress_percent() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<1>(
              stream, this_._internal_progress_percent(), target);
    }
  }

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.protobuf.Timestamp start_time = 2;
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        2, *this_._impl_.start_time_, this_._impl_.start_time_->GetCachedSize(), target,
        stream);
  }

  // .google.protobuf.Timestamp last_update_time = 3;
  if ((cached_has_bits & 0x00000004U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        3, *this_._impl_.last_update_time_, this_._impl_.last_update_time_->GetCachedSize(), target,
        stream);
  }

  // string uri = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
  if ((cached_has_bits & 0x00000001U) != 0) {
    if (!this_._internal_uri().empty()) {
      const ::std::string& _s = this_._internal_uri();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.LongRunningRecognizeMetadata.uri");
      target = stream->WriteStringMaybeAliased(4, _s, target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t LongRunningRecognizeMetadata::ByteSizeLong(const MessageLite& base) {
  const LongRunningRecognizeMetadata& this_ = static_cast<const LongRunningRecognizeMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t LongRunningRecognizeMetadata::ByteSizeLong() const {
  const LongRunningRecognizeMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000000fU) != 0) {
    // string uri = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!this_._internal_uri().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_uri());
      }
    }
    // .google.protobuf.Timestamp start_time = 2;
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.start_time_);
    }
    // .google.protobuf.Timestamp last_update_time = 3;
    if ((cached_has_bits & 0x00000004U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.last_update_time_);
    }
    // int32 progress_percent = 1;
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (this_._internal_progress_percent() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_progress_percent());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void LongRunningRecognizeMetadata::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<LongRunningRecognizeMetadata*>(&to_msg);
  auto& from = static_cast<const LongRunningRecognizeMetadata&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000000fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!from._internal_uri().empty()) {
        _this->_internal_set_uri(from._internal_uri());
      } else {
        if (_this->_impl_.uri_.IsDefault()) {
          _this->_internal_set_uri("");
        }
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.start_time_ != nullptr);
      if (_this->_impl_.start_time_ == nullptr) {
        _this->_impl_.start_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.start_time_);
      } else {
        _this->_impl_.start_time_->MergeFrom(*from._impl_.start_time_);
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(from._impl_.last_update_time_ != nullptr);
      if (_this->_impl_.last_update_time_ == nullptr) {
        _this->_impl_.last_update_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.last_update_time_);
      } else {
        _this->_impl_.last_update_time_->MergeFrom(*from._impl_.last_update_time_);
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (from._internal_progress_percent() != 0) {
        _this->_impl_.progress_percent_ = from._impl_.progress_percent_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void LongRunningRecognizeMetadata::CopyFrom(const LongRunningRecognizeMetadata& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.LongRunningRecognizeMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void LongRunningRecognizeMetadata::InternalSwap(LongRunningRecognizeMetadata* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.uri_, &other->_impl_.uri_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.progress_percent_)
      + sizeof(LongRunningRecognizeMetadata::_impl_.progress_percent_)
      - PROTOBUF_FIELD_OFFSET(LongRunningRecognizeMetadata, _impl_.start_time_)>(
          reinterpret_cast<char*>(&_impl_.start_time_),
          reinterpret_cast<char*>(&other->_impl_.start_time_));
}

::google::protobuf::Metadata LongRunningRecognizeMetadata::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognizeResponse::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<StreamingRecognizeResponse>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_._has_bits_);
};

void StreamingRecognizeResponse::clear_error() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.error_ != nullptr) _impl_.error_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001U;
}
void StreamingRecognizeResponse::clear_speech_event_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.speech_event_time_ != nullptr) _impl_.speech_event_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000004U;
}
void StreamingRecognizeResponse::clear_total_billed_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.total_billed_time_ != nullptr) _impl_.total_billed_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002U;
}
StreamingRecognizeResponse::StreamingRecognizeResponse(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognizeResponse_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognizeResponse)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognizeResponse::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::StreamingRecognizeResponse& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        results_{visibility, arena, from.results_} {}

StreamingRecognizeResponse::StreamingRecognizeResponse(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const StreamingRecognizeResponse& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognizeResponse_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognizeResponse* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.error_ = ((cached_has_bits & 0x00000001U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.error_)
                : nullptr;
  _impl_.total_billed_time_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.total_billed_time_)
                : nullptr;
  _impl_.speech_event_time_ = ((cached_has_bits & 0x00000004U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_event_time_)
                : nullptr;
  _impl_.speech_adaptation_info_ = ((cached_has_bits & 0x00000008U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_adaptation_info_)
                : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, request_id_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, request_id_),
           offsetof(Impl_, speech_event_type_) -
               offsetof(Impl_, request_id_) +
               sizeof(Impl_::speech_event_type_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognizeResponse)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognizeResponse::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        results_{visibility, arena} {}

inline void StreamingRecognizeResponse::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, error_),
           0,
           offsetof(Impl_, speech_event_type_) -
               offsetof(Impl_, error_) +
               sizeof(Impl_::speech_event_type_));
}
StreamingRecognizeResponse::~StreamingRecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognizeResponse)
  SharedDtor(*this);
}
inline void StreamingRecognizeResponse::SharedDtor(MessageLite& self) {
  StreamingRecognizeResponse& this_ = static_cast<StreamingRecognizeResponse&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.error_;
  delete this_._impl_.total_billed_time_;
  delete this_._impl_.speech_event_time_;
  delete this_._impl_.speech_adaptation_info_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL StreamingRecognizeResponse::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) StreamingRecognizeResponse(arena);
}
constexpr auto StreamingRecognizeResponse::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.results_) +
          decltype(StreamingRecognizeResponse::_impl_.results_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(StreamingRecognizeResponse), alignof(StreamingRecognizeResponse), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&StreamingRecognizeResponse::PlacementNew_,
                                 sizeof(StreamingRecognizeResponse),
                                 alignof(StreamingRecognizeResponse));
  }
}
constexpr auto StreamingRecognizeResponse::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_StreamingRecognizeResponse_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &StreamingRecognizeResponse::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<StreamingRecognizeResponse>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &StreamingRecognizeResponse::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<StreamingRecognizeResponse>(), &StreamingRecognizeResponse::ByteSizeLong,
              &StreamingRecognizeResponse::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_._cached_size_),
          false,
      },
      &StreamingRecognizeResponse::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull StreamingRecognizeResponse_class_data_ =
        StreamingRecognizeResponse::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
StreamingRecognizeResponse::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&StreamingRecognizeResponse_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(StreamingRecognizeResponse_class_data_.tc_table);
  return StreamingRecognizeResponse_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 7, 5, 0, 2>
StreamingRecognizeResponse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_._has_bits_),
    0, // no _extensions_
    10, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294966372,  // skipmap
    offsetof(decltype(_table_), field_entries),
    7,  // num_field_entries
    5,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    StreamingRecognizeResponse_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognizeResponse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .google.protobuf.Duration speech_event_time = 8;
    {::_pbi::TcParser::FastMtS1,
     {66, 2, 3, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_time_)}},
    // .google.rpc.Status error = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.error_)}},
    // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;
    {::_pbi::TcParser::FastMtR1,
     {18, 63, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.results_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(StreamingRecognizeResponse, _impl_.speech_event_type_), 5>(),
     {32, 5, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_type_)}},
    // .google.protobuf.Duration total_billed_time = 5;
    {::_pbi::TcParser::FastMtS1,
     {42, 1, 2, PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.total_billed_time_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.rpc.Status error = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.error_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.results_), -1, 1, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_type_), _Internal::kHasBitsOffset + 5, 0, (0 | ::_fl::kFcOptional | ::_fl::kOpenEnum)},
    // .google.protobuf.Duration total_billed_time = 5;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.total_billed_time_), _Internal::kHasBitsOffset + 1, 2, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration speech_event_time = 8;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_time_), _Internal::kHasBitsOffset + 2, 3, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 9;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_adaptation_info_), _Internal::kHasBitsOffset + 3, 4, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 request_id = 10;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.request_id_), _Internal::kHasBitsOffset + 4, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt64)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::rpc::Status>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionResult>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptationInfo>()},
  }},
  {{
  }},
};
PROTOBUF_NOINLINE void StreamingRecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognizeResponse)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.results_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000000fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(_impl_.error_ != nullptr);
      _impl_.error_->Clear();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.total_billed_time_ != nullptr);
      _impl_.total_billed_time_->Clear();
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(_impl_.speech_event_time_ != nullptr);
      _impl_.speech_event_time_->Clear();
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      ABSL_DCHECK(_impl_.speech_adaptation_info_ != nullptr);
      _impl_.speech_adaptation_info_->Clear();
    }
  }
  if ((cached_has_bits & 0x00000030U) != 0) {
    ::memset(&_impl_.request_id_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.speech_event_type_) -
        reinterpret_cast<char*>(&_impl_.request_id_)) + sizeof(_impl_.speech_event_type_));
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL StreamingRecognizeResponse::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const StreamingRecognizeResponse& this_ = static_cast<const StreamingRecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL StreamingRecognizeResponse::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const StreamingRecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognizeResponse)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.rpc.Status error = 1;
  if ((cached_has_bits & 0x00000001U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        1, *this_._impl_.error_, this_._impl_.error_->GetCachedSize(), target,
        stream);
  }

  // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;
  for (unsigned i = 0, n = static_cast<unsigned>(
                           this_._internal_results_size());
       i < n; i++) {
    const auto& repfield = this_._internal_results().Get(i);
    target =
        ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
            2, repfield, repfield.GetCachedSize(),
            target, stream);
  }

  // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;
  if ((cached_has_bits & 0x00000020U) != 0) {
    if (this_._internal_speech_event_type() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteEnumToArray(
          4, this_._internal_speech_event_type(), target);
    }
  }

  // .google.protobuf.Duration total_billed_time = 5;
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        5, *this_._impl_.total_billed_time_, this_._impl_.total_billed_time_->GetCachedSize(), target,
        stream);
  }

  // .google.protobuf.Duration speech_event_time = 8;
  if ((cached_has_bits & 0x00000004U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        8, *this_._impl_.speech_event_time_, this_._impl_.speech_event_time_->GetCachedSize(), target,
        stream);
  }

  // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 9;
  if ((cached_has_bits & 0x00000008U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        9, *this_._impl_.speech_adaptation_info_, this_._impl_.speech_adaptation_info_->GetCachedSize(), target,
        stream);
  }

  // int64 request_id = 10;
  if ((cached_has_bits & 0x00000010U) != 0) {
    if (this_._internal_request_id() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt64ToArrayWithField<10>(
              stream, this_._internal_request_id(), target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognizeResponse)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t StreamingRecognizeResponse::ByteSizeLong(const MessageLite& base) {
  const StreamingRecognizeResponse& this_ = static_cast<const StreamingRecognizeResponse&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t StreamingRecognizeResponse::ByteSizeLong() const {
  const StreamingRecognizeResponse& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognizeResponse)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
   {
    // repeated .google.cloud.speech.v1.StreamingRecognitionResult results = 2;
    {
      total_size += 1UL * this_._internal_results_size();
      for (const auto& msg : this_._internal_results()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
  }
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000003fU) != 0) {
    // .google.rpc.Status error = 1;
    if ((cached_has_bits & 0x00000001U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.error_);
    }
    // .google.protobuf.Duration total_billed_time = 5;
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.total_billed_time_);
    }
    // .google.protobuf.Duration speech_event_time = 8;
    if ((cached_has_bits & 0x00000004U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_event_time_);
    }
    // .google.cloud.speech.v1.SpeechAdaptationInfo speech_adaptation_info = 9;
    if ((cached_has_bits & 0x00000008U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.speech_adaptation_info_);
    }
    // int64 request_id = 10;
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (this_._internal_request_id() != 0) {
        total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
            this_._internal_request_id());
      }
    }
    // .google.cloud.speech.v1.StreamingRecognizeResponse.SpeechEventType speech_event_type = 4;
    if ((cached_has_bits & 0x00000020U) != 0) {
      if (this_._internal_speech_event_type() != 0) {
        total_size += 1 +
                      ::_pbi::WireFormatLite::EnumSize(this_._internal_speech_event_type());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void StreamingRecognizeResponse::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognizeResponse*>(&to_msg);
  auto& from = static_cast<const StreamingRecognizeResponse&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognizeResponse)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_results()->MergeFrom(
      from._internal_results());
  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000003fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      ABSL_DCHECK(from._impl_.error_ != nullptr);
      if (_this->_impl_.error_ == nullptr) {
        _this->_impl_.error_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.error_);
      } else {
        _this->_impl_.error_->MergeFrom(*from._impl_.error_);
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.total_billed_time_ != nullptr);
      if (_this->_impl_.total_billed_time_ == nullptr) {
        _this->_impl_.total_billed_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.total_billed_time_);
      } else {
        _this->_impl_.total_billed_time_->MergeFrom(*from._impl_.total_billed_time_);
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(from._impl_.speech_event_time_ != nullptr);
      if (_this->_impl_.speech_event_time_ == nullptr) {
        _this->_impl_.speech_event_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_event_time_);
      } else {
        _this->_impl_.speech_event_time_->MergeFrom(*from._impl_.speech_event_time_);
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      ABSL_DCHECK(from._impl_.speech_adaptation_info_ != nullptr);
      if (_this->_impl_.speech_adaptation_info_ == nullptr) {
        _this->_impl_.speech_adaptation_info_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.speech_adaptation_info_);
      } else {
        _this->_impl_.speech_adaptation_info_->MergeFrom(*from._impl_.speech_adaptation_info_);
      }
    }
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (from._internal_request_id() != 0) {
        _this->_impl_.request_id_ = from._impl_.request_id_;
      }
    }
    if ((cached_has_bits & 0x00000020U) != 0) {
      if (from._internal_speech_event_type() != 0) {
        _this->_impl_.speech_event_type_ = from._impl_.speech_event_type_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognizeResponse::CopyFrom(const StreamingRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognizeResponse::InternalSwap(StreamingRecognizeResponse* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.results_.InternalSwap(&other->_impl_.results_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.speech_event_type_)
      + sizeof(StreamingRecognizeResponse::_impl_.speech_event_type_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognizeResponse, _impl_.error_)>(
          reinterpret_cast<char*>(&_impl_.error_),
          reinterpret_cast<char*>(&other->_impl_.error_));
}

::google::protobuf::Metadata StreamingRecognizeResponse::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StreamingRecognitionResult::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<StreamingRecognitionResult>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_._has_bits_);
};

void StreamingRecognitionResult::clear_result_end_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.result_end_time_ != nullptr) _impl_.result_end_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002U;
}
StreamingRecognitionResult::StreamingRecognitionResult(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognitionResult_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.StreamingRecognitionResult)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognitionResult::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::StreamingRecognitionResult& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        alternatives_{visibility, arena, from.alternatives_},
        language_code_(arena, from.language_code_) {}

StreamingRecognitionResult::StreamingRecognitionResult(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const StreamingRecognitionResult& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, StreamingRecognitionResult_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StreamingRecognitionResult* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.result_end_time_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.result_end_time_)
                : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, is_final_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, is_final_),
           offsetof(Impl_, channel_tag_) -
               offsetof(Impl_, is_final_) +
               sizeof(Impl_::channel_tag_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.StreamingRecognitionResult)
}
PROTOBUF_NDEBUG_INLINE StreamingRecognitionResult::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        alternatives_{visibility, arena},
        language_code_(arena) {}

inline void StreamingRecognitionResult::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, result_end_time_),
           0,
           offsetof(Impl_, channel_tag_) -
               offsetof(Impl_, result_end_time_) +
               sizeof(Impl_::channel_tag_));
}
StreamingRecognitionResult::~StreamingRecognitionResult() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.StreamingRecognitionResult)
  SharedDtor(*this);
}
inline void StreamingRecognitionResult::SharedDtor(MessageLite& self) {
  StreamingRecognitionResult& this_ = static_cast<StreamingRecognitionResult&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.language_code_.Destroy();
  delete this_._impl_.result_end_time_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL StreamingRecognitionResult::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) StreamingRecognitionResult(arena);
}
constexpr auto StreamingRecognitionResult::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.alternatives_) +
          decltype(StreamingRecognitionResult::_impl_.alternatives_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(StreamingRecognitionResult), alignof(StreamingRecognitionResult), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&StreamingRecognitionResult::PlacementNew_,
                                 sizeof(StreamingRecognitionResult),
                                 alignof(StreamingRecognitionResult));
  }
}
constexpr auto StreamingRecognitionResult::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_StreamingRecognitionResult_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &StreamingRecognitionResult::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<StreamingRecognitionResult>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &StreamingRecognitionResult::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<StreamingRecognitionResult>(), &StreamingRecognitionResult::ByteSizeLong,
              &StreamingRecognitionResult::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_._cached_size_),
          false,
      },
      &StreamingRecognitionResult::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull StreamingRecognitionResult_class_data_ =
        StreamingRecognitionResult::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
StreamingRecognitionResult::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&StreamingRecognitionResult_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(StreamingRecognitionResult_class_data_.tc_table);
  return StreamingRecognitionResult_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 2, 71, 2>
StreamingRecognitionResult::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_._has_bits_),
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967232,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    StreamingRecognitionResult_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::StreamingRecognitionResult>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.alternatives_)}},
    // bool is_final = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(StreamingRecognitionResult, _impl_.is_final_), 2>(),
     {16, 2, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.is_final_)}},
    // float stability = 3;
    {::_pbi::TcParser::FastF32S1,
     {29, 3, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.stability_)}},
    // .google.protobuf.Duration result_end_time = 4;
    {::_pbi::TcParser::FastMtS1,
     {34, 1, 1, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.result_end_time_)}},
    // int32 channel_tag = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(StreamingRecognitionResult, _impl_.channel_tag_), 4>(),
     {40, 4, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.channel_tag_)}},
    // string language_code = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::FastUS1,
     {50, 0, 0, PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.language_code_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.alternatives_), -1, 0, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool is_final = 2;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.is_final_), _Internal::kHasBitsOffset + 2, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // float stability = 3;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.stability_), _Internal::kHasBitsOffset + 3, 0, (0 | ::_fl::kFcOptional | ::_fl::kFloat)},
    // .google.protobuf.Duration result_end_time = 4;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.result_end_time_), _Internal::kHasBitsOffset + 1, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int32 channel_tag = 5;
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.channel_tag_), _Internal::kHasBitsOffset + 4, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // string language_code = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.language_code_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionAlternative>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
  }},
  {{
    "\61\0\0\0\0\0\15\0"
    "google.cloud.speech.v1.StreamingRecognitionResult"
    "language_code"
  }},
};
PROTOBUF_NOINLINE void StreamingRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.StreamingRecognitionResult)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.alternatives_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      _impl_.language_code_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.result_end_time_ != nullptr);
      _impl_.result_end_time_->Clear();
    }
  }
  if ((cached_has_bits & 0x0000001cU) != 0) {
    ::memset(&_impl_.is_final_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.channel_tag_) -
        reinterpret_cast<char*>(&_impl_.is_final_)) + sizeof(_impl_.channel_tag_));
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL StreamingRecognitionResult::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const StreamingRecognitionResult& this_ = static_cast<const StreamingRecognitionResult&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL StreamingRecognitionResult::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const StreamingRecognitionResult& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.StreamingRecognitionResult)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
  for (unsigned i = 0, n = static_cast<unsigned>(
                           this_._internal_alternatives_size());
       i < n; i++) {
    const auto& repfield = this_._internal_alternatives().Get(i);
    target =
        ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
            1, repfield, repfield.GetCachedSize(),
            target, stream);
  }

  // bool is_final = 2;
  if ((this_._impl_._has_bits_[0] & 0x00000004U) != 0) {
    if (this_._internal_is_final() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          2, this_._internal_is_final(), target);
    }
  }

  // float stability = 3;
  if ((this_._impl_._has_bits_[0] & 0x00000008U) != 0) {
    if (::absl::bit_cast<::uint32_t>(this_._internal_stability()) != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteFloatToArray(
          3, this_._internal_stability(), target);
    }
  }

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.protobuf.Duration result_end_time = 4;
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        4, *this_._impl_.result_end_time_, this_._impl_.result_end_time_->GetCachedSize(), target,
        stream);
  }

  // int32 channel_tag = 5;
  if ((cached_has_bits & 0x00000010U) != 0) {
    if (this_._internal_channel_tag() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<5>(
              stream, this_._internal_channel_tag(), target);
    }
  }

  // string language_code = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
  if ((cached_has_bits & 0x00000001U) != 0) {
    if (!this_._internal_language_code().empty()) {
      const ::std::string& _s = this_._internal_language_code();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.StreamingRecognitionResult.language_code");
      target = stream->WriteStringMaybeAliased(6, _s, target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.StreamingRecognitionResult)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t StreamingRecognitionResult::ByteSizeLong(const MessageLite& base) {
  const StreamingRecognitionResult& this_ = static_cast<const StreamingRecognitionResult&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t StreamingRecognitionResult::ByteSizeLong() const {
  const StreamingRecognitionResult& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.StreamingRecognitionResult)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
   {
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {
      total_size += 1UL * this_._internal_alternatives_size();
      for (const auto& msg : this_._internal_alternatives()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
  }
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000001fU) != 0) {
    // string language_code = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!this_._internal_language_code().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_language_code());
      }
    }
    // .google.protobuf.Duration result_end_time = 4;
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.result_end_time_);
    }
    // bool is_final = 2;
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (this_._internal_is_final() != 0) {
        total_size += 2;
      }
    }
    // float stability = 3;
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (::absl::bit_cast<::uint32_t>(this_._internal_stability()) != 0) {
        total_size += 5;
      }
    }
    // int32 channel_tag = 5;
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (this_._internal_channel_tag() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_channel_tag());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void StreamingRecognitionResult::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StreamingRecognitionResult*>(&to_msg);
  auto& from = static_cast<const StreamingRecognitionResult&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.StreamingRecognitionResult)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_alternatives()->MergeFrom(
      from._internal_alternatives());
  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000001fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!from._internal_language_code().empty()) {
        _this->_internal_set_language_code(from._internal_language_code());
      } else {
        if (_this->_impl_.language_code_.IsDefault()) {
          _this->_internal_set_language_code("");
        }
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.result_end_time_ != nullptr);
      if (_this->_impl_.result_end_time_ == nullptr) {
        _this->_impl_.result_end_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.result_end_time_);
      } else {
        _this->_impl_.result_end_time_->MergeFrom(*from._impl_.result_end_time_);
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (from._internal_is_final() != 0) {
        _this->_impl_.is_final_ = from._impl_.is_final_;
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      if (::absl::bit_cast<::uint32_t>(from._internal_stability()) != 0) {
        _this->_impl_.stability_ = from._impl_.stability_;
      }
    }
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (from._internal_channel_tag() != 0) {
        _this->_impl_.channel_tag_ = from._impl_.channel_tag_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StreamingRecognitionResult::CopyFrom(const StreamingRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.StreamingRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StreamingRecognitionResult::InternalSwap(StreamingRecognitionResult* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.alternatives_.InternalSwap(&other->_impl_.alternatives_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.language_code_, &other->_impl_.language_code_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.channel_tag_)
      + sizeof(StreamingRecognitionResult::_impl_.channel_tag_)
      - PROTOBUF_FIELD_OFFSET(StreamingRecognitionResult, _impl_.result_end_time_)>(
          reinterpret_cast<char*>(&_impl_.result_end_time_),
          reinterpret_cast<char*>(&other->_impl_.result_end_time_));
}

::google::protobuf::Metadata StreamingRecognitionResult::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeechRecognitionResult::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<SpeechRecognitionResult>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_._has_bits_);
};

void SpeechRecognitionResult::clear_result_end_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.result_end_time_ != nullptr) _impl_.result_end_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002U;
}
SpeechRecognitionResult::SpeechRecognitionResult(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeechRecognitionResult_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeechRecognitionResult)
}
PROTOBUF_NDEBUG_INLINE SpeechRecognitionResult::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::SpeechRecognitionResult& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        alternatives_{visibility, arena, from.alternatives_},
        language_code_(arena, from.language_code_) {}

SpeechRecognitionResult::SpeechRecognitionResult(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const SpeechRecognitionResult& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeechRecognitionResult_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SpeechRecognitionResult* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.result_end_time_ = ((cached_has_bits & 0x00000002U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.result_end_time_)
                : nullptr;
  _impl_.channel_tag_ = from._impl_.channel_tag_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.SpeechRecognitionResult)
}
PROTOBUF_NDEBUG_INLINE SpeechRecognitionResult::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        alternatives_{visibility, arena},
        language_code_(arena) {}

inline void SpeechRecognitionResult::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, result_end_time_),
           0,
           offsetof(Impl_, channel_tag_) -
               offsetof(Impl_, result_end_time_) +
               sizeof(Impl_::channel_tag_));
}
SpeechRecognitionResult::~SpeechRecognitionResult() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeechRecognitionResult)
  SharedDtor(*this);
}
inline void SpeechRecognitionResult::SharedDtor(MessageLite& self) {
  SpeechRecognitionResult& this_ = static_cast<SpeechRecognitionResult&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.language_code_.Destroy();
  delete this_._impl_.result_end_time_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL SpeechRecognitionResult::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) SpeechRecognitionResult(arena);
}
constexpr auto SpeechRecognitionResult::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.alternatives_) +
          decltype(SpeechRecognitionResult::_impl_.alternatives_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(SpeechRecognitionResult), alignof(SpeechRecognitionResult), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&SpeechRecognitionResult::PlacementNew_,
                                 sizeof(SpeechRecognitionResult),
                                 alignof(SpeechRecognitionResult));
  }
}
constexpr auto SpeechRecognitionResult::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_SpeechRecognitionResult_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &SpeechRecognitionResult::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<SpeechRecognitionResult>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &SpeechRecognitionResult::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<SpeechRecognitionResult>(), &SpeechRecognitionResult::ByteSizeLong,
              &SpeechRecognitionResult::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_._cached_size_),
          false,
      },
      &SpeechRecognitionResult::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull SpeechRecognitionResult_class_data_ =
        SpeechRecognitionResult::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
SpeechRecognitionResult::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&SpeechRecognitionResult_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(SpeechRecognitionResult_class_data_.tc_table);
  return SpeechRecognitionResult_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 4, 2, 68, 2>
SpeechRecognitionResult::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_._has_bits_),
    0, // no _extensions_
    5, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967268,  // skipmap
    offsetof(decltype(_table_), field_entries),
    4,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    SpeechRecognitionResult_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionResult>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.alternatives_)}},
    // int32 channel_tag = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(SpeechRecognitionResult, _impl_.channel_tag_), 2>(),
     {16, 2, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // .google.protobuf.Duration result_end_time = 4;
    {::_pbi::TcParser::FastMtS1,
     {34, 1, 1, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.result_end_time_)}},
    // string language_code = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::FastUS1,
     {42, 0, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.language_code_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.alternatives_), -1, 0, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // int32 channel_tag = 2;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_), _Internal::kHasBitsOffset + 2, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // .google.protobuf.Duration result_end_time = 4;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.result_end_time_), _Internal::kHasBitsOffset + 1, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // string language_code = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.language_code_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionAlternative>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
  }},
  {{
    "\56\0\0\0\15\0\0\0"
    "google.cloud.speech.v1.SpeechRecognitionResult"
    "language_code"
  }},
};
PROTOBUF_NOINLINE void SpeechRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeechRecognitionResult)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.alternatives_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      _impl_.language_code_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(_impl_.result_end_time_ != nullptr);
      _impl_.result_end_time_->Clear();
    }
  }
  _impl_.channel_tag_ = 0;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL SpeechRecognitionResult::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const SpeechRecognitionResult& this_ = static_cast<const SpeechRecognitionResult&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL SpeechRecognitionResult::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const SpeechRecognitionResult& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeechRecognitionResult)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
  for (unsigned i = 0, n = static_cast<unsigned>(
                           this_._internal_alternatives_size());
       i < n; i++) {
    const auto& repfield = this_._internal_alternatives().Get(i);
    target =
        ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
            1, repfield, repfield.GetCachedSize(),
            target, stream);
  }

  // int32 channel_tag = 2;
  if ((this_._impl_._has_bits_[0] & 0x00000004U) != 0) {
    if (this_._internal_channel_tag() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<2>(
              stream, this_._internal_channel_tag(), target);
    }
  }

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.protobuf.Duration result_end_time = 4;
  if ((cached_has_bits & 0x00000002U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        4, *this_._impl_.result_end_time_, this_._impl_.result_end_time_->GetCachedSize(), target,
        stream);
  }

  // string language_code = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
  if ((cached_has_bits & 0x00000001U) != 0) {
    if (!this_._internal_language_code().empty()) {
      const ::std::string& _s = this_._internal_language_code();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.SpeechRecognitionResult.language_code");
      target = stream->WriteStringMaybeAliased(5, _s, target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeechRecognitionResult)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t SpeechRecognitionResult::ByteSizeLong(const MessageLite& base) {
  const SpeechRecognitionResult& this_ = static_cast<const SpeechRecognitionResult&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t SpeechRecognitionResult::ByteSizeLong() const {
  const SpeechRecognitionResult& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeechRecognitionResult)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
   {
    // repeated .google.cloud.speech.v1.SpeechRecognitionAlternative alternatives = 1;
    {
      total_size += 1UL * this_._internal_alternatives_size();
      for (const auto& msg : this_._internal_alternatives()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
  }
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    // string language_code = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!this_._internal_language_code().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_language_code());
      }
    }
    // .google.protobuf.Duration result_end_time = 4;
    if ((cached_has_bits & 0x00000002U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.result_end_time_);
    }
    // int32 channel_tag = 2;
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (this_._internal_channel_tag() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_channel_tag());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void SpeechRecognitionResult::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeechRecognitionResult*>(&to_msg);
  auto& from = static_cast<const SpeechRecognitionResult&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeechRecognitionResult)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_alternatives()->MergeFrom(
      from._internal_alternatives());
  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000007U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!from._internal_language_code().empty()) {
        _this->_internal_set_language_code(from._internal_language_code());
      } else {
        if (_this->_impl_.language_code_.IsDefault()) {
          _this->_internal_set_language_code("");
        }
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      ABSL_DCHECK(from._impl_.result_end_time_ != nullptr);
      if (_this->_impl_.result_end_time_ == nullptr) {
        _this->_impl_.result_end_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.result_end_time_);
      } else {
        _this->_impl_.result_end_time_->MergeFrom(*from._impl_.result_end_time_);
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      if (from._internal_channel_tag() != 0) {
        _this->_impl_.channel_tag_ = from._impl_.channel_tag_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechRecognitionResult::CopyFrom(const SpeechRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeechRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeechRecognitionResult::InternalSwap(SpeechRecognitionResult* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.alternatives_.InternalSwap(&other->_impl_.alternatives_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.language_code_, &other->_impl_.language_code_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.channel_tag_)
      + sizeof(SpeechRecognitionResult::_impl_.channel_tag_)
      - PROTOBUF_FIELD_OFFSET(SpeechRecognitionResult, _impl_.result_end_time_)>(
          reinterpret_cast<char*>(&_impl_.result_end_time_),
          reinterpret_cast<char*>(&other->_impl_.result_end_time_));
}

::google::protobuf::Metadata SpeechRecognitionResult::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeechRecognitionAlternative::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<SpeechRecognitionAlternative>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_._has_bits_);
};

SpeechRecognitionAlternative::SpeechRecognitionAlternative(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeechRecognitionAlternative_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeechRecognitionAlternative)
}
PROTOBUF_NDEBUG_INLINE SpeechRecognitionAlternative::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::SpeechRecognitionAlternative& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        words_{visibility, arena, from.words_},
        transcript_(arena, from.transcript_) {}

SpeechRecognitionAlternative::SpeechRecognitionAlternative(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const SpeechRecognitionAlternative& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeechRecognitionAlternative_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SpeechRecognitionAlternative* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  _impl_.confidence_ = from._impl_.confidence_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.SpeechRecognitionAlternative)
}
PROTOBUF_NDEBUG_INLINE SpeechRecognitionAlternative::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        words_{visibility, arena},
        transcript_(arena) {}

inline void SpeechRecognitionAlternative::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.confidence_ = {};
}
SpeechRecognitionAlternative::~SpeechRecognitionAlternative() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeechRecognitionAlternative)
  SharedDtor(*this);
}
inline void SpeechRecognitionAlternative::SharedDtor(MessageLite& self) {
  SpeechRecognitionAlternative& this_ = static_cast<SpeechRecognitionAlternative&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.transcript_.Destroy();
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL SpeechRecognitionAlternative::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) SpeechRecognitionAlternative(arena);
}
constexpr auto SpeechRecognitionAlternative::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.words_) +
          decltype(SpeechRecognitionAlternative::_impl_.words_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(SpeechRecognitionAlternative), alignof(SpeechRecognitionAlternative), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&SpeechRecognitionAlternative::PlacementNew_,
                                 sizeof(SpeechRecognitionAlternative),
                                 alignof(SpeechRecognitionAlternative));
  }
}
constexpr auto SpeechRecognitionAlternative::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_SpeechRecognitionAlternative_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &SpeechRecognitionAlternative::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<SpeechRecognitionAlternative>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &SpeechRecognitionAlternative::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<SpeechRecognitionAlternative>(), &SpeechRecognitionAlternative::ByteSizeLong,
              &SpeechRecognitionAlternative::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_._cached_size_),
          false,
      },
      &SpeechRecognitionAlternative::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull SpeechRecognitionAlternative_class_data_ =
        SpeechRecognitionAlternative::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
SpeechRecognitionAlternative::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&SpeechRecognitionAlternative_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(SpeechRecognitionAlternative_class_data_.tc_table);
  return SpeechRecognitionAlternative_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 1, 70, 2>
SpeechRecognitionAlternative::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_._has_bits_),
    0, // no _extensions_
    3, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967288,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    SpeechRecognitionAlternative_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechRecognitionAlternative>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // string transcript = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.transcript_)}},
    // float confidence = 2;
    {::_pbi::TcParser::FastF32S1,
     {21, 1, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.confidence_)}},
    // repeated .google.cloud.speech.v1.WordInfo words = 3;
    {::_pbi::TcParser::FastMtR1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.words_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string transcript = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.transcript_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // float confidence = 2;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.confidence_), _Internal::kHasBitsOffset + 1, 0, (0 | ::_fl::kFcOptional | ::_fl::kFloat)},
    // repeated .google.cloud.speech.v1.WordInfo words = 3;
    {PROTOBUF_FIELD_OFFSET(SpeechRecognitionAlternative, _impl_.words_), -1, 0, (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::cloud::speech::v1::WordInfo>()},
  }},
  {{
    "\63\12\0\0\0\0\0\0"
    "google.cloud.speech.v1.SpeechRecognitionAlternative"
    "transcript"
  }},
};
PROTOBUF_NOINLINE void SpeechRecognitionAlternative::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.words_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000001U) != 0) {
    _impl_.transcript_.ClearNonDefaultToEmpty();
  }
  _impl_.confidence_ = 0;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL SpeechRecognitionAlternative::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const SpeechRecognitionAlternative& this_ = static_cast<const SpeechRecognitionAlternative&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL SpeechRecognitionAlternative::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const SpeechRecognitionAlternative& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // string transcript = 1;
  if ((this_._impl_._has_bits_[0] & 0x00000001U) != 0) {
    if (!this_._internal_transcript().empty()) {
      const ::std::string& _s = this_._internal_transcript();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.SpeechRecognitionAlternative.transcript");
      target = stream->WriteStringMaybeAliased(1, _s, target);
    }
  }

  // float confidence = 2;
  if ((this_._impl_._has_bits_[0] & 0x00000002U) != 0) {
    if (::absl::bit_cast<::uint32_t>(this_._internal_confidence()) != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteFloatToArray(
          2, this_._internal_confidence(), target);
    }
  }

  // repeated .google.cloud.speech.v1.WordInfo words = 3;
  for (unsigned i = 0, n = static_cast<unsigned>(
                           this_._internal_words_size());
       i < n; i++) {
    const auto& repfield = this_._internal_words().Get(i);
    target =
        ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
            3, repfield, repfield.GetCachedSize(),
            target, stream);
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeechRecognitionAlternative)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t SpeechRecognitionAlternative::ByteSizeLong(const MessageLite& base) {
  const SpeechRecognitionAlternative& this_ = static_cast<const SpeechRecognitionAlternative&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t SpeechRecognitionAlternative::ByteSizeLong() const {
  const SpeechRecognitionAlternative& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
   {
    // repeated .google.cloud.speech.v1.WordInfo words = 3;
    {
      total_size += 1UL * this_._internal_words_size();
      for (const auto& msg : this_._internal_words()) {
        total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
      }
    }
  }
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    // string transcript = 1;
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!this_._internal_transcript().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_transcript());
      }
    }
    // float confidence = 2;
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (::absl::bit_cast<::uint32_t>(this_._internal_confidence()) != 0) {
        total_size += 5;
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void SpeechRecognitionAlternative::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeechRecognitionAlternative*>(&to_msg);
  auto& from = static_cast<const SpeechRecognitionAlternative&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_words()->MergeFrom(
      from._internal_words());
  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!from._internal_transcript().empty()) {
        _this->_internal_set_transcript(from._internal_transcript());
      } else {
        if (_this->_impl_.transcript_.IsDefault()) {
          _this->_internal_set_transcript("");
        }
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (::absl::bit_cast<::uint32_t>(from._internal_confidence()) != 0) {
        _this->_impl_.confidence_ = from._impl_.confidence_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechRecognitionAlternative::CopyFrom(const SpeechRecognitionAlternative& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeechRecognitionAlternative)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeechRecognitionAlternative::InternalSwap(SpeechRecognitionAlternative* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.words_.InternalSwap(&other->_impl_.words_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.transcript_, &other->_impl_.transcript_, arena);
  swap(_impl_.confidence_, other->_impl_.confidence_);
}

::google::protobuf::Metadata SpeechRecognitionAlternative::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class WordInfo::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<WordInfo>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(WordInfo, _impl_._has_bits_);
};

void WordInfo::clear_start_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.start_time_ != nullptr) _impl_.start_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000004U;
}
void WordInfo::clear_end_time() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.end_time_ != nullptr) _impl_.end_time_->Clear();
  _impl_._has_bits_[0] &= ~0x00000008U;
}
WordInfo::WordInfo(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, WordInfo_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.WordInfo)
}
PROTOBUF_NDEBUG_INLINE WordInfo::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::WordInfo& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        word_(arena, from.word_),
        speaker_label_(arena, from.speaker_label_) {}

WordInfo::WordInfo(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const WordInfo& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, WordInfo_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  WordInfo* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.start_time_ = ((cached_has_bits & 0x00000004U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.start_time_)
                : nullptr;
  _impl_.end_time_ = ((cached_has_bits & 0x00000008U) != 0)
                ? ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.end_time_)
                : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, confidence_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, confidence_),
           offsetof(Impl_, speaker_tag_) -
               offsetof(Impl_, confidence_) +
               sizeof(Impl_::speaker_tag_));

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.WordInfo)
}
PROTOBUF_NDEBUG_INLINE WordInfo::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        word_(arena),
        speaker_label_(arena) {}

inline void WordInfo::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, start_time_),
           0,
           offsetof(Impl_, speaker_tag_) -
               offsetof(Impl_, start_time_) +
               sizeof(Impl_::speaker_tag_));
}
WordInfo::~WordInfo() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.WordInfo)
  SharedDtor(*this);
}
inline void WordInfo::SharedDtor(MessageLite& self) {
  WordInfo& this_ = static_cast<WordInfo&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.word_.Destroy();
  this_._impl_.speaker_label_.Destroy();
  delete this_._impl_.start_time_;
  delete this_._impl_.end_time_;
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL WordInfo::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) WordInfo(arena);
}
constexpr auto WordInfo::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(WordInfo),
                                            alignof(WordInfo));
}
constexpr auto WordInfo::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_WordInfo_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &WordInfo::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<WordInfo>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &WordInfo::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<WordInfo>(), &WordInfo::ByteSizeLong,
              &WordInfo::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(WordInfo, _impl_._cached_size_),
          false,
      },
      &WordInfo::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull WordInfo_class_data_ =
        WordInfo::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
WordInfo::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&WordInfo_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(WordInfo_class_data_.tc_table);
  return WordInfo_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 2, 57, 2>
WordInfo::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(WordInfo, _impl_._has_bits_),
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967232,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    WordInfo_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::WordInfo>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // .google.protobuf.Duration start_time = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 2, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_)}},
    // .google.protobuf.Duration end_time = 2;
    {::_pbi::TcParser::FastMtS1,
     {18, 3, 1, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.end_time_)}},
    // string word = 3;
    {::_pbi::TcParser::FastUS1,
     {26, 0, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.word_)}},
    // float confidence = 4;
    {::_pbi::TcParser::FastF32S1,
     {37, 4, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.confidence_)}},
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(WordInfo, _impl_.speaker_tag_), 5>(),
     {40, 5, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_)}},
    // string speaker_label = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {::_pbi::TcParser::FastUS1,
     {50, 1, 0, PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_label_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .google.protobuf.Duration start_time = 1;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_), _Internal::kHasBitsOffset + 2, 0, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .google.protobuf.Duration end_time = 2;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.end_time_), _Internal::kHasBitsOffset + 3, 1, (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // string word = 3;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.word_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // float confidence = 4;
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.confidence_), _Internal::kHasBitsOffset + 4, 0, (0 | ::_fl::kFcOptional | ::_fl::kFloat)},
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_), _Internal::kHasBitsOffset + 5, 0, (0 | ::_fl::kFcOptional | ::_fl::kInt32)},
    // string speaker_label = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    {PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_label_), _Internal::kHasBitsOffset + 1, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  {{
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
      {::_pbi::TcParser::GetTable<::google::protobuf::Duration>()},
  }},
  {{
    "\37\0\0\4\0\0\15\0"
    "google.cloud.speech.v1.WordInfo"
    "word"
    "speaker_label"
  }},
};
PROTOBUF_NOINLINE void WordInfo::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.WordInfo)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000000fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      _impl_.word_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      _impl_.speaker_label_.ClearNonDefaultToEmpty();
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(_impl_.start_time_ != nullptr);
      _impl_.start_time_->Clear();
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      ABSL_DCHECK(_impl_.end_time_ != nullptr);
      _impl_.end_time_->Clear();
    }
  }
  if ((cached_has_bits & 0x00000030U) != 0) {
    ::memset(&_impl_.confidence_, 0, static_cast<::size_t>(
        reinterpret_cast<char*>(&_impl_.speaker_tag_) -
        reinterpret_cast<char*>(&_impl_.confidence_)) + sizeof(_impl_.speaker_tag_));
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL WordInfo::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const WordInfo& this_ = static_cast<const WordInfo&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL WordInfo::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const WordInfo& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.WordInfo)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  cached_has_bits = this_._impl_._has_bits_[0];
  // .google.protobuf.Duration start_time = 1;
  if ((cached_has_bits & 0x00000004U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        1, *this_._impl_.start_time_, this_._impl_.start_time_->GetCachedSize(), target,
        stream);
  }

  // .google.protobuf.Duration end_time = 2;
  if ((cached_has_bits & 0x00000008U) != 0) {
    target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
        2, *this_._impl_.end_time_, this_._impl_.end_time_->GetCachedSize(), target,
        stream);
  }

  // string word = 3;
  if ((cached_has_bits & 0x00000001U) != 0) {
    if (!this_._internal_word().empty()) {
      const ::std::string& _s = this_._internal_word();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.WordInfo.word");
      target = stream->WriteStringMaybeAliased(3, _s, target);
    }
  }

  // float confidence = 4;
  if ((cached_has_bits & 0x00000010U) != 0) {
    if (::absl::bit_cast<::uint32_t>(this_._internal_confidence()) != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteFloatToArray(
          4, this_._internal_confidence(), target);
    }
  }

  // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
  if ((cached_has_bits & 0x00000020U) != 0) {
    if (this_._internal_speaker_tag() != 0) {
      target =
          ::google::protobuf::internal::WireFormatLite::WriteInt32ToArrayWithField<5>(
              stream, this_._internal_speaker_tag(), target);
    }
  }

  // string speaker_label = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
  if ((cached_has_bits & 0x00000002U) != 0) {
    if (!this_._internal_speaker_label().empty()) {
      const ::std::string& _s = this_._internal_speaker_label();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.WordInfo.speaker_label");
      target = stream->WriteStringMaybeAliased(6, _s, target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.WordInfo)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t WordInfo::ByteSizeLong(const MessageLite& base) {
  const WordInfo& this_ = static_cast<const WordInfo&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t WordInfo::ByteSizeLong() const {
  const WordInfo& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.WordInfo)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000003fU) != 0) {
    // string word = 3;
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!this_._internal_word().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_word());
      }
    }
    // string speaker_label = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (!this_._internal_speaker_label().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_speaker_label());
      }
    }
    // .google.protobuf.Duration start_time = 1;
    if ((cached_has_bits & 0x00000004U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.start_time_);
    }
    // .google.protobuf.Duration end_time = 2;
    if ((cached_has_bits & 0x00000008U) != 0) {
      total_size += 1 +
                    ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.end_time_);
    }
    // float confidence = 4;
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (::absl::bit_cast<::uint32_t>(this_._internal_confidence()) != 0) {
        total_size += 5;
      }
    }
    // int32 speaker_tag = 5 [deprecated = true, (.google.api.field_behavior) = OUTPUT_ONLY];
    if ((cached_has_bits & 0x00000020U) != 0) {
      if (this_._internal_speaker_tag() != 0) {
        total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
            this_._internal_speaker_tag());
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void WordInfo::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<WordInfo*>(&to_msg);
  auto& from = static_cast<const WordInfo&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.WordInfo)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x0000003fU) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!from._internal_word().empty()) {
        _this->_internal_set_word(from._internal_word());
      } else {
        if (_this->_impl_.word_.IsDefault()) {
          _this->_internal_set_word("");
        }
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (!from._internal_speaker_label().empty()) {
        _this->_internal_set_speaker_label(from._internal_speaker_label());
      } else {
        if (_this->_impl_.speaker_label_.IsDefault()) {
          _this->_internal_set_speaker_label("");
        }
      }
    }
    if ((cached_has_bits & 0x00000004U) != 0) {
      ABSL_DCHECK(from._impl_.start_time_ != nullptr);
      if (_this->_impl_.start_time_ == nullptr) {
        _this->_impl_.start_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.start_time_);
      } else {
        _this->_impl_.start_time_->MergeFrom(*from._impl_.start_time_);
      }
    }
    if ((cached_has_bits & 0x00000008U) != 0) {
      ABSL_DCHECK(from._impl_.end_time_ != nullptr);
      if (_this->_impl_.end_time_ == nullptr) {
        _this->_impl_.end_time_ = ::google::protobuf::Message::CopyConstruct(arena, *from._impl_.end_time_);
      } else {
        _this->_impl_.end_time_->MergeFrom(*from._impl_.end_time_);
      }
    }
    if ((cached_has_bits & 0x00000010U) != 0) {
      if (::absl::bit_cast<::uint32_t>(from._internal_confidence()) != 0) {
        _this->_impl_.confidence_ = from._impl_.confidence_;
      }
    }
    if ((cached_has_bits & 0x00000020U) != 0) {
      if (from._internal_speaker_tag() != 0) {
        _this->_impl_.speaker_tag_ = from._impl_.speaker_tag_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void WordInfo::CopyFrom(const WordInfo& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.WordInfo)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void WordInfo::InternalSwap(WordInfo* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.word_, &other->_impl_.word_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.speaker_label_, &other->_impl_.speaker_label_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.speaker_tag_)
      + sizeof(WordInfo::_impl_.speaker_tag_)
      - PROTOBUF_FIELD_OFFSET(WordInfo, _impl_.start_time_)>(
          reinterpret_cast<char*>(&_impl_.start_time_),
          reinterpret_cast<char*>(&other->_impl_.start_time_));
}

::google::protobuf::Metadata WordInfo::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SpeechAdaptationInfo::_Internal {
 public:
  using HasBits =
      decltype(::std::declval<SpeechAdaptationInfo>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_._has_bits_);
};

SpeechAdaptationInfo::SpeechAdaptationInfo(::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeechAdaptationInfo_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:google.cloud.speech.v1.SpeechAdaptationInfo)
}
PROTOBUF_NDEBUG_INLINE SpeechAdaptationInfo::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
    [[maybe_unused]] const ::google::cloud::speech::v1::SpeechAdaptationInfo& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        timeout_message_(arena, from.timeout_message_) {}

SpeechAdaptationInfo::SpeechAdaptationInfo(
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena,
    const SpeechAdaptationInfo& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, SpeechAdaptationInfo_class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SpeechAdaptationInfo* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  _impl_.adaptation_timeout_ = from._impl_.adaptation_timeout_;

  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1.SpeechAdaptationInfo)
}
PROTOBUF_NDEBUG_INLINE SpeechAdaptationInfo::Impl_::Impl_(
    [[maybe_unused]] ::google::protobuf::internal::InternalVisibility visibility,
    [[maybe_unused]] ::google::protobuf::Arena* PROTOBUF_NULLABLE arena)
      : _cached_size_{0},
        timeout_message_(arena) {}

inline void SpeechAdaptationInfo::SharedCtor(::_pb::Arena* PROTOBUF_NULLABLE arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.adaptation_timeout_ = {};
}
SpeechAdaptationInfo::~SpeechAdaptationInfo() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1.SpeechAdaptationInfo)
  SharedDtor(*this);
}
inline void SpeechAdaptationInfo::SharedDtor(MessageLite& self) {
  SpeechAdaptationInfo& this_ = static_cast<SpeechAdaptationInfo&>(self);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.timeout_message_.Destroy();
  this_._impl_.~Impl_();
}

inline void* PROTOBUF_NONNULL SpeechAdaptationInfo::PlacementNew_(
    const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
    ::google::protobuf::Arena* PROTOBUF_NULLABLE arena) {
  return ::new (mem) SpeechAdaptationInfo(arena);
}
constexpr auto SpeechAdaptationInfo::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(SpeechAdaptationInfo),
                                            alignof(SpeechAdaptationInfo));
}
constexpr auto SpeechAdaptationInfo::InternalGenerateClassData_() {
  return ::google::protobuf::internal::ClassDataFull{
      ::google::protobuf::internal::ClassData{
          &_SpeechAdaptationInfo_default_instance_._instance,
          &_table_.header,
          nullptr,  // OnDemandRegisterArenaDtor
          nullptr,  // IsInitialized
          &SpeechAdaptationInfo::MergeImpl,
          ::google::protobuf::Message::GetNewImpl<SpeechAdaptationInfo>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
          &SpeechAdaptationInfo::SharedDtor,
          ::google::protobuf::Message::GetClearImpl<SpeechAdaptationInfo>(), &SpeechAdaptationInfo::ByteSizeLong,
              &SpeechAdaptationInfo::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
          PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_._cached_size_),
          false,
      },
      &SpeechAdaptationInfo::kDescriptorMethods,
      &descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto,
      nullptr,  // tracker
  };
}

PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 const
    ::google::protobuf::internal::ClassDataFull SpeechAdaptationInfo_class_data_ =
        SpeechAdaptationInfo::InternalGenerateClassData_();

PROTOBUF_ATTRIBUTE_WEAK const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL
SpeechAdaptationInfo::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&SpeechAdaptationInfo_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(SpeechAdaptationInfo_class_data_.tc_table);
  return SpeechAdaptationInfo_class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 67, 2>
SpeechAdaptationInfo::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_._has_bits_),
    0, // no _extensions_
    4, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967286,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    SpeechAdaptationInfo_class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::google::cloud::speech::v1::SpeechAdaptationInfo>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string timeout_message = 4;
    {::_pbi::TcParser::FastUS1,
     {34, 0, 0, PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_.timeout_message_)}},
    // bool adaptation_timeout = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(SpeechAdaptationInfo, _impl_.adaptation_timeout_), 1>(),
     {8, 1, 0, PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_.adaptation_timeout_)}},
  }}, {{
    65535, 65535
  }}, {{
    // bool adaptation_timeout = 1;
    {PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_.adaptation_timeout_), _Internal::kHasBitsOffset + 1, 0, (0 | ::_fl::kFcOptional | ::_fl::kBool)},
    // string timeout_message = 4;
    {PROTOBUF_FIELD_OFFSET(SpeechAdaptationInfo, _impl_.timeout_message_), _Internal::kHasBitsOffset + 0, 0, (0 | ::_fl::kFcOptional | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\53\0\17\0\0\0\0\0"
    "google.cloud.speech.v1.SpeechAdaptationInfo"
    "timeout_message"
  }},
};
PROTOBUF_NOINLINE void SpeechAdaptationInfo::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1.SpeechAdaptationInfo)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000001U) != 0) {
    _impl_.timeout_message_.ClearNonDefaultToEmpty();
  }
  _impl_.adaptation_timeout_ = false;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::uint8_t* PROTOBUF_NONNULL SpeechAdaptationInfo::_InternalSerialize(
    const ::google::protobuf::MessageLite& base, ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) {
  const SpeechAdaptationInfo& this_ = static_cast<const SpeechAdaptationInfo&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::uint8_t* PROTOBUF_NONNULL SpeechAdaptationInfo::_InternalSerialize(
    ::uint8_t* PROTOBUF_NONNULL target,
    ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
  const SpeechAdaptationInfo& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    this_.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1.SpeechAdaptationInfo)
  ::uint32_t cached_has_bits = 0;
  (void)cached_has_bits;

  // bool adaptation_timeout = 1;
  if ((this_._impl_._has_bits_[0] & 0x00000002U) != 0) {
    if (this_._internal_adaptation_timeout() != 0) {
      target = stream->EnsureSpace(target);
      target = ::_pbi::WireFormatLite::WriteBoolToArray(
          1, this_._internal_adaptation_timeout(), target);
    }
  }

  // string timeout_message = 4;
  if ((this_._impl_._has_bits_[0] & 0x00000001U) != 0) {
    if (!this_._internal_timeout_message().empty()) {
      const ::std::string& _s = this_._internal_timeout_message();
      ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
          _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "google.cloud.speech.v1.SpeechAdaptationInfo.timeout_message");
      target = stream->WriteStringMaybeAliased(4, _s, target);
    }
  }

  if (ABSL_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
    target =
        ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
            this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1.SpeechAdaptationInfo)
  return target;
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
::size_t SpeechAdaptationInfo::ByteSizeLong(const MessageLite& base) {
  const SpeechAdaptationInfo& this_ = static_cast<const SpeechAdaptationInfo&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
::size_t SpeechAdaptationInfo::ByteSizeLong() const {
  const SpeechAdaptationInfo& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
  // @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1.SpeechAdaptationInfo)
  ::size_t total_size = 0;

  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void)cached_has_bits;

  ::_pbi::Prefetch5LinesFrom7Lines(&this_);
  cached_has_bits = this_._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    // string timeout_message = 4;
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!this_._internal_timeout_message().empty()) {
        total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                        this_._internal_timeout_message());
      }
    }
    // bool adaptation_timeout = 1;
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (this_._internal_adaptation_timeout() != 0) {
        total_size += 2;
      }
    }
  }
  return this_.MaybeComputeUnknownFieldsSize(total_size,
                                             &this_._impl_._cached_size_);
}

void SpeechAdaptationInfo::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SpeechAdaptationInfo*>(&to_msg);
  auto& from = static_cast<const SpeechAdaptationInfo&>(from_msg);
  if constexpr (::_pbi::DebugHardenVerifyHasBitConsistency()) {
    from.VerifyHasBitConsistency();
  }
  // @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1.SpeechAdaptationInfo)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if ((cached_has_bits & 0x00000003U) != 0) {
    if ((cached_has_bits & 0x00000001U) != 0) {
      if (!from._internal_timeout_message().empty()) {
        _this->_internal_set_timeout_message(from._internal_timeout_message());
      } else {
        if (_this->_impl_.timeout_message_.IsDefault()) {
          _this->_internal_set_timeout_message("");
        }
      }
    }
    if ((cached_has_bits & 0x00000002U) != 0) {
      if (from._internal_adaptation_timeout() != 0) {
        _this->_impl_.adaptation_timeout_ = from._impl_.adaptation_timeout_;
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SpeechAdaptationInfo::CopyFrom(const SpeechAdaptationInfo& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1.SpeechAdaptationInfo)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SpeechAdaptationInfo::InternalSwap(SpeechAdaptationInfo* PROTOBUF_RESTRICT PROTOBUF_NONNULL other) {
  using ::std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.timeout_message_, &other->_impl_.timeout_message_, arena);
  swap(_impl_.adaptation_timeout_, other->_impl_.adaptation_timeout_);
}

::google::protobuf::Metadata SpeechAdaptationInfo::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// @@protoc_insertion_point(namespace_scope)
}  // namespace v1
}  // namespace speech
}  // namespace cloud
}  // namespace google
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google
// @@protoc_insertion_point(global_scope)
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::std::false_type
    _static_init2_ [[maybe_unused]] =
        (::_pbi::AddDescriptors(&descriptor_table_CoreAI3D_2fcloud_5fspeech_2eproto),
         ::std::false_type{});
#include "google/protobuf/port_undef.inc"
